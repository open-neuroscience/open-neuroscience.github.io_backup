[{"authors":["admin"],"categories":null,"content":"We are network of collaborators trying to keep track and curate interesting open source projects related to neurosciences. If you have a project that you’d like to see listed here or if you know of a project that should be listed, drop us a line, via E-mail, or Twitter.\n","date":1601251200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1601251200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://open-neuroscience.com/en/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/admin/","section":"authors","summary":"We are network of collaborators trying to keep track and curate interesting open source projects related to neurosciences. If you have a project that you’d like to see listed here or if you know of a project that should be listed, drop us a line, via E-mail, or Twitter.","tags":null,"title":"","type":"authors"},{"authors":["andre-maia-chagas"],"categories":null,"content":"","date":1591401600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1591401600,"objectID":"28f39237c0f9636c65a6ceb4f5018d18","permalink":"https://open-neuroscience.com/en/authors/andre-maia-chagas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/andre-maia-chagas/","section":"authors","summary":"","tags":null,"title":"","type":"authors"},{"authors":["agustin-solano"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7758ec8b60b8b67fced9f7c18c795eba","permalink":"https://open-neuroscience.com/en/authors/agustin-solano/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/agustin-solano/","section":"authors","summary":"","tags":null,"title":"","type":"authors"},{"authors":["benjamin-paffhausen"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4c4af14a37303b26b6ab0502c331f095","permalink":"https://open-neuroscience.com/en/authors/benjamin-paffhausen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/benjamin-paffhausen/","section":"authors","summary":"","tags":null,"title":"","type":"authors"},{"authors":["gaspar-herrera"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6c98e2b8d4c1aa643899047b6f0341e4","permalink":"https://open-neuroscience.com/en/authors/gaspar-herrera/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/gaspar-herrera/","section":"authors","summary":"","tags":null,"title":"","type":"authors"},{"authors":["JJ-ballesteros"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6959ba6d2f221fd3af702a3a44045e4b","permalink":"https://open-neuroscience.com/en/authors/jj-balesteros/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/jj-balesteros/","section":"authors","summary":"","tags":null,"title":"","type":"authors"},{"authors":["matias-andina"],"categories":null,"content":"I continuously find myself mesmerized by the complexity of life. I finished my Biology Degree at University of Buenos Aires in 2015 and moved to the United States in order to continue my studies at University of Massachusetts Amherst. After obtaining my MSc, I continued doing neuroscience at MIT. I am currently doing a PhD in Neuroscience at Tufts University.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"10a9f8e912c4dc53bcd896c2ce2fdced","permalink":"https://open-neuroscience.com/en/authors/matias-andina/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/matias-andina/","section":"authors","summary":"I continuously find myself mesmerized by the complexity of life. I finished my Biology Degree at University of Buenos Aires in 2015 and moved to the United States in order to continue my studies at University of Massachusetts Amherst.","tags":null,"title":"","type":"authors"},{"authors":["Miguel-fernandes"],"categories":null,"content":"I believe that knowledge and education can empower people and will lead to a significant improvement in our world. I was born in Portugal and currently live in Munich, Germany.\nAs a Neuroscientist I am using several methods, including high-resolution behavioral tracking, neuronal imaging, molecular and machine learning approaches to study behavioral choice in zebrafish larvae.\nI love teaching and to work in a team to solve complex questions. I am also a strong supporter of open source tools, accessible to people around the world to tackle their own challenges\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1eee0ca844a6df1101257cb8d5d0491c","permalink":"https://open-neuroscience.com/en/authors/miguel-fernandes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/miguel-fernandes/","section":"authors","summary":"I believe that knowledge and education can empower people and will lead to a significant improvement in our world. I was born in Portugal and currently live in Munich, Germany.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://open-neuroscience.com/en/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/en/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://open-neuroscience.com/en/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://open-neuroscience.com/en/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://open-neuroscience.com/en/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/en/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[""],"categories":["Software","Data Analysis","Computational Neuroscience"],"content":"MorphoPy is an open software package written in Python3 that allows for visualization and processing of morphological reconstructions of neural data. It has been created to facilitate the translation from morphology graphs into descriptive features like density maps, morphometric statistics, and persistence diagrams for down-stream exploration and statistical analysis.\nProject Author(s) Sophie Laturnus; Adam von Daranyi; Ziwei Huang; Philipp Berens\nProject Links https://github.com/berenslab/MorphoPy\n This post was automatically generated by Sophie Laturnus\n ","date":1601251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601251200,"objectID":"e972cbe8c5d325aa25d52bc71fb996d2","permalink":"https://open-neuroscience.com/en/post/morphopy_a_python_package_for_feature_extraction_of_neural_morphologies/","publishdate":"2020-09-28T00:00:00Z","relpermalink":"/en/post/morphopy_a_python_package_for_feature_extraction_of_neural_morphologies/","section":"post","summary":"MorphoPy is an open software package written in Python3 that allows for visualization and processing of morphological reconstructions of neural data. It has been created to facilitate the translation from morphology graphs into descriptive features like density maps, morphometric statistics, and persistence diagrams for down-stream exploration and statistical analysis.","tags":["Software","Data Analysis","Computational Neuroscience"],"title":"MorphoPy: A python package for feature extraction of neural morphologies","type":"post"},{"authors":[""],"categories":["Data Analysis"],"content":"OpenCitations is an independent infrastructure organization for open scholarship dedicated to the publication of open bibliographic and citation data by the use of Semantic Web (Linked Data) technologies. It is also engaged in advocacy for open citations, particularly by organizing the Workshops for Open Citations and Scholarly Metadata, and in its role as a key founding member of the Initiative for Open Citations (I4OC) and the Initiative for Open Abstracts (I4OA).\nOpenCitations espouses fully the founding principles of Open Science. It complies with the FAIR data principles by Force11 that data should be findable, accessible, interoperable and re-usable, and it complies with the recommendations of I4OC that citation data in particular should be structured, separable, and open. On the latter topic, OpenCitations has recently published a formal definition of an Open Citation, and has launched a system for globally unique and persistent identifiers (PIDs) for bibliographic citations – Open Citation Identifiers (OCIs).\nThe following publication is the canonical publication describing OpenCitations itself, as an infrastructure organization for open scholarship. The article describes OpenCitations and its datasets, tools, services and activities.\nSilvio Peroni, David Shotton (2020). OpenCitations, an infrastructure organization for open scholarship. Quantitative Science Studies, 1(1): 428-444. https://doi.org/10.1162/qss_a_00023\nThe OpenCitations Data Model (OCDM) is the metadata model used for the data stored in all the OpenCitations' datasets, described in\nMarilena Daquino, Silvio Peroni, David Shotton (2020). The OpenCitations Data Model. Figshare. https://doi.org/10.6084/m9.figshare.3443876.\nThe largest dataset created by OpenCitations is COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations, an RDF dataset containing details of all the citations that are specified by the open references to DOI-identified works present in Crossref. COCI does not index Crossref references that are not open, nor Crossref open references to entities that lack DOIs. The citations available in COCI are treated as first-class data entities, with accompanying properties including the citations timespan, modelled according to the OpenCitations Data Model.\nCurrently, COCI contains information concerning 733,367,140 citations, and 59,455,917 bibliographic resources. COCI was most recently updated on 6 September 2020.\nFor an in-depth description of COCI, see:\nIvan Heibi, Silvio Peroni, David Shotton (2019). Software review: COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations. Scientometrics, 121 (2): 1213-1228. https://doi.org/10.1007/s11192-019-03217-6\nProject Author(s) David Shotton; Silvio Peroni\nProject Links http://opencitations.net/\nProject Video https://www.youtube.com/watch?v=-bCPS2iIdCc\u0026amp;feature=youtu.be\n This post was automatically generated by David Shotton\n ","date":1601164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601164800,"objectID":"9e2588456c9b5f0fe5c221e151190bd3","permalink":"https://open-neuroscience.com/en/post/opencitations/","publishdate":"2020-09-27T00:00:00Z","relpermalink":"/en/post/opencitations/","section":"post","summary":"OpenCitations is an independent infrastructure organization for open scholarship dedicated to the publication of open bibliographic and citation data by the use of Semantic Web (Linked Data) technologies. It is also engaged in advocacy for open citations, particularly by organizing the Workshops for Open Citations and Scholarly Metadata, and in its role as a key founding member of the Initiative for Open Citations (I4OC) and the Initiative for Open Abstracts (I4OA).","tags":["Data Analysis"],"title":"OpenCitations","type":"post"},{"authors":[""],"categories":["Software","Computational Neuroscience","Data Analysis","Human Neuroscience"],"content":"DIPY is the paragon 3D/4D+ imaging library in Python. Contains generic methods for spatial normalization, signal processing, machine learning, statistical analysis and visualization of medical images. Additionally, it contains specialized methods for computational anatomy including diffusion, perfusion and structural imaging.\nProject Author(s) https://github.com/dipy/dipy/graphs/contributors\nProject Links https://dipy.org\nProject Video https://www.youtube.com/channel/UCHnEuCRDGFOR5cfEo0nD3pw\n This post was automatically generated by anonymous\n ","date":1601078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601078400,"objectID":"c68c240ecd5ad9bb4135770ca88b2aac","permalink":"https://open-neuroscience.com/en/post/dipy/","publishdate":"2020-09-26T00:00:00Z","relpermalink":"/en/post/dipy/","section":"post","summary":"DIPY is the paragon 3D/4D+ imaging library in Python. Contains generic methods for spatial normalization, signal processing, machine learning, statistical analysis and visualization of medical images. Additionally, it contains specialized methods for computational anatomy including diffusion, perfusion and structural imaging.","tags":["Software","Computational Neuroscience","Data Analysis","Human Neuroscience"],"title":"DIPY","type":"post"},{"authors":[""],"categories":["Software","Computers","Simulations","Computational Neuroscience"],"content":"NeuroFedora is an initiative to provide a ready to use Fedora Linux based Free/Open source software platform for neuroscience. We believe that similar to Free software, science should be free for all to use, share, modify, and study. The use of Free software also aids reproducibility, data sharing, and collaboration in the research community. By making the tools used in the scientific process easier to use, NeuroFedora aims to take a step to enable this ideal.\nProject Author(s) NeuroFedora volunteers @ the Fedora project\nProject Links https://neuro.fedoraproject.org\n This post was automatically generated by Ankur Sinha (NeuroFedora SIG member)\n ","date":1601078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601078400,"objectID":"6427d7617e43de21755e6f76ccda87d9","permalink":"https://open-neuroscience.com/en/post/neurofedora/","publishdate":"2020-09-26T00:00:00Z","relpermalink":"/en/post/neurofedora/","section":"post","summary":"NeuroFedora is an initiative to provide a ready to use Fedora Linux based Free/Open source software platform for neuroscience. We believe that similar to Free software, science should be free for all to use, share, modify, and study.","tags":["Software","Computers","Simulations","Computational Neuroscience"],"title":"NeuroFedora","type":"post"},{"authors":[""],"categories":["Software","Data Analysis","Computers"],"content":"Many excellent brain atlases exist for different species. Some of them have an API (application programming interface) to allow users to interact with the data programmatically (e.g. the excellent Allen Mouse Brain Atlas), but many do not, and there is no consistent way to process data from multiple sources.\nThe brainglobe atlas API (BG-AtlasAPI) deals with this problem by providing a common interface for programmers to download and process atlas data from multiple sources.\nProject Author(s) Adam Tyson; Federico Claudi; Luigi Petrucco\nProject Links https://github.com/brainglobe/bg-atlasapi\n This post was automatically generated by Adam Tyson\n ","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598140800,"objectID":"5d6fbddc038d37af7fb3f4c7b5091752","permalink":"https://open-neuroscience.com/en/post/brainglobe_atlas_api/","publishdate":"2020-08-23T00:00:00Z","relpermalink":"/en/post/brainglobe_atlas_api/","section":"post","summary":"Many excellent brain atlases exist for different species. Some of them have an API (application programming interface) to allow users to interact with the data programmatically (e.g. the excellent Allen Mouse Brain Atlas), but many do not, and there is no consistent way to process data from multiple sources.","tags":["Software","Data Analysis","Computers"],"title":"Brainglobe atlas API","type":"post"},{"authors":[""],"categories":["Hardware","Molecular biology","Electric stimulation","Software"],"content":"Culture Shock is an open-source electroporator that was developed through internet based collaboration, starting on the DIYbio Google Group. It is an evolution on the traditional capacitive discharge circuit topology, instead using pulsed induction to enable a programmable waveform as well as reduce the size, weight, and cost of the equipment. With all these benefits, we hope to reduce the burden of laboratory consumables for DNA transformation and electrofusion procedures, where chemical supplies are currently relied on. The added benefit of programmability allows many cell types to be manipulated by altering the voltage level, or even giving the voltage profile a particular shape.\nProject Author(s) John Griessen; Nathan McCorkle; Bryan Bishop\nProject Links https://github.com/kanzure/culture_shock\n This post was automatically generated by Nathan McCorkle\n ","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598140800,"objectID":"a84f11cd3414573cc09b6a3034321606","permalink":"https://open-neuroscience.com/en/post/culture_shock/","publishdate":"2020-08-23T00:00:00Z","relpermalink":"/en/post/culture_shock/","section":"post","summary":"Culture Shock is an open-source electroporator that was developed through internet based collaboration, starting on the DIYbio Google Group. It is an evolution on the traditional capacitive discharge circuit topology, instead using pulsed induction to enable a programmable waveform as well as reduce the size, weight, and cost of the equipment.","tags":["Hardware","Molecular biology","Electric stimulation","Software"],"title":"culture_shock","type":"post"},{"authors":[""],"categories":["Software, Data Analysis","Microscopes, Molecular biology","Tutorials \u0026 learning portals","Fluorescence"],"content":"WholeBrain is a software to create anatomical maps. With a code base in C/C++ with wrappers to R and JavaScript/WASM.\nThe purpose of WholeBrain is to provide a user-friendly and efficient way for scientist with minimal knowledge of computers to create anatomical maps and integrate this information with behavioral and physiological data for sharing on the web.\nWholeBrain is conceived and created by Daniel Fürth, CSHL.\nQuick question about something you think can be resolved quite fast? Then just go to the gitter room and chat with me: https://gitter.im/tractatus/Lobby\nProject Author(s) Daniel Fürth\nProject Links https://github.com/tractatus/wholebrain/\n This post was automatically generated by Daniel Fürth\n ","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"2a227098737b109886627600520fe406","permalink":"https://open-neuroscience.com/en/post/wholebrain/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/en/post/wholebrain/","section":"post","summary":"WholeBrain is a software to create anatomical maps. With a code base in C/C++ with wrappers to R and JavaScript/WASM.\nThe purpose of WholeBrain is to provide a user-friendly and efficient way for scientist with minimal knowledge of computers to create anatomical maps and integrate this information with behavioral and physiological data for sharing on the web.","tags":["Software, Data Analysis","Microscopes, Molecular biology","Tutorials \u0026 learning portals","Fluorescence"],"title":"WholeBrain","type":"post"},{"authors":[""],"categories":["Software","Data Analysis","Other"],"content":"brainrender is a python package for the visualization of three dimensional neuro-anatomical data. It can be used to render data from publicly available data set (e.g. Allen Brain atlas) as well as user generated experimental data. The goal of brainrender is to facilitate the exploration and dissemination of neuro-anatomical data by providing a user-friendly platform to create high-quality 3D renderings.\nProject Author(s) Federico Claudi\nProject Links https://github.com/BrancoLab/BrainRender\n This post was automatically generated by Federico Claudi\n ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596067200,"objectID":"27bd95f119377806e6e7dea311d9e01a","permalink":"https://open-neuroscience.com/en/post/brainrender/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/en/post/brainrender/","section":"post","summary":"brainrender is a python package for the visualization of three dimensional neuro-anatomical data. It can be used to render data from publicly available data set (e.g. Allen Brain atlas) as well as user generated experimental data.","tags":["Software","Data Analysis","Other"],"title":"brainrender","type":"post"},{"authors":[""],"categories":["Software","Data Analysis"],"content":"JASP is a cross-platform statistical software program with a state-of-the-art graphical user interface. The JASP interface allows you to conduct statistical analyses in seconds, and without having to learn programming or risking a programming mistake. JASP is open-source and free of charge, and we provide it as a service to the community. JASP is statistically inclusive as it offers both frequentist and Bayesian analysis methods.\nProject Author(s) The JASP Team\nProject Links https://jasp-stats.org/\nProject Video https://www.youtube.com/watch?v=HxqB7CUA-XI\n This post was automatically generated by EJ Wagenmakers\n ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596067200,"objectID":"c190dc13687217a7ceb0a41d9dc9ddce","permalink":"https://open-neuroscience.com/en/post/jasp/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/en/post/jasp/","section":"post","summary":"JASP is a cross-platform statistical software program with a state-of-the-art graphical user interface. The JASP interface allows you to conduct statistical analyses in seconds, and without having to learn programming or risking a programming mistake.","tags":["Software","Data Analysis"],"title":"JASP","type":"post"},{"authors":[""],"categories":["Hardware","Behaviour","Benchtop","Other"],"content":"PiDose is an open-source tool for scientists performing drug administration experiments with mice. It allows for automated daily oral dosing of mice over long time periods (weeks to months) without the need for experimenter interaction and handling. To accomplish this, a small 3D-printed chamber is mounted adjacent to a regular mouse home-cage, with an opening in the cage to allow animals to freely access the chamber.\nThe chamber is supported by a load cell, and does not contact the cage but sits directly next to the entrance opening. Prior to treatment, mice have a small RFID capsule implanted subcutaneously, and when they enter the chamber they are detected by an RFID reader. While the mouse is in the chamber, readings are taken from the load cell in order to determine the mouse\u0026rsquo;s bodyweight. At the opposite end of the chamber from the entrance, a nose-poke port accesses a spout which dispenses drops from two separate liquid reservoirs. This spout is wired to a capacitive touch sensor controller in order to detect licks, and delivers liquid drops in response to licking.\nEach day, an average weight is calculated for each mouse and a drug dosage is determined based on this. When a mouse licks at the spout it dispenses either regular drinking water or a drop of drug solution depending on if they have received their daily dosage or not. All components are controlled by a Python script running on a Raspberry Pi.\nProject Author(s) Cameron Woodard; Wissam Nasrallah; Bahram Samiei; Tim Murphy; Lynn Raymond\nProject Links https://osf.io/rpyfm/\n This post was automatically generated by Cameron Woodard\n ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596067200,"objectID":"ecde8fee0065711249a807ce31f3cb1a","permalink":"https://open-neuroscience.com/en/post/pidose/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/en/post/pidose/","section":"post","summary":"PiDose is an open-source tool for scientists performing drug administration experiments with mice. It allows for automated daily oral dosing of mice over long time periods (weeks to months) without the need for experimenter interaction and handling.","tags":["Hardware","Behaviour","Benchtop","Other"],"title":"PiDose","type":"post"},{"authors":[""],"categories":["Behaviour","Hardware","Software"],"content":"pyControl is a system of open source hardware and software for controlling behavioural experiments, built around the Micropython microcontroller.\npyControl makes it easy to program complex behavioural tasks using a clean, intuitive, and flexible syntax for specifying tasks as state machines. User created task definition files, written in Python, run directly on the microcontroller, supported by pyControl framework code. This gives users the power and simplicity of Python for specifying task behaviour, while allowing advanced users low-level access to the microcontroller hardware.\npyControl hardware consists of a breakout board and a set of devices such as nose-pokes, audio boards, LED drivers, rotary encoders and stepper motor controllers that are connected to the breakout board to create behavioural setups.\nProject Author(s) Thomas Akam\nProject Links https://pycontrol.readthedocs.io\n This post was automatically generated by Thomas Akam\n ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596067200,"objectID":"db0171451263e0fd10469953f4fa5db3","permalink":"https://open-neuroscience.com/en/post/pycontrol/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/en/post/pycontrol/","section":"post","summary":"pyControl is a system of open source hardware and software for controlling behavioural experiments, built around the Micropython microcontroller.\npyControl makes it easy to program complex behavioural tasks using a clean, intuitive, and flexible syntax for specifying tasks as state machines.","tags":["Behaviour","Hardware","Software"],"title":"pyControl","type":"post"},{"authors":[""],"categories":["Hardware","Software","Fluorescence"],"content":"pyPhotometry is system of open source, Python based, hardware and software for neuroscience fiber photometry data acquisition, consisting of an acquisition board and graphical user interface.\npyPhotometry supports data aquisition from two analog and two digital inputs, and control of two LEDs via built in LED drivers with an adjustable 0-100mA output. The system supports time-division multiplexed illumination which allows fluoresence evoked by different excitation wavelengths to be independenly readout from a single photoreciever signal.\nProject Author(s) Thomas Akam\nProject Links https://pyphotometry.readthedocs.io\n This post was automatically generated by Thomas Akam\n ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596067200,"objectID":"9698862c794601ddd80391b88e45e95a","permalink":"https://open-neuroscience.com/en/post/pyphotometry/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/en/post/pyphotometry/","section":"post","summary":"pyPhotometry is system of open source, Python based, hardware and software for neuroscience fiber photometry data acquisition, consisting of an acquisition board and graphical user interface.\npyPhotometry supports data aquisition from two analog and two digital inputs, and control of two LEDs via built in LED drivers with an adjustable 0-100mA output.","tags":["Hardware","Software","Fluorescence"],"title":"pyPhotometry","type":"post"},{"authors":[""],"categories":["Behaviour","Software"],"content":"SLEAP (Social LEAP Estimates Animal Poses) is a multi-animal pose tracker based on deep learning. It is the successor of LEAP (Pereira et al., Nature Methods, 2019) and was designed to deal with the problem of tracking body landmarks of multiple freely interacting animals.\nUsing deep learning, SLEAP trains neural network models from few user annotations to enable highly accurate body part localization, grouping and tracking. It supports multiple neural network architectures, including pretrained state-of-the-art models and lightweight customizable architectures. SLEAP has been used successfully to track mice, fruit flies, bees and other species of animals under a variety of experimental and imaging conditions.\nThe software was designed to make it easy for users with no experience with deep learning through a fully featured GUI, as well as providing a rich functionality for advanced users seeking to develop a custom solution for their project. Tutorials and guides are available on our website (https://sleap.ai) detailing steps for easy installation (Windows/Mac/Linux), labeling a new project, training on the locally or on the cloud, and tracking new data.\nProject Author(s) Talmo Pereira; Joshua Shaevitz; Mala Murthy\nProject Links https://sleap.ai\nProject Video https://www.youtube.com/watch?v=zwCf1pGnBUw\n This post was automatically generated by Talmo Pereira\n ","date":1595721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595721600,"objectID":"4a439b49086899fa755e5d671a4eae61","permalink":"https://open-neuroscience.com/en/post/sleap/","publishdate":"2020-07-26T00:00:00Z","relpermalink":"/en/post/sleap/","section":"post","summary":"SLEAP (Social LEAP Estimates Animal Poses) is a multi-animal pose tracker based on deep learning. It is the successor of LEAP (Pereira et al., Nature Methods, 2019) and was designed to deal with the problem of tracking body landmarks of multiple freely interacting animals.","tags":["Behaviour","Software"],"title":"SLEAP","type":"post"},{"authors":[""],"categories":["Software","Data Analysis","Data Repositories","Computers"],"content":"NeuroImaging Tools \u0026amp; Resources Collaboratory is an award-winning free web-based resource that offers comprehensive information on an ever expanding scope of neuroinformatics software and data. Since debuting in 2007, NITRC has helped the neuroscience community make further discoveries using software and data produced from research that used to end up lost or disregarded.\nNITRC also provides free access to data and enables pay-per-use cloud-based access to unlimited computing power, enabling worldwide scientific collaboration with minimal startup and cost. NITRC’s scientific focus includes: MR, PET/SPECT, CT, EEG/MEG, optical imaging, clinical neuroimaging, computational neuroscience, and imaging genomics software tools, data, and computational resources.\nWith NITRC and its components—the Resources Registry (NITRC-R), Image Repository (NITRC-IR), and Computational Environment (NITRC-CE)—a researcher can obtain pilot or proof-of-concept data to validate a hypothesis for just a few dollars.\nProject Author(s) NITRC Development Team\nProject Links http://www.nitrc.org\n This post was automatically generated by David Kennedy\n ","date":1595462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595462400,"objectID":"7bd59f27d36e8c7c51a86cb3941d5365","permalink":"https://open-neuroscience.com/en/post/neuroimaging_informatics_tools_and_resources_collaboratory_nitrc/","publishdate":"2020-07-23T00:00:00Z","relpermalink":"/en/post/neuroimaging_informatics_tools_and_resources_collaboratory_nitrc/","section":"post","summary":"NeuroImaging Tools \u0026amp; Resources Collaboratory is an award-winning free web-based resource that offers comprehensive information on an ever expanding scope of neuroinformatics software and data. Since debuting in 2007, NITRC has helped the neuroscience community make further discoveries using software and data produced from research that used to end up lost or disregarded.","tags":["Software","Data Analysis","Data Repositories","Computers"],"title":"Neuroimaging Informatics Tools and Resources Collaboratory (NITRC)","type":"post"},{"authors":[""],"categories":["Software","Optogenetics","Behaviour","Hardware"],"content":"PiVR is a system that allows experimenters to immerse small animals into virtual realities. The system tracks the position of the animal and presents light stimulation according to predefined rules, thus creating a virtual landscape in which the animal can behave. By using optogenetics, we have used PiVR to present fruit fly larvae with virtual olfactory realities, adult fruit flies with a virtual gustatory reality and zebrafish larvae with a virtual light gradient.\nPiVR operates at high temporal resolution (70Hz) with low latencies (\u0026lt;30 milliseconds) while being affordable (\u0026lt;US$500) and easy to build (\u0026lt;6 hours). Through extensive documentation (www.PiVR.org), this tool was designed to be accessible to a wide public, from high school students to professional researchers studying systems neuroscience in academia.\nThe project is open source (BSD-3) and the documented code written in the freely available programming language Python. We hope that PiVR will be adapted by advanced users for their particular needs, for example to create closed-loop experiments involving other sensory modalities (e.g., sound/vibration) through the use of PWM controllable devices. We envision PiVR to be used as the central module when creating virtual realities for a variety of sensory modalities. This ‘PiVR module’ takes care of detecting the animal and presenting the appropriate PWM signal that is then picked up by the PWM controllable device installed by the user, for example to produce a sound whenever an animal enters a pre-defined region.\nIn short, PiVR is a powerful and affordable experimental platform allowing experimenters to create a wide array of virtual reality experiments. Our hope is that PiVR will be adapted by several labs to democratize closed-loop experiments and, by standardizing image quality and the animal detection algorithm, increase reproducibility.\nProject Author(s) David Tadres; Matthieu Louis\nProject Links http://www.PiVR.org\nProject Video https://www.youtube.com/watch?v=w5tIG6B6FWo\n This post was automatically generated by David Tadres\n ","date":1595462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595462400,"objectID":"7d3cc9eeb464da0e64d95c6e1caf691b","permalink":"https://open-neuroscience.com/en/post/pivr/","publishdate":"2020-07-23T00:00:00Z","relpermalink":"/en/post/pivr/","section":"post","summary":"PiVR is a system that allows experimenters to immerse small animals into virtual realities. The system tracks the position of the animal and presents light stimulation according to predefined rules, thus creating a virtual landscape in which the animal can behave.","tags":["Software","Optogenetics","Behaviour","Hardware"],"title":"PiVR","type":"post"},{"authors":[""],"categories":["Data Analysis","Software","Tutorials \u0026 learning portals","Data Repositories"],"content":"ReproNim\u0026rsquo;s goal is to improve the reproducibility of neuroimaging science and extend the value of our national investment in neuroimaging research, while making the process easier and more efficient for investigators.\nReproNim delivers a reproducible analysis framework comprised of components that include: 1) data and software discovery; 2) implementation of standardized description of data, results and workflows; 3) development of execution options that facilitates operation in all computational environments; 4) provision of training and education to the community.\nAll components of the framework are intended to foster continued use and development of the reproducible and generalizable framework in neuroimaging research.\nProject Author(s) The ReproNim Development Team\nProject Links https://github.com/ReproNim\n This post was automatically generated by David Kennedy\n ","date":1595462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595462400,"objectID":"054b326e3e053a15e28dde2a2f46e738","permalink":"https://open-neuroscience.com/en/post/repronim_a_center_for_reproducible_neuroimaging_computation/","publishdate":"2020-07-23T00:00:00Z","relpermalink":"/en/post/repronim_a_center_for_reproducible_neuroimaging_computation/","section":"post","summary":"ReproNim\u0026rsquo;s goal is to improve the reproducibility of neuroimaging science and extend the value of our national investment in neuroimaging research, while making the process easier and more efficient for investigators.","tags":["Data Analysis","Software","Tutorials \u0026 learning portals","Data Repositories"],"title":"ReproNim: A Center for Reproducible Neuroimaging Computation","type":"post"},{"authors":[""],"categories":["Behaviour","Data Analysis","Software","Data Repositories"],"content":"Several excellent computational frameworks exist that enable high-throughput and consistent tracking of freely moving unmarked animals. SimBA introduce and distribute a plug-and play pipeline that enables users to use these pose-estimation approaches in combination with behavioral annotation for the generation of supervised machine-learning behavioral predictive classifiers.\nSimBA was developed for the analysis of complex social behaviors, but includes the flexibility for users to generate predictive classifiers across other behavioral modalities with minimal effort and no specialized computational background.\nSimBA has a variety of extended functions for large scale batch video pre-processing, generating descriptive statistics from movement features, and interactive modules for user-defined regions of interest and visualizing classification probabilities and movement patterns.\nProject Author(s) Simon Nilsson: Jia Jie Chhong; Sophia Hwang; Nastacia Goodwin; Sam A Golden\nProject Links https://github.com/sgoldenlab/simba\nProject Video https://www.youtube.com/watch?v=Frq6mMcaHBc\u0026amp;list=PLi5Vwf0hhy1R6NDQJ3U28MOUJPfl2YWYl\u0026amp;index=2\u0026amp;t=0s\n This post was automatically generated by Simon Nilsson\n ","date":1595462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595462400,"objectID":"c7a1eb5c043ea668a2003ccf73861e71","permalink":"https://open-neuroscience.com/en/post/simple_behavioral_analysis_simba/","publishdate":"2020-07-23T00:00:00Z","relpermalink":"/en/post/simple_behavioral_analysis_simba/","section":"post","summary":"Several excellent computational frameworks exist that enable high-throughput and consistent tracking of freely moving unmarked animals. SimBA introduce and distribute a plug-and play pipeline that enables users to use these pose-estimation approaches in combination with behavioral annotation for the generation of supervised machine-learning behavioral predictive classifiers.","tags":["Behaviour","Data Analysis","Software","Data Repositories"],"title":"Simple Behavioral Analysis (SimBA)","type":"post"},{"authors":[""],"categories":["Data Analysis","Computational Neuroscience","Calcium Imaging","Animal electrophysiology"],"content":"DataJoint is an open-source library for managing and sharing scientific data pipelines in Python and Matlab.\nDataJoint allows creating and sharing computational data pipelines, which are defined as databases and analysis code for executing steps of activities for data collection and analysis. For example, many neuroscience studies are organized around DataJoint pipelines that start with basic information about the experiment, then ingest acquired data, and then perform processing, analysis, and visualization of results. The entire pipeline is diagrammed as a graph where each node is a table in the database with a corresponding class in the programming language; together they define the data structure and computations.\nDataJoint key features include:\n access to shared data pipelines in a relational database (MySQL-compatible) from Python, Matlab, or both. data integrity and consistency based founded on the relational data model and transactions an intuitive data definition language for pipeline design a diagramming notation to visualize data structure and dependencies a serialization framework: storing large numerical arrays and other scientific data in a language-independent way a flexible query language to retrieve precise cross-sections of data in a desired format automated execution of computational jobs, with built-in job management for distributed computing managed storage of large data objects outside the database  Project Author(s) Dimitri Yatsenko; Edgar Walker; Fabian Sinz; Christopher Turner; Raphael Guzman\nProject Links https://datajoint.io\n This post was automatically generated by Dimitri Yatsenko\n ","date":1595116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595116800,"objectID":"a5f6fe6b93d8f3396df84a464ba402bf","permalink":"https://open-neuroscience.com/en/post/datajoint/","publishdate":"2020-07-19T00:00:00Z","relpermalink":"/en/post/datajoint/","section":"post","summary":"DataJoint is an open-source library for managing and sharing scientific data pipelines in Python and Matlab.\nDataJoint allows creating and sharing computational data pipelines, which are defined as databases and analysis code for executing steps of activities for data collection and analysis.","tags":["Data Analysis","Computational Neuroscience","Calcium Imaging","Animal electrophysiology"],"title":"DataJoint","type":"post"},{"authors":[""],"categories":["Software","Animal electrophysiology","Calcium Imaging","Behaviour, Other"],"content":"Neurodata Without Borders is a data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build analysis tools for neurophysiology data. NWB is designed to store a variety of neurophysiology data, including data from intracellular and extracellular electrophysiology experiments, data from optical physiology experiments, and tracking and stimulus data.\nThe NWB team consists of neuroscientists and software developers who recognize that adoption of a unified data format is an important step toward breaking down the barriers to data sharing in neuroscience.\nProject Author(s) Andrew Tritt; Ryan Ly; Ben Dichter; Oliver Ruebel\nProject Links https://www.nwb.org/\nProject Video https://youtu.be/vfQsMyl0HQI\n This post was automatically generated by Ben Dichter\n ","date":1595116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595116800,"objectID":"d30d081409b42277365a0894fd5d3100","permalink":"https://open-neuroscience.com/en/post/neurodata_without_borders/","publishdate":"2020-07-19T00:00:00Z","relpermalink":"/en/post/neurodata_without_borders/","section":"post","summary":"Neurodata Without Borders is a data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build analysis tools for neurophysiology data. NWB is designed to store a variety of neurophysiology data, including data from intracellular and extracellular electrophysiology experiments, data from optical physiology experiments, and tracking and stimulus data.","tags":["Software","Animal electrophysiology","Calcium Imaging","Behaviour, Other"],"title":"Neurodata Without Borders","type":"post"},{"authors":[""],"categories":["Hardware","Benchtop","Computers","Software"],"content":"OpenDrop a modular, open source digital microfludics platform for research purposes. The device uses recent electro-wetting technology to control small droplets of liquids. Potential applications are lab on a chip devices for automating processes of digital biology.\nThe OpenDrop V4 is modular electrowetting controller. The driver board is equipped with a connector that can host a circuit board cartridge with a 14×8 electrode array and 4 reservoirs. The liquids stay on a thin, hydrophobic foil laminated to the circuit board . The device is powered from USB though an included USB-C cable. All the voltage level are generated on the device and can be set with the built in soft menu from 150-300 Volts, DC or AC.\nOpenDrop Cartridges The modular concepts of the OpenDrop V4 allows different configurations of cartridges: A gold coated electrode array board that can be coated with any dielectric layer and hydrophobic coating to make cartridges for topless digital microfluidic applications using readily available materials.The OpenDrop V4 Cartridge is a close-cell cartridge capable of “move, mix, split and reservoir dispensing”. The 4×8 electrode array and 4 reservoirs are laminated with a 15um ETFE foil, hydrophobic coating and ITO top cover.\nProgramming The OpenDrop V4 can be operated standalone and droplets can be moved through the built in joystick. A control software to program sequences of patterns from a computer is available as a free download. The board is also compatible with Adafruit Feather M0 controller boards and can be reprogrammed through the free Arduino IDE for custom specific applications. A sample code with the instruction to activate electrodes can be found on the OpenDrop GitHub.\nFeatures:\n Modular Cartridge System - Connector to connect electrode board with up to 128 channels - Gold coated 14×8 electrodes array, 2.75 mm x 2.75 mm in size, 4mil gaps Reservoirs – the new electrode array features 4 CT-type reservoirs AC and DC voltage generated on the device form USB power. True AC voltage driving capability (up to 300VAC). 32bit AVR SAMD21G18 microprocessor with plenty of memory and power - Electronic settings for voltage level, frequency and AC/DC selection - Electronic reading of actual voltage level - One connector for communication and powering (USB-C) - Optical isolation of the high-voltage electronics trough opto-couplers and PhotoMOS - New polyphonic audio amplifier and speaker (it’s a synth!) - Cartridge presence detection - Feedback amplifier - Super flat OLED Display - Nice joystick and 2 buttons, 3 LEDs - Reset button - All files open source, designed on KiCAD  Project Author(s) MSc Urs Gaudenz\nProject Links http://www.gaudi.ch/OpenDrop/\nProject Video https://www.youtube.com/watch?v=TY97QfWY6J4\n This post was automatically generated by Anonymous\n ","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594771200,"objectID":"92d9a9992b10247700ea899d9c492bb0","permalink":"https://open-neuroscience.com/en/post/opendrop_digital_microfluidics_platform/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/en/post/opendrop_digital_microfluidics_platform/","section":"post","summary":"OpenDrop a modular, open source digital microfludics platform for research purposes. The device uses recent electro-wetting technology to control small droplets of liquids. Potential applications are lab on a chip devices for automating processes of digital biology.","tags":["Hardware","Benchtop","Computers","Software"],"title":"OpenDrop Digital Microfluidics Platform","type":"post"},{"authors":[""],"categories":["Software","Behaviour","Hardware","Benchtop"],"content":"Stytra, a flexible, open-source software package, written in Python and designed to cover all the general requirements involved in larval zebrafish behavioral experiments.\nIt provides timed stimulus presentation, interfacing with external devices and simultaneous real-time tracking of behavioral parameters such as position, orientation, tail and eye motion in both freely-swimming and head-restrained preparations.\nStytra logs all recorded quantities, metadata, and code version in standardized formats to allow full provenance tracking, from data acquisition through analysis to publication.\nThe package is modular and expandable for different experimental protocols and setups. We also provide complete documentation with examples for extending the package to new stimuli and hardware, as well as a schema and parts list for behavioural setups.\nThe software can be used in the context of calcium imaging experiments by interfacing with other acquisition devices.\nOur aims are to enable more laboratories to easily implement behavioral experiments, as well as to provide a platform for sharing stimulus protocols that permits easy reproduction of experiments and straightforward validation.\nProject Author(s) Vilim Stih; Luigi Petrucco\nProject Links https://github.com/portugueslab/stytra\n This post was automatically generated by Anonymous\n ","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594771200,"objectID":"ec4f56ebc7a319ca1fb2e62831144c22","permalink":"https://open-neuroscience.com/en/post/stytra/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/en/post/stytra/","section":"post","summary":"Stytra, a flexible, open-source software package, written in Python and designed to cover all the general requirements involved in larval zebrafish behavioral experiments.\nIt provides timed stimulus presentation, interfacing with external devices and simultaneous real-time tracking of behavioral parameters such as position, orientation, tail and eye motion in both freely-swimming and head-restrained preparations.","tags":["Software","Behaviour","Hardware","Benchtop"],"title":"Stytra","type":"post"},{"authors":[""],"categories":["Hardware","Software","Journal","Other"],"content":"We present an open-source anthropomorphic robot hand system called HRI hand. Our robot hand system was developed with a focus on the end-effector role of the collaborative robot manipulator. HRI hand is a research platform that can be built at a lower price (approximately $500, using only 3D printing) than commercial end-effectors. Moreover, it was designed as a two four-bar linkage for the under-actuated mechanism and provides pre-shaping motion similar to the human hand prior to touching an object. A URDF, python node, and rviz package is also provided to support the Robot Operating System (ROS). All hardware CAD design files and software source codes have been released and can be easily assembled and modified. The system proposed in this paper is developed with a five-finger structure, but each finger is modularized, so it can be developed with end-effectors of various shapes depending on the shape of the palm.\nProject Author(s) Hyeonjun Park; Donghan Kim\nProject Links https://github.com/MrLacuqer/HRI-hand-firmware.git\nProject Video https://youtu.be/c5Ry3tl9FVw\n This post was automatically generated by Andre M Chagas\n ","date":1594684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594684800,"objectID":"ee3391a6d54fe8c83e4ca3e7429966bd","permalink":"https://open-neuroscience.com/en/post/an_open-source_anthropomorphic_robot_hand_system_hri_hand/","publishdate":"2020-07-14T00:00:00Z","relpermalink":"/en/post/an_open-source_anthropomorphic_robot_hand_system_hri_hand/","section":"post","summary":"We present an open-source anthropomorphic robot hand system called HRI hand. Our robot hand system was developed with a focus on the end-effector role of the collaborative robot manipulator. HRI hand is a research platform that can be built at a lower price (approximately $500, using only 3D printing) than commercial end-effectors.","tags":["Hardware","Software","Journal","Other"],"title":"An Open-source Anthropomorphic Robot Hand System: HRI Hand","type":"post"},{"authors":[""],"categories":["Hardware"],"content":"Researchers in the biomedical area are always involved in methodologies comprising several processes that are repetitive and time-consuming; these researchers can take advantage of this time for other more important things.\nFor many years, the trend for this type of problem has been automation. One of the routine methodologies used by researchers in broad areas of basic investigation is the Western blot technique.\nThis method allows the detection through specific antibodies and the eventual quantification of the protein of interest in different biological lysates transferred onto a suitable membrane. This methodology involves several repetitive processes; one of them is the washing of blots after incubations with primary and secondary antibodies.\nThe present device has been designed to automate this process at a low cost. Researchers must use several tools to carry out the same task at a much higher price, and more importantly, in a time-consuming process. Although it is designed for the Western blot, it can be optimized for other cyclic tasks.\nProject Author(s) Jorge Bravo-Martinez\nProject Links http://dx.doi.org/10.17632/xcvckyc9mh.1\n This post was automatically generated by Jorge Bravo-Martinez\n ","date":1594684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594684800,"objectID":"09b508d499a1b2e524a1c4fc8bd4ffd5","permalink":"https://open-neuroscience.com/en/post/open_source_automated_western_blot_processor/","publishdate":"2020-07-14T00:00:00Z","relpermalink":"/en/post/open_source_automated_western_blot_processor/","section":"post","summary":"Researchers in the biomedical area are always involved in methodologies comprising several processes that are repetitive and time-consuming; these researchers can take advantage of this time for other more important things.","tags":["Hardware"],"title":"Open Source Automated Western Blot Processor","type":"post"},{"authors":[""],"categories":["Data Repositories","Human Neuroscience"],"content":"A free and open platform for sharing MRI, MEG, EEG, iEEG, and ECoG data.\nWith OpenNeuro, you can:\n Browse and explore public datasets and analyses from a wide range of global contributors. Our collection of public datasets continues to grow as more and more become BIDS compatible. Download and use public data to create new datasets and run your own analyses. Privately share your data so your colleagues can view and edit your work. Publish your dataset where anyone can view, download, and run analyses on it. Create snapshots of your datasets to ensure past analyses remain reproducible as your datasets grow and change. Publish any of your snapshots while you continue work on your original data behind the scenes. Explore your published OpenNeuro dataset using BrainLife\u0026rsquo;s computing network. Utilize their community driven apps to run a variety of analysis and processing software in the browser.  Project Author(s) Russell A. Poldrack; Krzysztof Jacek Gorgolewski\nProject Links https://openneuro.org/\nProject Video https://www.youtube.com/watch?v=FK_c1x1Pilk\n This post was automatically generated by Elizabeth DuPre\n ","date":1594684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594684800,"objectID":"c3e3343ef9e974e92cf75f972e51ca01","permalink":"https://open-neuroscience.com/en/post/openneuro/","publishdate":"2020-07-14T00:00:00Z","relpermalink":"/en/post/openneuro/","section":"post","summary":"A free and open platform for sharing MRI, MEG, EEG, iEEG, and ECoG data.\nWith OpenNeuro, you can:\n Browse and explore public datasets and analyses from a wide range of global contributors.","tags":["Data Repositories","Human Neuroscience"],"title":"OpenNeuro","type":"post"},{"authors":[""],"categories":["Hardware"],"content":"The project overall aim is to provide cost efficient solution to drive microfluidics systems for e.g. cell culture and organ on a chip applications. Pumps, valves and other accessories are ofter expensive to buy or very expensive to custom made. The 8-channel FAST pump is a 3D printed pump that uses some off the shelf parts (steel pins and ball bearings) and is easily fabricated and assembled. A step by step protocol is published (https://www.sciencedirect.com/science/article/pii/S2468067220300249). The link to the picture is from this publication. The pump is far cheaper and smaller than commercial pumps and still has at least as good as or better pump performance. The 8-channel pump is excellent for use in parallel cell culture applications.\nProject Author(s) Alexander Jönsson; Arianna Toppi; Martin Dufva\nProject Links https://www.sciencedirect.com/science/article/pii/S2468067220300249\n This post was automatically generated by Martin Dufva\n ","date":1594684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594684800,"objectID":"00035094b4a41c7ffbd8d030e0858ed8","permalink":"https://open-neuroscience.com/en/post/small_cost_efficient_3d_printed_peristaltic_pumps/","publishdate":"2020-07-14T00:00:00Z","relpermalink":"/en/post/small_cost_efficient_3d_printed_peristaltic_pumps/","section":"post","summary":"The project overall aim is to provide cost efficient solution to drive microfluidics systems for e.g. cell culture and organ on a chip applications. Pumps, valves and other accessories are ofter expensive to buy or very expensive to custom made.","tags":["Hardware"],"title":"Small cost efficient 3D printed peristaltic pumps","type":"post"},{"authors":[""],"categories":["Hardware, Other"],"content":"Organ on a chip is typically difficult to achieve due to large technical challenges such as fabrication of chips and systems and biological challenges such as co-culture of cells. In this project we have developed a system to stack 12 well plates inserts on top of each other where each plate holds a tissue. We illustrated this approach by creating an intestine model in the top plate, a blood vessel model in the middle plate and a liver model in the lower plate. The respective insert contain specific cell types are developed independently and just before use, the plates are stacked on top of each other where in this case, the complete assembly models the first pass metabolism. The independent development circumvent long term co-culture and medium incompatibilities. The plates are 3D printed in a biocompatible resin and modified with a disc of gelatine where cell are cultured either on top (epithelial and endothelial cells) or inside (hepatocytes). Hence there is diffusional communication from intestine to the lived provided that studies compounds can penetrate the respective barrier. The simple to use system can be modified with any cell type including stem cell organoids and likely neuronal cells.\nProject Author(s) Martin Dufva; Morten Jepsen; Anja Boisen; Line Hagner Nielsen; Chiara Mazzoni; Andreas Willumsen\nProject Links https://onlinelibrary.wiley.com/doi/abs/10.1002/adbi.201900289\n This post was automatically generated by Martin Dufva\n ","date":1594684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594684800,"objectID":"84fbf3f71d9684aba9d01457ebefcdc7","permalink":"https://open-neuroscience.com/en/post/stackable_titre_plates_for_organ_on_a_chip_applications/","publishdate":"2020-07-14T00:00:00Z","relpermalink":"/en/post/stackable_titre_plates_for_organ_on_a_chip_applications/","section":"post","summary":"Organ on a chip is typically difficult to achieve due to large technical challenges such as fabrication of chips and systems and biological challenges such as co-culture of cells. In this project we have developed a system to stack 12 well plates inserts on top of each other where each plate holds a tissue.","tags":["Hardware, Other"],"title":"Stackable titre plates for organ on a chip applications","type":"post"},{"authors":[""],"categories":["Data Analysis","Software","Fluorescence"],"content":"cellfinder is software from the Margrie Lab at the Sainsbury Wellcome Centre for automated 3D cell detection and registration of whole-brain images (e.g. serial two-photon or lightsheet imaging).\nIt’s a work in progress, but cellfinder can:\n Detect labelled cells in 3D in whole-brain images (many hundreds of GB) Register the image to an atlas (such as the Allen Mouse Brain Atlas) Segment the brain based on the reference atlas Calculate the volume of each brain area, and the number of labelled cells within it Transform everything into standard space for analysis and visualisation  Project Author(s) Adam Tyson\nProject Links https://github.com/SainsburyWellcomeCentre/cellfinder\n This post was automatically generated by Adam Tyson\n ","date":1594512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594512000,"objectID":"98765387b6b5cfc70bd1e52a04d1f904","permalink":"https://open-neuroscience.com/en/post/cellfinder/","publishdate":"2020-07-12T00:00:00Z","relpermalink":"/en/post/cellfinder/","section":"post","summary":"cellfinder is software from the Margrie Lab at the Sainsbury Wellcome Centre for automated 3D cell detection and registration of whole-brain images (e.g. serial two-photon or lightsheet imaging).\nIt’s a work in progress, but cellfinder can:","tags":["Data Analysis","Software","Fluorescence"],"title":"cellfinder","type":"post"},{"authors":[""],"categories":["Software","Behaviour","Data Analysis","Tutorials \u0026 learning portals"],"content":"DeepLabCut™ is an efficient method for 3D markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results (i.e. you can match human labeling accuracy) with minimal training data (typically 50-200 frames). We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors.\nThe package is open source, fast, robust, and can be used to compute 3D pose estimates. Please see the original paper and the latest work below. This package is collaboratively developed by the Mathis Group \u0026amp; Mathis Lab at EPFL/Harvard.\nThe code is freely available and easy to install in a few clicks with Anaconda (and pypi). Please see instructions on deeplabcut.org. We also provide a very easy to use GUI interface, and a step-by-step user guide!\nProject Author(s) Mackenzie Mathis, Alexander Mathis \u0026amp; contributors\nProject Links http://deeplabcut.org/\nProject Video https://www.youtube.com/channel/UC2HEbWpC_1v6i9RnDMy-dfA\n This post was automatically generated by Mackenzie Mathis\n ","date":1594512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594512000,"objectID":"bc3df7004664e3b2977a1bf04ebe9a7e","permalink":"https://open-neuroscience.com/en/post/deeplabcut/","publishdate":"2020-07-12T00:00:00Z","relpermalink":"/en/post/deeplabcut/","section":"post","summary":"DeepLabCut™ is an efficient method for 3D markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results (i.e. you can match human labeling accuracy) with minimal training data (typically 50-200 frames).","tags":["Software","Behaviour","Data Analysis","Tutorials \u0026 learning portals"],"title":"DeepLabCut","type":"post"},{"authors":[""],"categories":["Software","Data Analysis","Human electrophysiology","Human Neuroscience"],"content":"MNE is a software package for processing electrophysiological signals primarily from magnetoencephalographic (MEG) and electroencephalographic (EEG) recordings, and more recently sEEG, ECoG and fNIRS. It provides a comprehensive solution for data preprocessing, forward modeling (with boundary element models), distributed source imaging, time–frequency analysis, non-parametric multivariate statistics, multivariate pattern analysis, and connectivity estimation. Importantly, this package allows all of these analyses to be applied in both sensor or source space. MNE is developed by an international team, with particular care for computational efficiency, code quality, and readability, as well as the common goal of facilitating reproducibility in neuroscience.\nProject Author(s) Alexandre Gramfort;Eric Larson;Denis Engemann;Daniel Strohmeier;Christian Brodbeck;Roman Goj;Mainak Jas;Teon Brooks;Lauri Parkkonen;Matti Hämäläinen;Jaakko Leppakangas;Jona Sassenhagen;Jean-Rémi King;Daniel McCloy;Marijn van Vliet;Clemens Brunner;Chris Holdgraf;Martin Luessi;Joan Massich;Guillaume Favelier;Andrew R. Dykstra;Mikolaj Magnuski;Stefan Appelhoff;Britta Westner;Richard Höchenberger;Robert Luke;Luke Bloy;Thomas Hartmann;Olaf Hauk;Adam Li\nProject Links https://mne.tools\n This post was automatically generated by Anonymous\n ","date":1594512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594512000,"objectID":"b96d0bc5e257a2536ca20f8db22b206e","permalink":"https://open-neuroscience.com/en/post/mne-python/","publishdate":"2020-07-12T00:00:00Z","relpermalink":"/en/post/mne-python/","section":"post","summary":"MNE is a software package for processing electrophysiological signals primarily from magnetoencephalographic (MEG) and electroencephalographic (EEG) recordings, and more recently sEEG, ECoG and fNIRS. It provides a comprehensive solution for data preprocessing, forward modeling (with boundary element models), distributed source imaging, time–frequency analysis, non-parametric multivariate statistics, multivariate pattern analysis, and connectivity estimation.","tags":["Software","Data Analysis","Human electrophysiology","Human Neuroscience"],"title":"MNE-Python","type":"post"},{"authors":[""],"categories":["Software","Data Analysis","Human Neuroscience"],"content":"Nilearn is a Python module for fast and easy statistical learning on NeuroImaging data. It leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.\nProject Author(s) https://github.com/orgs/nilearn/people\nProject Links http://nilearn.github.io/\n This post was automatically generated by Anonymous\n ","date":1594425600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594425600,"objectID":"d1e564228c1caad7fd122f15aad364ed","permalink":"https://open-neuroscience.com/en/post/nilearn/","publishdate":"2020-07-11T00:00:00Z","relpermalink":"/en/post/nilearn/","section":"post","summary":"Nilearn is a Python module for fast and easy statistical learning on NeuroImaging data. It leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.","tags":["Software","Data Analysis","Human Neuroscience"],"title":"Nilearn","type":"post"},{"authors":[""],"categories":["Hardware","Benchtop","Software"],"content":"The fruit fly, Drosophila melanogaster, continues to be one of the most widely used model organisms in biomedical research.\nThough chosen for its ease of husbandry, maintaining large numbers of stocks of fruit flies, as done by many laboratories, is labour-intensive.\nOne task which lends itself to automation is the production of the vials of food in which the flies are reared. Fly facilities typically have to generate several thousand vials of fly food each week to sustain their fly stocks.\nThe system presented here combines a cartesian coordinate robot with a peristaltic pump. The design of the robot is based on an open hardware CNC (computer numerical control) machine, and uses belt and pulley actuators for the X and Y axes, and a leadscrew actuator for the Z axis.\nCNC motion and operation of the peristaltic pump are controlled by grbl (https://github.com/gnea/grbl), an open source, embedded, G-code parser. Grbl is written in optimized C and runs directly on an Arduino. A Raspberry Pi is used to generate and stream G-code instructions to Grbl.\nA touch screen on the Raspberry Pi provides a graphical user interface to the system. Whilst the robot was built for the express purpose of filling vials of fly food, it could potentially be used for other liquid handling tasks in the laboratory.\nProject Author(s) Matt Wayland; Matthias Landgraf\nProject Links https://github.com/WaylandM/fly-food-robot\nProject Video https://doi.org/10.6084/m9.figshare.5175223.v1\n This post was automatically generated by Matt Wayland\n ","date":1594339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594339200,"objectID":"adad71905379555ebd40c26da5fea6b1","permalink":"https://open-neuroscience.com/en/post/a_cartesian_coordinate_robot_for_dispensing_fruit_fly_food/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/en/post/a_cartesian_coordinate_robot_for_dispensing_fruit_fly_food/","section":"post","summary":"The fruit fly, Drosophila melanogaster, continues to be one of the most widely used model organisms in biomedical research.\nThough chosen for its ease of husbandry, maintaining large numbers of stocks of fruit flies, as done by many laboratories, is labour-intensive.","tags":["Hardware","Benchtop","Software"],"title":"A Cartesian Coordinate Robot for Dispensing Fruit Fly Food","type":"post"},{"authors":[""],"categories":["Software","Behaviour","Human electrophysiology, Animal electrophysiology"],"content":"Bonsai is a high-performance, easy to use, and flexible visual programming language for designing closed-loop neuroscience experiments combining physiology and behaviour data.\nBonsai has allowed scientists with no previous programming experience to quickly develop their own experimental rigs and is also being increasingly used as a platform to integrate new open-source hardware and software from the experimental neuroscience community.\nProject Author(s) Gonçalo Lopes\nProject Links https://bonsai-rx.org/\n This post was automatically generated by Gonçalo Lopes\n ","date":1594339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594339200,"objectID":"d7cd802d1446eeb9918db36dd2729ddd","permalink":"https://open-neuroscience.com/en/post/bonsai/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/en/post/bonsai/","section":"post","summary":"Bonsai is a high-performance, easy to use, and flexible visual programming language for designing closed-loop neuroscience experiments combining physiology and behaviour data.\nBonsai has allowed scientists with no previous programming experience to quickly develop their own experimental rigs and is also being increasingly used as a platform to integrate new open-source hardware and software from the experimental neuroscience community.","tags":["Software","Behaviour","Human electrophysiology, Animal electrophysiology"],"title":"Bonsai","type":"post"},{"authors":[""],"categories":["Behaviour","Hardware","Software","Computers"],"content":"Ethoscopes are machines for high-throughput analysis of behavior in Drosophila and other animals.\nEthoscopes provide a software and hardware solution that is reproducible and easily scalable.\nThey perform, in real-time, tracking and profiling of behavior by using a supervised machine learning algorithm, are able to deliver behaviorally triggered stimuli to flies in a feedback-loop mode, and are highly customizable and open source.\nEthoscopes can be built easily by using 3D printing technology and rely on Raspberry Pi microcomputers and Arduino boards to provide affordable and flexible hardware.\nProject Author(s) Quentin Geissmann; Luis Garcia; Giorgio Gilestro\nProject Links http://lab.gilest.ro/ethoscope\nProject Video https://www.youtube.com/watch?v=5oWGBUMJON8\u0026amp;feature=emb_title\n This post was automatically generated by Giorgio Gilestro\n ","date":1594339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594339200,"objectID":"b12290026fe0a3b50f094e1f7afec210","permalink":"https://open-neuroscience.com/en/post/ethoscopes/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/en/post/ethoscopes/","section":"post","summary":"Ethoscopes are machines for high-throughput analysis of behavior in Drosophila and other animals.\nEthoscopes provide a software and hardware solution that is reproducible and easily scalable.\nThey perform, in real-time, tracking and profiling of behavior by using a supervised machine learning algorithm, are able to deliver behaviorally triggered stimuli to flies in a feedback-loop mode, and are highly customizable and open source.","tags":["Behaviour","Hardware","Software","Computers"],"title":"Ethoscopes","type":"post"},{"authors":[""],"categories":["Software","Behaviour"],"content":"BonVision is an open-source closed-loop visual environment generator developed by the Saleem Lab and Solomon Lab at the UCL Institute of Behavioural Neuroscience in collaboration with NeuroGEARS.\nBonVision’s key features include:\nNaturally closed-loop system based on reactive coding of the Bonsai framework Handles 2D and 3D stimuli with equal ease Visual environment generated independent of display configuration Graphical programming language of the Bonsai framework Can be used for Augmented Reality, Virtual Reality or 2D visual stimuli Does not require the observer to be in a fixed position  Project Author(s) Bonvision\nProject Links http://bonvision.github.io\n This post was automatically generated by Matias Andina\n ","date":1593993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593993600,"objectID":"0971b7d019e02981b0f1382f941c25ce","permalink":"https://open-neuroscience.com/en/post/bonvision/","publishdate":"2020-07-06T00:00:00Z","relpermalink":"/en/post/bonvision/","section":"post","summary":"BonVision is an open-source closed-loop visual environment generator developed by the Saleem Lab and Solomon Lab at the UCL Institute of Behavioural Neuroscience in collaboration with NeuroGEARS.\nBonVision’s key features include:","tags":["Software","Behaviour"],"title":"Bonvision","type":"post"},{"authors":[""],"categories":["Software","Hardware","Microscopes","Molecular biology"],"content":"The Poseidon is an open-source syringe pump and microscope system. It uses 3D printed parts and common components that can be easily purchased. It can be used in microfluidics experiments or other applications. You can assemble it in a short-time for under $400. The system is modular and highly customizable. Examples of applications are: control the chemical environment of a bioreactor, purify proteins and precisely add reagents to chemical reactions over time.\nProject Author(s) Pachter Lab\nProject Links https://pachterlab.github.io/poseidon\n This post was automatically generated by Miguel Fernandes\n ","date":1593993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593993600,"objectID":"25f3a2707e98d88eb547dee05ba63457","permalink":"https://open-neuroscience.com/en/post/poseidon/","publishdate":"2020-07-06T00:00:00Z","relpermalink":"/en/post/poseidon/","section":"post","summary":"The Poseidon is an open-source syringe pump and microscope system. It uses 3D printed parts and common components that can be easily purchased. It can be used in microfluidics experiments or other applications.","tags":["Software","Hardware","Microscopes","Molecular biology"],"title":"Poseidon","type":"post"},{"authors":[""],"categories":["Software","Behaviour","Data Analysis"],"content":"DeepLabStream is a python based multi-purpose tool that enables the realtime tracking of animals and manipulation of experiments. Our toolbox is adapted from the previously published DeepLabCut (Mathis et al., 2018) and expands on its core capabilities. DeepLabStreams core feature is the real-time analysis using any type of camera-based video stream (incl. multiple streams). Building onto that, we designed a full experimental closed-loop toolkit. It enables running experimental protocols that are dependent on a constant stream of bodypart positions and feedback activation of several input/output devices. It\u0026rsquo;s capabilities range from simple region of interest (ROI) based triggers to headdirection or behavior dependent stimulation.\nProject Author(s) Schwarz Neurocon Lab\nProject Links https://github.com/SchwarzNeuroconLab/DeepLabStream\n This post was automatically generated by Matias Andina\n ","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"8f073c74db368b33fd3fac7a4e85e608","permalink":"https://open-neuroscience.com/en/post/deeplabstream/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/en/post/deeplabstream/","section":"post","summary":"DeepLabStream is a python based multi-purpose tool that enables the realtime tracking of animals and manipulation of experiments. Our toolbox is adapted from the previously published DeepLabCut (Mathis et al., 2018) and expands on its core capabilities.","tags":["Software","Behaviour","Data Analysis"],"title":"DeepLabStream","type":"post"},{"authors":[""],"categories":["Hardware","Simulations","Optogenetics","Behaviour, Microscopes, Calcium Imaging, Fluorescence"],"content":"Two-photon (2P) microscopy is a cornerstone technique in neuroscience research. However, combining 2P imaging with spectrally arbitrary light stimulation can be challenging due to crosstalk between stimulation light and fluorescence detection. To overcome this limitation, we present a simple and low-cost electronic solution based on an ESP32 microcontroller and a TLC5947 LED driver to rapidly time-interleave stimulation and detection epochs during scans. Implemented for less than $100, our design can independently drive up to 24 arbitrary spectrum LEDs to meet user requirements. We demonstrate the utility of our stimulator for colour vision experiments on the in vivo tetrachromatic zebrafish retina and for optogenetic circuit mapping in Drosophila.\nProject Author(s) Maxime Zimmermann; Andre Maia Chagas; Philipp Bartel; Sinzi Pop, Lucia Pierto Godino; Tom Baden\nProject Links https://github.com/BadenLab/LED-Zappelin\n This post was automatically generated by Maxime Zimmermann\n ","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"368e16a35670177d4134621661914f5e","permalink":"https://open-neuroscience.com/en/post/led_zappelin/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/en/post/led_zappelin/","section":"post","summary":"Two-photon (2P) microscopy is a cornerstone technique in neuroscience research. However, combining 2P imaging with spectrally arbitrary light stimulation can be challenging due to crosstalk between stimulation light and fluorescence detection.","tags":["Hardware","Simulations","Optogenetics","Behaviour, Microscopes, Calcium Imaging, Fluorescence"],"title":"LED Zappelin'","type":"post"},{"authors":[""],"categories":["Software","Data Analysis","Animal electrophysiology","Human electrophysiology"],"content":"SpikeInterface is a unified Python framework for spike sorting. With its high-level API, it is designed to be accessible and easy to use, allowing users to build full analysis pipelines for spike sorting (reading-writing (IO) / preprocessing / spike sorting / postprocessing / validation / curation / comparison / visualization) with a few lines of code.\nProject Author(s) Alessio Buccino*; Cole Hurwitz*; Samuel Garcia; Jeremy Magland; Josh Siegle; Matthias Hennig\nProject Links https://github.com/SpikeInterface/spikeinterface\nProject Video https://www.youtube.com/watch?v=nWJGwFB7oII\n This post was automatically generated by Alessio Buccino\n ","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"76d3291aaf19843bd38a881a684cbd91","permalink":"https://open-neuroscience.com/en/post/spikeinterface/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/en/post/spikeinterface/","section":"post","summary":"SpikeInterface is a unified Python framework for spike sorting. With its high-level API, it is designed to be accessible and easy to use, allowing users to build full analysis pipelines for spike sorting (reading-writing (IO) / preprocessing / spike sorting / postprocessing / validation / curation / comparison / visualization) with a few lines of code.","tags":["Software","Data Analysis","Animal electrophysiology","Human electrophysiology"],"title":"SpikeInterface","type":"post"},{"authors":[""],"categories":["Data Repositories","Tutorials \u0026 learning portals","Microscopes","Optogenetics"],"content":"AAV are versatile tools used by neuroscientists for expression and manipulation of neurons. Many scientists have benefited from the high-quality, ready-to-use AAV prep service from Addgene, a nonprofit plasmid repository. However, it can be challenging to determine which AAV tool and techniques are best to use for an experiment. Scientists also may have questions about how much virus to inject or which serotype or promoter should be used to target the desired neuron or brain region. To help scientists answer these questions, Addgene launched an open platform called the AAV Data Hub (https://datahub.addgene.org/aav/) which allows researchers to easily share practical experimental details with the scientific community (AAV used, in vivo model used, injection site, injection volumes, etc.). The goal of this platform is to help scientists find the best AAV tool for their experiments by reviewing combined data from a broad range of research labs. The AAV Data Hub launched in late 2019 and over 100 experiments have since been contributed to this project. The dataset includes details and images from experiments conducted in six different species and several different expression sites.\nProject Author(s) Addgene\nProject Links https://datahub.addgene.org/aav/\nProject Video https://www.youtube.com/watch?v=ZPKdr1RdtGI\u0026amp;feature=youtu.be\n This post was automatically generated by Angela Abitua\n ","date":1592870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592870400,"objectID":"9f00b3461c9cf400bb9c885b00ba8e04","permalink":"https://open-neuroscience.com/en/post/addgenes_aav_data_hub/","publishdate":"2020-06-23T00:00:00Z","relpermalink":"/en/post/addgenes_aav_data_hub/","section":"post","summary":"AAV are versatile tools used by neuroscientists for expression and manipulation of neurons. Many scientists have benefited from the high-quality, ready-to-use AAV prep service from Addgene, a nonprofit plasmid repository. However, it can be challenging to determine which AAV tool and techniques are best to use for an experiment.","tags":["Data Repositories","Tutorials \u0026 learning portals","Microscopes","Optogenetics"],"title":"Addgene's AAV Data Hub","type":"post"},{"authors":[""],"categories":["Hardware","Behaviour"],"content":"We describe the “FishCam”, a low-cost (500 USD) autonomous camera package to record videos and images underwater. The system is composed of easily accessible components and can be programmed to turn ON and OFF on customizable schedules. Its 8-megapixel camera module is capable of taking 3280 × 2464-pixel images and videos. An optional buzzer circuit inside the pressure housing allows synchronization of the video data from the FishCam with passive acoustic recorders. Ten FishCam deployments were performed along the east coast of Vancouver Island, British Columbia, Canada, from January to December 2019. Field tests demonstrate that the proposed system can record up to 212 h of video data over a period of at least 14 days. The FishCam data collected allowed us to identify fish species and observe species interactions and behaviors. The FishCam is an operational, easily-reproduced and inexpensive camera system that can help expand both the temporal and spatial coverage of underwater observations in ecological research. With its low cost and simple design, it has the potential to be integrated into educational and citizen science projects, and to facilitate learning the basics of electronics and programming.\nProject Author(s) Xavier Mouy\nProject Links https://www.sciencedirect.com/science/article/pii/S2468067220300195\n This post was automatically generated by Matias Andina\n ","date":1592870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592870400,"objectID":"3a0754177d392291c248a4d8e6a52e00","permalink":"https://open-neuroscience.com/en/post/fishcam/","publishdate":"2020-06-23T00:00:00Z","relpermalink":"/en/post/fishcam/","section":"post","summary":"We describe the “FishCam”, a low-cost (500 USD) autonomous camera package to record videos and images underwater. The system is composed of easily accessible components and can be programmed to turn ON and OFF on customizable schedules.","tags":["Hardware","Behaviour"],"title":"FishCam","type":"post"},{"authors":[""],"categories":["Software","Data Analysis"],"content":"neuTube is an open source software for reconstructing neurons from fluorescence microscope images. It is easy to use and improves the efficiency of reconstructing neuron structures accurately. The framework combines 2D/3D visualization, semi-automated tracing algorithms, and flexible editing options that simplify the task of neuron reconstruction.\nProject Author(s) Ting Zhao\nProject Links https://www.neutracing.com/\n This post was automatically generated by Miguel Fernandes\n ","date":1592784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592784000,"objectID":"38d9013d6a746b4d8ef19099308f3dd4","permalink":"https://open-neuroscience.com/en/post/neutube/","publishdate":"2020-06-22T00:00:00Z","relpermalink":"/en/post/neutube/","section":"post","summary":"neuTube is an open source software for reconstructing neurons from fluorescence microscope images. It is easy to use and improves the efficiency of reconstructing neuron structures accurately. The framework combines 2D/3D visualization, semi-automated tracing algorithms, and flexible editing options that simplify the task of neuron reconstruction.","tags":["Software","Data Analysis"],"title":"neuTube","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware","Molecular biology","Software"],"content":"Today, biologists spend too much time pipetting by hand. We think biologists should have robots to do pipetting for them. People doing science should be free of tedious benchwork and repetitive stress injuries. They should be able to spend their time designing experiments and analyzing data.\nThat\u0026rsquo;s why we started Opentrons.\nWe make robots for biologists. Our mission is to provide the scientific community with a common platform to easily share protocols and reproduce each other\u0026rsquo;s results. Our robots automate experiments that would otherwise be done by hand, allowing our community to spend more time pursuing answers to some of the 21st century’s most important questions\nProject Author(s) Opentrons\nProject Links https://opentrons.com/about\nProject Video https://www.youtube.com/channel/UCvMRmXIxnHs3AutkVhuqaQg\n This post was automatically generated by Matias Andina\n ","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"900101a06d384d089f32726f44a5166b","permalink":"https://open-neuroscience.com/en/post/opentrons/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/en/post/opentrons/","section":"post","summary":"Today, biologists spend too much time pipetting by hand. We think biologists should have robots to do pipetting for them. People doing science should be free of tedious benchwork and repetitive stress injuries.","tags":["Benchtop","Hardware","Molecular biology","Software"],"title":"OpenTrons","type":"post"},{"authors":[""],"categories":["Calcium Imaging","Software","Behaviour","Data Analysis"],"content":"Two-photon calcium imaging is now widely used to infer neuronal dynamics from changes in fluorescence of an indicator. However, state of the art computational tools are not optimized for the reliable detection of fluorescence transients from highly synchronous neurons located in densely packed regions such as the CA1 pyramidal layer of the hippocampus during early postnatal stages of development. Indeed,the latest analytical tools often lack proper benchmark measurements. To meet this challenge, we first developed a graphical user interface allowing for a precise manual detection of all calcium transients from imaged neurons based on the visualization of the calcium imaging movie. Then, we analyzed the movies using a convolutional neural network with an attention process and a bidirectional long-short term memory network. This method is able to reach human performance and offers a better F1 score (harmonic mean of sensitivity and precision) than CaImAn to infer neural activity in the developingCA1 without any user intervention. It also enables automatically identifying activity originating from GABAergic neurons. Overall, DeepCINAC offers a simple, fast and flexible open-source toolbox for processing a wide variety of calcium imaging datasets while providing the tools to evaluate its performance.\nSee full text at https://www.biorxiv.org/content/10.1101/803726v2.full.pdf\nProject Author(s) Julien Denis\nProject Links https://gitlab.com/cossartlab/deepcinac\n This post was automatically generated by Matias Andina\n ","date":1591401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591401600,"objectID":"6417bbbd8c1aa83976d3bd16c9817bd3","permalink":"https://open-neuroscience.com/en/post/deep_cinac/","publishdate":"2020-06-06T00:00:00Z","relpermalink":"/en/post/deep_cinac/","section":"post","summary":"Two-photon calcium imaging is now widely used to infer neuronal dynamics from changes in fluorescence of an indicator. However, state of the art computational tools are not optimized for the reliable detection of fluorescence transients from highly synchronous neurons located in densely packed regions such as the CA1 pyramidal layer of the hippocampus during early postnatal stages of development.","tags":["Calcium Imaging","Software","Behaviour","Data Analysis"],"title":"Deep Cinac","type":"post"},{"authors":[""],"categories":["Prosthetics","Hardware"],"content":" The fingertip laser project makes use of the sensor used in an Avago ADNS-9500 laser mouse, to improve the capabilities of robotic hands, giving them the capability to detect distance, surface type and slippage of grasped objects. Very elegant hack of a mouse sensor!\n","date":1591401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591401600,"objectID":"d96f03c07055edf2a2d55811f0129718","permalink":"https://open-neuroscience.com/en/post/fingertip_laser_sensor/","publishdate":"2020-06-06T00:00:00Z","relpermalink":"/en/post/fingertip_laser_sensor/","section":"post","summary":"The fingertip laser project makes use of the sensor used in an Avago ADNS-9500 laser mouse, to improve the capabilities of robotic hands, giving them the capability to detect distance, surface type and slippage of grasped objects.","tags":["Prosthetics","Hardware"],"title":"Fingertip laser sensor","type":"post"},{"authors":[""],"categories":["Other","Journal"],"content":"SciDraw is a free repository of high quality drawings of animals, scientific setups, and anything that might be useful for scientific presentations and posters. We want this repository to be as open as possible, so do not require signing up to post a drawing. This however means that you won\u0026rsquo;t be able to edit your drawings after submission, so upload carefully! The drawings on SciDraw are made by and for scientists. You are free to download, modify and use all drawings on the website.\nProject Author(s) Federico Claudi and Alex Harston\nProject Links https://scidraw.io/\n This post was automatically generated by Matias Andina\n ","date":1591401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591401600,"objectID":"cec43735a6d1a5520e1032b3de414d31","permalink":"https://open-neuroscience.com/en/post/scidraw/","publishdate":"2020-06-06T00:00:00Z","relpermalink":"/en/post/scidraw/","section":"post","summary":"SciDraw is a free repository of high quality drawings of animals, scientific setups, and anything that might be useful for scientific presentations and posters. We want this repository to be as open as possible, so do not require signing up to post a drawing.","tags":["Other","Journal"],"title":"SciDraw","type":"post"},{"authors":[""],"categories":["Microscopes","Hardware","Software"],"content":"The open-source optical toolbox UC2 [YouSeeToo] simplifies the process of building optical setups, by combining 3D-printed cubes, each holding a specific component (e.g. lens, mirror) on a magnetic square-grid baseplate. The use of widely available consumables and 3D printing, together with documentation and software, offers an extremely low-cost and accessible alternative for both education and research areas. In order to reduce the entry barrier, we provide a fully comprehensive toolbox called TheBOX. A paper describing the scientific application in detail can be found here.\nProject Author(s) Benedict Diederich; René Lachmann; Barbora Marsikova\nProject Links https://useetoo.org\nProject Video https://www.youtube.com/watch?v=ey4uEFEG6MY\n This post was automatically generated by Barbora Marsikova\n ","date":1591401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591401600,"objectID":"68121b84e316b4cf236442c2d739812b","permalink":"https://open-neuroscience.com/en/post/uc2/","publishdate":"2020-06-06T00:00:00Z","relpermalink":"/en/post/uc2/","section":"post","summary":"The open-source optical toolbox UC2 [YouSeeToo] simplifies the process of building optical setups, by combining 3D-printed cubes, each holding a specific component (e.g. lens, mirror) on a magnetic square-grid baseplate. The use of widely available consumables and 3D printing, together with documentation and software, offers an extremely low-cost and accessible alternative for both education and research areas.","tags":["Microscopes","Hardware","Software"],"title":"UC2","type":"post"},{"authors":[""],"categories":["Hardware","Behaviour"],"content":"The advent of genetically encoded calcium indicators, along with surgical preparations such as thinned skulls or refractive index matched skulls, have enabled mesoscale cortical activity imaging in head-fixed mice. Such imaging studies have revealed complex patterns of coordinated activity across the cortex during spontaneous behaviors, goal-directed behavior, locomotion, motor learning,and perceptual decision making. However, neural activity during unrestrained behavior significantly differs from neural activity in head-fixed animals. Whole-cortex imaging in freely behaving mice will enable the study of neural activity in a larger, more complex repertoire of behaviors not possible in head-fixed animals. Here we present the “Mesoscope,” a wide-field miniaturized, head-mounted fluorescence microscope compatible with transparent polymer skulls recently developed by our group. With afield of view of 8 mm x 10 mm and weighing less than 4 g, the Mesoscope can image most of the mouse dorsal cortex with resolution ranging from 39 to 56μm. Stroboscopic illumination with blue and green LEDs allows fort he measurement of both fluorescence changes due to calcium activity and reflectance signals to capture hemodynamic changes. We have used the Mesoscope to successfully record mesoscale calcium activity across the dorsal cortex during sensory-evoked stimuli, open field behaviors, and social interactions.\nProject Author(s) Biosensing and Biorobotics Lab\nProject Links https://www.biorxiv.org/content/10.1101/2020.05.25.114892v1.full.pdf\n This post was automatically generated by Matias Andina\n ","date":1590796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590796800,"objectID":"151463c705ca21cb5c9f75421678f216","permalink":"https://open-neuroscience.com/en/post/head-mounted_mesoscope/","publishdate":"2020-05-30T00:00:00Z","relpermalink":"/en/post/head-mounted_mesoscope/","section":"post","summary":"The advent of genetically encoded calcium indicators, along with surgical preparations such as thinned skulls or refractive index matched skulls, have enabled mesoscale cortical activity imaging in head-fixed mice. Such imaging studies have revealed complex patterns of coordinated activity across the cortex during spontaneous behaviors, goal-directed behavior, locomotion, motor learning,and perceptual decision making.","tags":["Hardware","Behaviour"],"title":"Head-Mounted Mesoscope","type":"post"},{"authors":[""],"categories":["Hardware"],"content":"The purpose of this project is to convey a location in 3 dimensional space to a machine, hands free and in real time.\nCurrently it is very difficult to control machines without making the user provide input with their hands. Additionally it can be very difficult to specify a location in space without a complex input device. This system provides a novel solution to this problem by allowing the user to specify a location simply by looking at it.\nNormally eyetracking solutions are prohibitively expensive and not open source, limiting their use for creators to integrate them into new projects. This solution is fully open source, easy to build and will provide a huge variety of options for makers interested in using this fascinating and powerful technology.\nProject Author(s) John Evans\nProject Links https://hackaday.io/project/153293-low-cost-open-source-eye-tracking\n This post was automatically generated by Matias Andina\n ","date":1590796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590796800,"objectID":"ceedfa7d4d943f6a95b15ef68fd11b61","permalink":"https://open-neuroscience.com/en/post/open_source_eye_tracking/","publishdate":"2020-05-30T00:00:00Z","relpermalink":"/en/post/open_source_eye_tracking/","section":"post","summary":"The purpose of this project is to convey a location in 3 dimensional space to a machine, hands free and in real time.\nCurrently it is very difficult to control machines without making the user provide input with their hands.","tags":["Hardware"],"title":"Open Source Eye Tracking","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware","Behaviour"],"content":"Syringe pumps are a necessary piece of laboratory equipment that are used for fluid delivery in behavioral neuroscience laboratories. Many experiments provide rodents and primates with fluid rewards such as juice, water, or liquid sucrose. Current commercialized syringe pumps are not customizable and do not have the ability to deliver multiple volumes of fluid based on different inputs to the pump. Additionally, many syringe pumps are expensive and cannot be used in experiments with paired neurophysiological recordings due to electrical noise. We developed an open source syringe pump controller using commonly available parts. The controller adjusts the acceleration and speed of the motor to deliver three different volumes of fluid reward within one common time epoch. This syringe pump controller is cost effective and has been successfully implemented in rodent behavioral experiments with paired neurophysiological recordings in the rat frontal cortex while rats lick for different volumes of liquid sucrose rewards. Our syringe pump controller will enable new experiments to address the potential confound of temporal information in studies of reward signaling by fluid magnitude.\nProject Author(s) Laubach Lab\nProject Links https://github.com/LaubachLab/OpenSourceSyringePump\n This post was automatically generated by Matias Andina\n ","date":1590796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590796800,"objectID":"566d84421458f24037c8a0bafa3f88e3","permalink":"https://open-neuroscience.com/en/post/open_source_syringe_pump_controller/","publishdate":"2020-05-30T00:00:00Z","relpermalink":"/en/post/open_source_syringe_pump_controller/","section":"post","summary":"Syringe pumps are a necessary piece of laboratory equipment that are used for fluid delivery in behavioral neuroscience laboratories. Many experiments provide rodents and primates with fluid rewards such as juice, water, or liquid sucrose.","tags":["Benchtop","Hardware","Behaviour"],"title":"Open Source Syringe Pump Controller","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware","Molecular biology"],"content":"An open-source 3-D printable laboratory sample rotator mixer is developed here in two variants that allow users to opt for the level of functionality, cost saving and associated complexity needed in their laboratories. First, a laboratory sample rotator is designed and demonstrated that can be used for tumbling as well as gentle mixing of samples in a variety of tube sizes by mixing them horizontally, vertically, or any position in between. Changing the mixing angle is fast and convenient and requires no tools. This device is battery powered and can be easily transported to operate in various locations in a lab including desktops, benches, clean hoods, chemical hoods, cold rooms, glove boxes, incubators or biological hoods. Second, an on-board Arduino-based microcontroller is incorporated that adds the functionality of a laboratory sample shaker. These devices can be customized both mechanically and functionally as the user can simply select the operation mode on the switch or alter the code to perform custom experiments. The open source laboratory sample rotator mixer can be built by non-specialists for under US$30 and adding shaking functionality can be done for under $20 more. Thus, these open source devices are technically superior to the proprietary commercial equipment available on the market while saving over 90% of the costs.\nProject Author(s) MOST\nProject Links https://www.appropedia.org/Open_Source_Laboratory_Sample_Rotator_Mixer_and_Shaker\nProject Video https://www.youtube.com/watch?v=Ta2ACV1oIjI\u0026amp;feature=emb_logo\n This post was automatically generated by Matias Andina\n ","date":1590796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590796800,"objectID":"d8150f722cda302d860030624b110177","permalink":"https://open-neuroscience.com/en/post/sample_rotator_mixer_and_shaker/","publishdate":"2020-05-30T00:00:00Z","relpermalink":"/en/post/sample_rotator_mixer_and_shaker/","section":"post","summary":"An open-source 3-D printable laboratory sample rotator mixer is developed here in two variants that allow users to opt for the level of functionality, cost saving and associated complexity needed in their laboratories.","tags":["Benchtop","Hardware","Molecular biology"],"title":"Sample Rotator Mixer and Shaker","type":"post"},{"authors":[""],"categories":["Behaviour","Hardware","Software"],"content":"Operant conditioning (OC) is a classical paradigm and a standard technique used in experimental psychology in which animals learn to perform an action to achieve a reward. By using this paradigm, it is possible to extract learning curves and measure accurately reaction times (RTs). Both these measurements are proxy of cognitive capabilities and can be used to evaluate the effectiveness of therapeutic interventions in mouse models of disease. Here, we describe a fully 3D printable device that is able to perform OC on freely moving mice, while performing real-time tracking of the animal position. We successfully trained six mice, showing stereotyped learning curves that are highly reproducible across mice and reaching \u0026gt;70% of accuracy after 2 d of conditioning. Different products for OC are commercially available, though most of them do not provide customizable features and are relatively expensive. This data demonstrate that this system is a valuable alternative to available state-of-the-art commercial devices, representing a good balance between performance, cost, and versatility in its use.\nProject Author(s) Raffaele Mazziotti, Giulia Sagona, Leonardo Lupori, Virginia Martini and Tommaso Pizzorusso\nProject Links https://github.com/raffaelemazziotti/oc_chamber\n This post was automatically generated by Matias Andina\n ","date":1590624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590624000,"objectID":"edee9393c7fe7b5f290e6b3f5075cae9","permalink":"https://open-neuroscience.com/en/post/automated_operant_conditioning/","publishdate":"2020-05-28T00:00:00Z","relpermalink":"/en/post/automated_operant_conditioning/","section":"post","summary":"Operant conditioning (OC) is a classical paradigm and a standard technique used in experimental psychology in which animals learn to perform an action to achieve a reward. By using this paradigm, it is possible to extract learning curves and measure accurately reaction times (RTs).","tags":["Behaviour","Hardware","Software"],"title":"Automated Operant Conditioning","type":"post"},{"authors":[""],"categories":["Software","Human electrophysiology","Animal electrophysiology","Computational Neuroscience"],"content":"Extracellular microelectrodes frequently record neural activity from more than one neuron in the vicinity of the electrode. The process of labeling each recorded spike waveform with the identity of its source neuron is called spike sorting and is often approached from an abstracted statistical perspective. However, these approaches do not consider neurophysiological realities and may ignore important features that could improve the accuracy of these methods. Further, standard algorithms typically require selection of at least one free parameter, which can have significant effects on the quality of the output. We describe a Heuristic Spike Sorting Tuner (HSST) that determines the optimal choice of the free parameters for a given spike sorting algorithm based on the neurophysiological qualification of unit isolation and signal discrimination. A set of heuristic metrics are used to score the output of a spike sorting algorithm over a range of free parameters resulting in optimal sorting quality. We demonstrate that these metrics can be used to tune parameters in several spike sorting algorithms. The HSST algorithm shows robustness to variations in signal to noise ratio, number and relative size of units per channel. Moreover, the HSST algorithm is computationally efficient, operates unsupervised, and is parallelizable for batch processing.\nProject Author(s) David A. Bjanes; Lee B. Fisher; Robert A. Gaunt; Douglas J. Weber\nProject Links https://github.com/davidbjanes/hsst\n This post was automatically generated by David Bjanes\n ","date":1590624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590624000,"objectID":"6efe590482e27e7ac40901184a8db5b2","permalink":"https://open-neuroscience.com/en/post/heuristic_spike_sorting_tuner_hsst_a_framework_to_determine_optimal_parameter_selection_for_a_generic_spike_sorting_algorithm/","publishdate":"2020-05-28T00:00:00Z","relpermalink":"/en/post/heuristic_spike_sorting_tuner_hsst_a_framework_to_determine_optimal_parameter_selection_for_a_generic_spike_sorting_algorithm/","section":"post","summary":"Extracellular microelectrodes frequently record neural activity from more than one neuron in the vicinity of the electrode. The process of labeling each recorded spike waveform with the identity of its source neuron is called spike sorting and is often approached from an abstracted statistical perspective.","tags":["Software","Human electrophysiology","Animal electrophysiology","Computational Neuroscience"],"title":"Heuristic Spike Sorting Tuner (HSST), a framework to determine optimal parameter selection for a generic spike sorting algorithm","type":"post"},{"authors":[""],"categories":["Software","Behaviour","Data Analysis"],"content":"Mice emit ultrasonic vocalizations (USV) to transmit socially-relevant information. To detect and classify these USVs, here we describe the development of VocalMat. VocalMat is a software that uses image-processing and differential geometry approaches to detect USVs in audio files, eliminating the need for user-defined parameter tuning. VocalMat also uses computational vision and machine learning methods to classify USVs into distinct categories. In a dataset of \u0026gt;4,000 USVs emitted by mice, VocalMat detected more than \u0026gt;98% of the USVs and accurately classified ≈86% of USVs when considering the most likely label out of 11 different USV types. We then used Diffusion Maps and Manifold Alignment to analyze the probability distribution of USV classification among different experimental groups, providing a robust method to quantify and qualify the vocal repertoire of mice. Thus, VocalMat allows accurate and highly quantitative analysis of USVs, opening the opportunity for detailed and high-throughput analysis of this behavior.\nProject Author(s) Antonio H. O. Fonseca, Gustavo M. Santana, Sergio Bampi, Marcelo O Dietrich\nProject Links https://www.dietrich-lab.org/vocalmat\n This post was automatically generated by Matias Andina\n ","date":1590537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590537600,"objectID":"4e5635b3ebf5939324612e1116bf3c85","permalink":"https://open-neuroscience.com/en/post/vocalmat/","publishdate":"2020-05-27T00:00:00Z","relpermalink":"/en/post/vocalmat/","section":"post","summary":"Mice emit ultrasonic vocalizations (USV) to transmit socially-relevant information. To detect and classify these USVs, here we describe the development of VocalMat. VocalMat is a software that uses image-processing and differential geometry approaches to detect USVs in audio files, eliminating the need for user-defined parameter tuning.","tags":["Software","Behaviour","Data Analysis"],"title":"VocalMat","type":"post"},{"authors":[""],"categories":["Data Repositories","Computational Neuroscience","Software","Tutorials \u0026 learning portals"],"content":"BossDB is a volumetric database that lives in the AWS cloud. Hundreds of terabytes of electron microscopy, light microscopy, and x-ray tomography data are available for free download and study.\nHave a project you want to share with the world for free? Get in touch! https://twitter.com/thebossdb\nProject Author(s) JHU|APL\nProject Links https://bossdb.org/\n This post was automatically generated by Jordan Matelsky\n ","date":1590451200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590451200,"objectID":"8accbeec426039bf59e83880c26b9593","permalink":"https://open-neuroscience.com/en/post/bossdb/","publishdate":"2020-05-26T00:00:00Z","relpermalink":"/en/post/bossdb/","section":"post","summary":"BossDB is a volumetric database that lives in the AWS cloud. Hundreds of terabytes of electron microscopy, light microscopy, and x-ray tomography data are available for free download and study.","tags":["Data Repositories","Computational Neuroscience","Software","Tutorials \u0026 learning portals"],"title":"BossDB","type":"post"},{"authors":[""],"categories":["Other"],"content":"Neuroanatomy and Behaviour (ISSN: 2652-1768) is a free open access journal for behavioural neuroscience and related fields. Powered by free open source software to eliminate costs and keep grant funds doing science. Scientist-run and non-profit.\nProject Author(s) Episteme Health Inc.\nProject Links https://epistemehealth.com\n This post was automatically generated by Shaun Khoo\n ","date":1590451200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590451200,"objectID":"9feecc874062de4d309262980a509712","permalink":"https://open-neuroscience.com/en/post/neuroanatomy_and_behaviour/","publishdate":"2020-05-26T00:00:00Z","relpermalink":"/en/post/neuroanatomy_and_behaviour/","section":"post","summary":"Neuroanatomy and Behaviour (ISSN: 2652-1768) is a free open access journal for behavioural neuroscience and related fields. Powered by free open source software to eliminate costs and keep grant funds doing science.","tags":["Other"],"title":"Neuroanatomy and Behaviour","type":"post"},{"authors":[""],"categories":["Software","Data Analysis"],"content":"3D Slicer is a software for medical image informatics, image processing, and three-dimensional visualization. It’s extremely powerful and versatile with plenty of different options. It is a great tool for volume rendering, registration, interactive segmentation of images and even offers the possibility of running Python scripts thought an embedded Python interpreter.\nProject Author(s) Ron Kikinis\nProject Links https://github.com/Slicer/Slicer\n This post was automatically generated by Miguel Fernandes\n ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590105600,"objectID":"c90d3ce4ef7c6b332120fc3ab85d566c","permalink":"https://open-neuroscience.com/en/post/3d_slicer/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/en/post/3d_slicer/","section":"post","summary":"3D Slicer is a software for medical image informatics, image processing, and three-dimensional visualization. It’s extremely powerful and versatile with plenty of different options. It is a great tool for volume rendering, registration, interactive segmentation of images and even offers the possibility of running Python scripts thought an embedded Python interpreter.","tags":["Software","Data Analysis"],"title":"3D Slicer","type":"post"},{"authors":[""],"categories":["Hardware","Animal electrophysiology","Benchtop"],"content":"The Craniobot is a cranial microsurgery platform that combines automated skull surface profiling with a computer numerical controlled (CNC) milling machine to perform a variety of cranial microsurgical procedures in mice. The Craniobot utilizes a low force contact sensor to profile the skull surface and uses this information to perform micrometer-scale precise milling operations within minutes. The procedure of removing the sub-millimeter thick mouse skull precisely without damaging the underlying brain can be technically challenging and often takes significant skill and practice. This can now be overcome using the Craniobot.\nProject Author(s) Mathew Rynes, Leila Ghanbari, Micheal Laroque, Greg Johnson, Daniel Sousa Schulman, Suhasa Kodandaramaiah\nProject Links https://www.labmaker.org/products/craniobot\n This post was automatically generated by Matias Andina\n ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590105600,"objectID":"462076efd3fdf91ade55fdc2292661e3","permalink":"https://open-neuroscience.com/en/post/craniobot/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/en/post/craniobot/","section":"post","summary":"The Craniobot is a cranial microsurgery platform that combines automated skull surface profiling with a computer numerical controlled (CNC) milling machine to perform a variety of cranial microsurgical procedures in mice.","tags":["Hardware","Animal electrophysiology","Benchtop"],"title":"Craniobot","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware","Electric stimulation"],"content":"LabMaker is a maker and assembly service for OPEN SCIENCE instruments. OPEN SCIENCE initiatives provide part lists or \u0026ldquo;Bill Of Materials\u0026rdquo; (BOM) for openly available scientific instruments. LabMaker bridges the gap between the BOM and the ready-to-use instrument for those not wanting to build by themselves. LabMaker is based in Berlin, Germany and ships worldwide. Berlin, as a city, is not only amongst the frontrunners for the title \u0026ldquo;start-up capital of Europe\u0026rdquo;, but also home to a large diversity of companies rooted in traditional precision manufacturing.\nProject Author(s) Labmaker\nProject Links https://www.labmaker.org/\n This post was automatically generated by Matias Andina\n ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590105600,"objectID":"36f5108bef23973164b5eb147097ddfe","permalink":"https://open-neuroscience.com/en/post/labmaker/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/en/post/labmaker/","section":"post","summary":"LabMaker is a maker and assembly service for OPEN SCIENCE instruments. OPEN SCIENCE initiatives provide part lists or \u0026ldquo;Bill Of Materials\u0026rdquo; (BOM) for openly available scientific instruments. LabMaker bridges the gap between the BOM and the ready-to-use instrument for those not wanting to build by themselves.","tags":["Benchtop","Hardware","Electric stimulation"],"title":"Labmaker","type":"post"},{"authors":[""],"categories":["Microscopes","Benchtop","Hardware"],"content":"An open-source, motorized, and modular microscope built using LEGO bricks, Arduino, Raspberry Pi and 3D printing. The microscope uses a Raspberry Pi mini-computer with an 8MP camera to capture images and videos. Stepper motors and the illumination are controlled using a circuit board comprising an Arduino microcontroller, six stepper motor drivers and a high-power LED driver. All functions can be controlled from a keyboard connected to the Raspberry Pi or a separate custom-built Arduino joystick connected to the mainboard. LEGO bricks are used to construct the main body of the microscope to achieve a modular and easy-to-assemble design concept.\nProject Author(s) Yuksel Temiz and IBM\nProject Links https://github.com/IBM/MicroscoPy\nProject Video https://www.youtube.com/watch?v=PBSYnk9T4o4\u0026amp;feature=youtu.be\n This post was automatically generated by Matias Andina\n ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590105600,"objectID":"40e93182588384957df8d19405b7dde3","permalink":"https://open-neuroscience.com/en/post/microscopy/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/en/post/microscopy/","section":"post","summary":"An open-source, motorized, and modular microscope built using LEGO bricks, Arduino, Raspberry Pi and 3D printing. The microscope uses a Raspberry Pi mini-computer with an 8MP camera to capture images and videos.","tags":["Microscopes","Benchtop","Hardware"],"title":"MicroscoPy","type":"post"},{"authors":[""],"categories":["Software","Data Analysis"],"content":"Colaboratory is a free Jupyter notebook environment that runs in the cloud. Your notebooks get stored on Google Drive. The great advantage is that you don’t have to install anything (however, for some features you need a Google account) on your system to use it. You can perform specific computations during data analysis with pre-installed Python libraries and gives you access to accelerated hardware for free (e.g. GPUs and TPUs).\nProject Author(s) Google\nProject Links https://colab.research.google.com/notebooks/intro.ipynb\n This post was automatically generated by Miguel Fernandes\n ","date":1589068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589068800,"objectID":"8bd296e3425096790bc6778df0a3ecae","permalink":"https://open-neuroscience.com/en/post/colaboratory/","publishdate":"2020-05-10T00:00:00Z","relpermalink":"/en/post/colaboratory/","section":"post","summary":"Colaboratory is a free Jupyter notebook environment that runs in the cloud. Your notebooks get stored on Google Drive. The great advantage is that you don’t have to install anything (however, for some features you need a Google account) on your system to use it.","tags":["Software","Data Analysis"],"title":"Colaboratory","type":"post"},{"authors":[""],"categories":["Software","Data Analysis","Computational Neuroscience"],"content":"Suite2P is a very modular imaging processing pipeline written in Python which allows you to perform registration of raw data movies, automatic cell detection, extraction of calcium traces and infers spike times. It is a very fast and accurate tool and can work on standard workstations. It also includes a visualization graphical user interface (GUI) that facilitates analysis and manual curation of the cell detection algorithm.\nProject Author(s) Carsen Stringer and Marius Pachitariu\nProject Links https://mouseland.github.io/suite2p/_build/html/index.html\n This post was automatically generated by Miguel Fernandes\n ","date":1589068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589068800,"objectID":"4fa0e44f97386a38e7fc636cb47942c3","permalink":"https://open-neuroscience.com/en/post/suite2p/","publishdate":"2020-05-10T00:00:00Z","relpermalink":"/en/post/suite2p/","section":"post","summary":"Suite2P is a very modular imaging processing pipeline written in Python which allows you to perform registration of raw data movies, automatic cell detection, extraction of calcium traces and infers spike times.","tags":["Software","Data Analysis","Computational Neuroscience"],"title":"Suite2P","type":"post"},{"authors":null,"categories":["Behaviour","Hardware"],"content":"The motivation to start this project arises when we started to include a new behavioral paradigm in the lab, an alternation T-mace with return arms (like the one in Wood e_t al._ 2000). We wanted a clean performance, as well as a clean video record, so we consider necessary to interfere neither with the animal attention (mice, how they are!) nor the camera’s field of view. I decided then to give a try to the new hobby I was getting into, “Do-It-Yourself” (DIY) stuff.\nIn my head, it was pictured very simple. At the end of the day, I just needed a) something to detect the animal passing by, b) something to deliver a drop of water and c) something to make it happen in a coordinated way. And that’s what Autoreward2 is, no more, no less.\nWell perhaps it is a bit more. So far, the project can:\n Detect when the animal reaches the end of any of the two arms. Deliver a small drop of fluid through the corresponding licking port (easy to make it happen in the opposite, if wanted). Give visual cues to the experimenter, indicating which arm has been reached. Allow to select different modes of working for different working protocols: ‘Waiting for selection’, ‘Habituation’, ‘Training’, ‘Experimental’ and “Filling and cleaning” modes (and is ready to include more!).  To achieve it, I decided for very simple approach. A couple of cheap infrared emitters are continuously read by an UNO R3 board. Breaking any of the beams triggers the signal to open the corresponding solenoid valve, connected to the fluid tank. That lets the liquid flow by gravity for around 75 milliseconds, resulting in a single drop at the tip of the licking port.\n There is a delay after each detection, to avoid repetitive delivery if animals don’t leave the area. A couple LEDs mounted in the bare-board (out of animal sight) light up when the process is triggered, one for each side. They also work as indicators for the ‘Waiting for selection’ mode, when they are continuously on, meanwhile no option is choose or the ‘return to waiting mode action’ is pressed.\nThe selection is made through a 4×4 membrane keypad. Right now, only options 1 to 4 are programmed, making up to 12 more programs available! When any section is made, the in-built LED blinks the corresponding times and the system is ready to work. At any moment, pressing any key makes the system reset to the waiting mode. As easy as that.\nEverything is powered by a regular 9V wall adapter, giving 3.3V to the LEDs and Infrared detectors, and 9V to the solenoids. Of course, it is possible to use a 9V batterie to power it. To avoid damage coming from the solenoid discharges, the circuit is protected by a couple of diodes at this level.\nAnd that’s all, it’s simple. The most important thing: it works. The other most important thing: it costs around 80€. Here is the to-buy list (or equivalent):\n Elegoo UNO R3 (I found them for 10€, with USB cable) BreadBoard + Acrylic base (7€) 9V 1A Wall power supply (9€) 2x InfraRed beams, 5mm (15€ both, the 3mm ones are even cheaper) 2x Mini-Solenoid valves (10€ both) 2x red LEDs 4x 1 KΩ resistors 2x TIP120 Transistors 2x 1N4001 diodes Wiring (set of jumpers for less than 10€) ‘Velcro’ to attach the acrylic base where the boards are mounted. Plastic tubing and laboratory sample tubes, modified with turning siringe tips to attach/deattach the tubing easily. 2x or 4x weak magnets to fix the tubes to the walls.   Feel free to access the Github page or the Arduino forum post to obtain the code, check for the circuit sketch, and see some pictures.\nPD: If someone is scandalized by the code, I am getting better on it, it is not my main strength. Please, improve it! Of course, I have in mind many possible upgrades such as a screen, a SD card port, to change the Keypad for a wireless interface (tactile?) … Did someone say smartphone plus Bluetooth? Going fancy, a barcode reader to easily introduce subjects’ data… And here is where I relay in the open-access idea, I offer it and hopefully someone implement any of the ideas. If so, remember to share!\nJesús J. Ballesteros\nContact me:\n Twitter\n ResearchGate\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"03328a18727f2c8b6e7135b9fa74ebc3","permalink":"https://open-neuroscience.com/en/post/autoreward2/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/autoreward2/","section":"post","summary":"The motivation to start this project arises when we started to include a new behavioral paradigm in the lab, an alternation T-mace with return arms (like the one in Wood e_t al.","tags":["Behaviour","Hardware"],"title":"Autoreward 2","type":"post"},{"authors":[""],"categories":["Topic"],"content":"Bellow is a list of interesting projects related to science and research, that we didn\u0026rsquo;t have time to curate yet. Feel free to browse through them and make comments and suggestions!\nhttp://wiki.cogain.org/index.php/Eye_Trackers Low cost eye tracking\nhttp://home.gna.org/veusz/ scientific plotting package\nhttp://erkutlu.blogspot.com.es/2012/12/eeg-and-arduino-do-it-yourself-eeg-ekg.html\nhttp://www.wired.com/wiredscience/2011/03/diy-cellphone-microscope cellphone into microscope spectrometer\nhttp://www.ncbi.nlm.nih.gov/geo/ gene expression omnibus database\nhttp://journal.frontiersin.org/Journal/10.3389/fninf.2014.00024/abstract Broccoli software for fast fMRI analyses\nhttp://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0086733 smartphone brain scanner\nhttp://paper.li/IbrahimMalick/1320890343 open source by ibrahim malick\nhttp://www.theguardian.com/public-leaders-network/2014/apr/15/big-data-open-data-transform-government?CMP=twt_gu big data\nhttps://code.google.com/p/arduino-v-neusci/ example on how to use arduino for visual neuroscience\nhttp://boinc.berkeley.edu/ the same idea from seth but generalized\nhttp://pybossa.com/ the same idea from boinc (above) but sharing cognition\nhttp://www.acq4.org/ neurophysiology and data analysis systems\nhttps://about.gitlab.com/about/ version control system for projects\nhttp://leaflabs.com/willow neuroscience 1000 channels array\nhttp://scalablephysiology.org/ the page dedicated to willow\nhttp://heywhatsthebigidea.net/projects/pi-vision-a-raspberry-pi-camera-controller/ pivision\nhttps://libre3d.com/category/687/Test-Equipment/listings/717/Open-Source-Water-Testing-Platform.html\nhttp://www.peekvision.org/ ophtamology exams with smartphones\nhttp://www.gpugrid.net/ distributed computing\nhttp://www.iorodeo.com/consulting open source hardware company\nhttp://hackaday.com/2015/01/06/3d-printing-circuits-gets-rid-of-the-box-altogether/ 3d print plastic and electronics together\n https://synbiota.com/  electronic lab notebook\nhttp://biojs.net/ biological data visualization tool\nhttp://open-access.net/de_en/homepage/ portal that gathers information on open access\nhttp://www.ohwr.org/ open hardware repository\nhttp://www.openingscience.org/ an umbrella t open scholarly data to a multitude of stakeholders\nhttp://woodenhaptics.org/ open source haptics device\nhttps://www.youtube.com/watch?v=Ss-9iXRUeGc Pneuflex actuators\nhttps://sites.google.com/site/openspinmicroscopy/ Openspin microscope\n http://openspim.org/Welcome_to_the_OpenSPIM_Wiki openspin microscope\nhttp://journal.frontiersin.org/Journal/10.3389/fneng.2014.00043/abstract signal generator\nhttp://hackaday.io/project/1395-open-source-science-tricorder arduino based gagdet with lots of sensors\nhttps://plot.ly/feed/ plots and data online\nhttp://littledevices.org/ small portable devices for health related tests/exams and etc\nhttps://gnu.io/ social interaction\n http://thinklab.com/how_it_works online platform for science project management\nhttp://credit.casrai.org/about-us/ changing the way scientific contributions are measured/displayed\n http://journal.frontiersin.org/article/10.3389/fneng.2015.00001/full?utm_source=newsletter\u0026amp;utm_medium=email\u0026amp;utm_campaign=Neuroscience-w15-2015 system for light stimulation and data recording for optogenetics\nhttps://arcturus.io/\n http://cmictig.cs.ucl.ac.uk/wiki/index.php/Main_Page  brain imaging software suite\n https://openhatch.org/wiki/Open_Science_Projects_and_Organizations#Neuroscience_2  Open science projects for neurosciences\nhttp://openpump.org/ open source syringe pump\nhttp://fab.cba.mit.edu/classes/4.140/people/wildebeest/projects/final/index.html another open source pump\n http://guides.teklalabs.org/c/Science_Lab_Equipment tekla labs\nhttp://blogs.lse.ac.uk/impactofsocialsciences/2014/08/05/oer-impact-map-open-university/ open lectures and their impact\nhttp://www.graphicsmagick.org/index.html image processing library\nhttp://www.kinectotherapy.in/\nhttp://www.oshwa.org/ open source hardware association page\nhttps://www.peerageofscience.org/how-it-works/ peerage of science\nhttp://www.linux-usb-daq.co.uk/ general IO boards for linux\nhttps://pubpeer.com/ post review of papers\n https://opensource.com/business/15/8/open-source-products-four-rules?utm_content=buffer7c7ae\u0026amp;utm_medium=social\u0026amp;utm_source=facebook.com\u0026amp;utm_campaign=buffer Open source for products\n[http://journal.frontiersin.org/article/10.3389/fnins.2015.00206/full?utm_source=newsletter\u0026amp;utm_medium=email\u0026amp;utm_campaign=Neuroscience-w33-2015 spinnaker. millisecond](http://journal.frontiersin.org/article/10.3389/fnins.2015.00206/full?utm_source=newsletter\u0026amp;utm_medium=email\u0026amp;utm_campaign=Neuroscience-w33-2015 spinnaker. millisecond) range modelling\nhttp://wiki.openscienceschool.com/wiki/Tools/DI-Lambda do it yourself spectrophotometer\nhttp://thurj.org/research/2011/01/432/ automated head fixed prep for rats\n http://journal.frontiersin.org/article/10.3389/fninf.2015.00004/full?utm_source=newsletter\u0026amp;utm_medium=email\u0026amp;utm_campaign=Neuroscience-w17-2015 map reduce, scalable data analysis for ephys\n www.elsevier.com/connect/the-changing-face-of-journal-metrics the changing face of journal metrics\nhttp://www.johnstowers.co.nz/blog/2014/05/27/flymad/ fly brain altering device\nhttps://jupyter.org/ open source notebook for over 40 programming languages\nhttps://sites.google.com/site/neurorighter/ closed loop recording and stimulation ephys\nhttp://www.kitware.com/opensource/opensource.html several open source software suites/libraries\nhttps://jasp-stats.org/ a fresh way to do statistics\nhttp://www.brain-map.org/ allen institute page with data, tools and maps\nhttps://www.circuitlab.com/\n www.123dapp.com/circuits\nhttps://madresistor.org/box0/\nhttps://zenodo.org/\nhttps://ipfs.io/\n The next wave in software is open adoption software  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4933559/pdf/1604.pdf\n https://www.rs-online.com/designspark/the-teaching-lab-of-tomorrow?cm_mmc=DE-EM-_-DSN_20160822-_-DM3300-_-TTB_URL2\u0026amp;cid=DM3300\u0026amp;bid=53290840\nhttp://www.nytimes.com/2016/06/28/technology/amazon-unveils-online-education-service-for-teachers.html?_r=5®ister=google\nhttps://www.hackster.io/arduino\nhttp://brainwaves.io/wp/\nhttp://www.mkme.org/\nhttps://outernet.is/\nhttps://hackaday.io/project/16024-openwheel-parametric-osh-wheelstyrestracks\nhttp://journals.plos.org/plosone/article?id=10.1371/journal.pone.0166735#sec016\nhttps://hackaday.io/project/18643-open-source-freakin-scanning-electron-microscope open source electron microscope\nhttp://jn.physiology.org/content/116/2/252.long Open notebooks on ephys\nhttp://www.instructables.com/id/Laser-Scanning-Microscope/ make a laser scanning microscope\nhttps://github.com/maxritter/DIY-Thermocam DIY thermal camera\nhttps://neuinfo.org/about/organization neuroscience information framework\nhttps://publishing.aip.org/publishing/journal-highlights/how-3-d-print-your-own-sonic-tractor-beam DIY sonic tractor beam\nhttp://www.upb.edu/en/contenido/mini-spectrometer-3d-printable-model DIY spectrometer\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4857158/pdf/ac5b04153.pdf lab on a drone\nhttp://oceanographyforeveryone.com/ page hosting hardware projects related to oceanography\nhttps://makingscience.withgoogle.com/science-journal?lang=en google app for data collection using mobile phone sensors\nhttp://3d.si.edu/browser smithsonian museum repository of scanned objects\nhttps://nasa3d.arc.nasa.gov/models nasa models for 3d p nting\nhttp://www.qtiplot.com/ Data analysis and visualization\nhttps://github.com/BigCorvus/Physio hacked medical device\nhttps://mousetube.pasteur.fr/ mouse vocalization database\nhttp://www.thinkering.de/cms/ blog on tinkering with science tool examples\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"02726fb579b942abbbe25e9b838d4692","permalink":"https://open-neuroscience.com/en/post/backlog/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/backlog/","section":"post","summary":"Bellow is a list of interesting projects related to science and research, that we didn\u0026rsquo;t have time to curate yet. Feel free to browse through them and make comments and suggestions!","tags":["Topic"],"title":"Backlog","type":"post"},{"authors":[""],"categories":["Computer clusters"],"content":"\nHere are two projects that use card sized computers as the basic units for computing clusters:\n A 64 node cluster, build using pi’s and lego, built at the University of Southampton.  BeagleBone Black cluster by Dan Ricart  ","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"d1ecb2871272481f39ccad7a83fc75da","permalink":"https://open-neuroscience.com/en/post/computer_cluster/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/computer_cluster/","section":"post","summary":"Here are two projects that use card sized computers as the basic units for computing clusters:\n A 64 node cluster, build using pi’s and lego, built at the University of Southampton.","tags":["Computer clusters"],"title":"Computer clusters","type":"post"},{"authors":[""],"categories":["Microscope","Hardware"],"content":"OpenFlexure is a 3D printed flexure translation stage, developed by a group at the Bath University. The stage is capable of sub-micron-scale motion, with very small drift over time. Which makes it quite good, among other things, for time-lapse protocols that need to be done over days/weeks time, and under space restricted areas, such as fume hoods. A paper describing it in detail can be found here.\nAdding a camera and servo motors, turns the stage into an automated microscope. More details about the project can be found here.\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"2df44df0573016548feae495e19ae7da","permalink":"https://open-neuroscience.com/en/post/openflexure/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/openflexure/","section":"post","summary":"OpenFlexure is a 3D printed flexure translation stage, developed by a group at the Bath University. The stage is capable of sub-micron-scale motion, with very small drift over time. Which makes it quite good, among other things, for time-lapse protocols that need to be done over days/weeks time, and under space restricted areas, such as fume hoods.","tags":["Microscope","Hardware"],"title":"OpenFlexure","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":" OpenFuge describes all the materials and gives step by step instructions to the assembly of a centrifuge that is able to deliver 6000 G’s of force and to rotate at 9000 RPM, while being able to hold 4 eppendorf tubes. Developed by CopabX\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"bbfc8b4764d87f57cf240395c3707654","permalink":"https://open-neuroscience.com/en/post/openfuge/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/openfuge/","section":"post","summary":"OpenFuge describes all the materials and gives step by step instructions to the assembly of a centrifuge that is able to deliver 6000 G’s of force and to rotate at 9000 RPM, while being able to hold 4 eppendorf tubes.","tags":["Benchtop","Hardware"],"title":"OpenFuge","type":"post"},{"authors":[""],"categories":["Software"],"content":"\nRoughly put, psychophysics studies the relationships of physical stimuli and their respective elicited sensations and perception. Psyhophysics also relates to the techniques used to probe these relationships and the toolboxes here presented are mainly dealing with these techniques.\n   OpenSesame is a graphical opensource experiment builder. It has drag and drop features as well as customization possibilities, via python scripting and custom plugins. here is a link to a paper describing the software  Psychtoolbox, or PTB, is a free versatile toolbox to be used mainly in visual experiments, it is able to deliver visual and auditory stimuli and to receive subject input. It has a big quantity of active users (15,000 as stated on their website) what should make the life of the beginner user somehow easier (they have a forum page) The latest version (PTB-3 as this page was written) is able to run under MATLAB (version 7.X) and Octave (version 3.2.X) in any of the three main operational systems out there (Mac, Windows and Linux). A paper describing the toolbox can be found here.\n   PsychoPy is also a free toolbox that can be used to deliver visual and auditory stimuli and receive inputs from subjects, on top of keyboard, mouse and button boxes, it also supports serial and parallel ports and compiled drivers (allowing interface with pretty much any hardware installed in your computer). It is written in Python, and it can be used with Windows, Mac or Linux. Two papers describing the toolbox can be found here and here.\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"5e1bbde04da89f9f2d1e0c08a5ca4fbe","permalink":"https://open-neuroscience.com/en/post/psychophysics-toolboxes/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/psychophysics-toolboxes/","section":"post","summary":"Roughly put, psychophysics studies the relationships of physical stimuli and their respective elicited sensations and perception. Psyhophysics also relates to the techniques used to probe these relationships and the toolboxes here presented are mainly dealing with these techniques.","tags":["Software"],"title":"Psychophysics toolboxes","type":"post"},{"authors":null,"categories":["Optogenetics","Hardware"],"content":" Pulse Pal is an open and inexpensive (~$210) alternative to pulse generators used in neurophysiology research, and is most often used to create precisely timed light trains in optogenetics assays. Pulse Pal generates four channels of configurable square pulse trains ranging in voltage from +10 to -10V using a bipolar DAC. Two digital trigger channels can be used to start and stop playback. APIs are available in C++, Python and MATLAB, and the hardware designs and firmware are fully open source.\n Be sure to check the paper about it and their wiki page.\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"80fe26a3777136de1c8977138e3e22a0","permalink":"https://open-neuroscience.com/en/post/pulse-pal/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/pulse-pal/","section":"post","summary":"Pulse Pal is an open and inexpensive (~$210) alternative to pulse generators used in neurophysiology research, and is most often used to create precisely timed light trains in optogenetics assays.","tags":["Optogenetics","Hardware"],"title":"Pulse Pal","type":"post"},{"authors":[""],"categories":["Software"],"content":"Python is a free programming language that is widely used, most of the software developed for Linux is written in Python. It contains several libraries that cover a lot of problem domains, from asynchronous processing to zip files. Also it is available for most platforms. More information can be found at the language official page.\nMore specifically to scientific computation, the NumPy project brings n-dimension array objects, random number capabilities, fourier transforms and many other useful tools.\nBoosting NumPy capabilities is SciPy, which is another Python library that adds signal processing, optimization and statistical tools to Python.\nAfter all the calculations are done, they can be plotted also using python and another useful library: Matplotlib.\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"be75ea560121d891706f3973e88d7781","permalink":"https://open-neuroscience.com/en/post/python-numpy-scipy-matplotlib/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/python-numpy-scipy-matplotlib/","section":"post","summary":"Python is a free programming language that is widely used, most of the software developed for Linux is written in Python. It contains several libraries that cover a lot of problem domains, from asynchronous processing to zip files.","tags":["Software"],"title":"Python, NumPy, SciPy \u0026 Matplotlib","type":"post"},{"authors":[""],"categories":["Computers","Hardware"],"content":" Red Pitaya is an computer+FPGA that has digital input and outputs and really fast analog inputs and outputs. It allows connection over ethernet and programming of custom routines. The system is powerful enough to have application in mostly all branches of neuroscience labs: oscilloscopes, signal generators and even a candidate for recording systems.\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"f46a9596ad3cd0eccc257bd641733995","permalink":"https://open-neuroscience.com/en/post/red-pitaya/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/red-pitaya/","section":"post","summary":"Red Pitaya is an computer+FPGA that has digital input and outputs and really fast analog inputs and outputs. It allows connection over ethernet and programming of custom routines. The system is powerful enough to have application in mostly all branches of neuroscience labs: oscilloscopes, signal generators and even a candidate for recording systems.","tags":["Computers","Hardware"],"title":"Red Pitaya","type":"post"},{"authors":null,"categories":["Learning"],"content":"School of Data is a global network that aims to train civil society in the practical use of the large amount of data available nowadays.\nThe network is composed of individuals and organizations that carry out training programs, hands-on courses and other activities in different regions and countries of the world. They also offer fellowships and experts programs to prepare new people in different parts of the world to continue with the training process and the application of the ideas of School of Data organization.\nIn the web page you can also find open material about basic concepts of data analysis and the methodological approach considered appropriate.\nThe school in numbers\n more than 6000 people trained 44 learning modules 13 member organizations 100 individual members 34 countries represented  For more information visit the webpage: https://schoolofdata.org/\n","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"d3497d4afa3774077a0711598b090cba","permalink":"https://open-neuroscience.com/en/post/school_of_data/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/school_of_data/","section":"post","summary":"School of Data is a global network that aims to train civil society in the practical use of the large amount of data available nowadays.\nThe network is composed of individuals and organizations that carry out training programs, hands-on courses and other activities in different regions and countries of the world.","tags":["Learning"],"title":"School of Data","type":"post"},{"authors":[""],"categories":["Software"],"content":"A brief description of their current software (09.Sep.2016) is provided by one of their founders, Mattias Karlsson:\n State Script:\nDo you need to control lasers for optogenetics, stimulators, or other TTL-based devices with precise, temporally defined patterns? Do you need to monitor beam breaks, lever presses, or other digital events in real time to define behavioral tasks? You could program an Arduino, but that’s a lot of work. Or, you can use StateScript, which allows users with minimal programming experience define complex input/output relationships for the most demanding hardware control experiments.\n This open-source project now runs on two available hardware platforms, the MBED LPC1768 micro controller board ($50) and the SpikeGadgets electrophysiology and behavioral control system. More hardware support in is the works. A software interface, which is part of the Trodes open-source eletrophysiology suite (http://www.spikegadgets.com/software/trodes.html), allows you to upload scripts and dynamically interact with variables and ports states.\nAnyone is welome to contribute. Here is the bitbucket repo.\n    Trodes:\nTrodes is a software suite with a focus on data acquisition for extracellular neural recordings. It has a growing user base and welcomes contributors with open arms! It is built using the ever-popular and powerful Qt C++ framework. While it is specialized to be used with SpikeGadgets’ ephys hardware, it also has built-in support for the Intan demo system and Open-Ephys hardware.\nIt has some pretty impressive capabilities, including visualization of thousands of channels, spike viewing, online spike sorting, and low latency feedback control. It has video processing, allowing position tracking that is synchronized to the recording, and integrates powerful environment control (lasers for optogenetics, levers, lights, pumps, etc.) with StateScript.\n Trodes interface Trodes  ","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"688c0e13ed77ed90c3fbdd8c41068e73","permalink":"https://open-neuroscience.com/en/post/spike-gadgets/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/en/post/spike-gadgets/","section":"post","summary":"A brief description of their current software (09.Sep.2016) is provided by one of their founders, Mattias Karlsson:\n State Script:\nDo you need to control lasers for optogenetics, stimulators, or other TTL-based devices with precise, temporally defined patterns?","tags":["Software"],"title":"Spike Gadgets","type":"post"},{"authors":null,"categories":["Software","Human Ephys"],"content":" BrainFlow BrainFlow is a library intended to obtain, parse and analyze EEG, EMG, ECG and other kinds of data from biosensors, it provides two APIs:\n Data Acquisition API to obtain data from BCI boards Signal Processing API which is completely independent and can be used without Data Acquisition API  Both of these APIs are uniform for all supported boards, so it allows to write completely board agnostic code.\nBrainFlow has bindings for:\n C++ Python Java C# R  And provides almost the same API for all languages above.\nCheck BrainFlow Docs for details.\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"2e0c47d0b9f49dcb08a5b7159f6fb37f","permalink":"https://open-neuroscience.com/en/post/brainflow/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/brainflow/","section":"post","summary":"BrainFlow BrainFlow is a library intended to obtain, parse and analyze EEG, EMG, ECG and other kinds of data from biosensors, it provides two APIs:\n Data Acquisition API to obtain data from BCI boards Signal Processing API which is completely independent and can be used without Data Acquisition API  Both of these APIs are uniform for all supported boards, so it allows to write completely board agnostic code.","tags":["Software","Human Ephys"],"title":"Brainflow","type":"post"},{"authors":[""],"categories":["Database"],"content":"  GenomeRNAi  is a database containing phenotypes from RNA interference (RNAi) screens in Drosophila and Homo sapiens. In addition, the database provides an updated resource of RNAi reagents and their predicted quality.\n  ","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"c3030febaac3544f5ef983a73404fb7e","permalink":"https://open-neuroscience.com/en/post/genome-rnai/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/genome-rnai/","section":"post","summary":"GenomeRNAi  is a database containing phenotypes from RNA interference (RNAi) screens in Drosophila and Homo sapiens. In addition, the database provides an updated resource of RNAi reagents and their predicted quality.","tags":["Database"],"title":"Genome RNAi","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":" GogoFuge is a good example of the power of opensource designs. IT was based on the idea of the DremelFuge and altered to be a tabletop centrifuge with vortex capability. It was created by Keegan Cooke\n ","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"bf9f325cd7e7d5adb9addf93f370c45a","permalink":"https://open-neuroscience.com/en/post/gogofuge/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/gogofuge/","section":"post","summary":"GogoFuge is a good example of the power of opensource designs. IT was based on the idea of the DremelFuge and altered to be a tabletop centrifuge with vortex capability.","tags":["Benchtop","Hardware"],"title":"GogoFuge","type":"post"},{"authors":[""],"categories":["Simulation"],"content":" The Green Brain project wants to create an artificial Apis mellifera brain and implement said brain into a robot, that will be able to fly and and behave just like a honey bee!\nThe reasons for this project are:\n The bee brain has way less neurons than the brain of rodents (but still in the order of 10^6 neurons!), so understanding how this simple brain works could be a nice step towards understanding more complex brains. The bee population has been declining and scientists are not exactly sure why. Understanding bee behaviour and the organ that produces them might help solve the problem Improvement of unmanned aerial vehicle control  ","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"4bb94faaa1e7caa565b5381f9851153e","permalink":"https://open-neuroscience.com/en/post/green-brain/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/green-brain/","section":"post","summary":"The Green Brain project wants to create an artificial Apis mellifera brain and implement said brain into a robot, that will be able to fly and and behave just like a honey bee!","tags":["Simulation"],"title":"Green Brain","type":"post"},{"authors":[""],"categories":["Software"],"content":"If you are using Linux, changes are that this page is not that useful for you, since most of these programs come installed by default. For you who are not yet into linux, most of these programs have Windows/Mac versions:\nOffice suites (spreadsheet calculation, slide manufacturing , document writing):\n Open Office\n Libre Office\nImage manipulation programs (vectorized images or photoshop style):\n Inkscape\n Gimp\n3D modelling (to create animations, solids or even things that can be printed):\n FreeCad\n Blender\n OpenScad\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"478fa85f594ef328dcb37657f2584fec","permalink":"https://open-neuroscience.com/en/post/image-office-suits-and-other-general-purpose-software/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/image-office-suits-and-other-general-purpose-software/","section":"post","summary":"If you are using Linux, changes are that this page is not that useful for you, since most of these programs come installed by default. For you who are not yet into linux, most of these programs have Windows/Mac versions:","tags":["Software"],"title":"Image, Office suites, and other general purpose software","type":"post"},{"authors":[""],"categories":["Prosthetics","Hardware"],"content":"Ojoshi at instructables.com has posted a manual on how to build this arduino based hearing aid system.\nFrom his instructables page:\n it has tuning functionality that allows the wearer to tune the amplification to his or her needs. It has a conversational mode which recognizes voice input and amplifies it while reducing background noise. It saves all data to memory so that the device can be quickly powered up and ready to use. This device also has a very easy user interface to keep operation quick and simple.\n  If you are going to try and build this, take maximum care and do it at your own risk!\n  from: http://cdn.instructables.com/F5D/JQVI/HOUFWUWY/F5DJQVIHOUFWUWY.LARGE.jpg\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"58d2538e11c514ebbc83e609ccdf5a8c","permalink":"https://open-neuroscience.com/en/post/intelligent-hearing-aid/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/intelligent-hearing-aid/","section":"post","summary":"Ojoshi at instructables.com has posted a manual on how to build this arduino based hearing aid system.\nFrom his instructables page:\n it has tuning functionality that allows the wearer to tune the amplification to his or her needs.","tags":["Prosthetics","Hardware"],"title":"Intelligent hearing aid","type":"post"},{"authors":[""],"categories":["Software"],"content":"IPipet is a neat system to help you not to lose track of which wells you have already pipetted in or from. The idea is simple, you place a tablet running a link with your specific pipetting protocol under your source and destination plates. The tablet will illuminate the corresponding wells. After you pipette one sample, you press next on the tablet and the next sample will be illuminated. For more details watch the video (below) and visit the project\u0026rsquo;s homepage. They even have a 3D printable adaptor to prevent the well plate from slipping on the tablet surface.\n iPipet Demo from Team Erlich on Vimeo.\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"0a18b11c872412cacd611636d578e3f3","permalink":"https://open-neuroscience.com/en/post/ipipet/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/ipipet/","section":"post","summary":"IPipet is a neat system to help you not to lose track of which wells you have already pipetted in or from. The idea is simple, you place a tablet running a link with your specific pipetting protocol under your source and destination plates.","tags":["Software"],"title":"IPipet","type":"post"},{"authors":[""],"categories":["Software"],"content":"Since organisation of ideas, stocks, and projects is a major concern (or at least should be) of labs and researchers, here is a small compilation of cost free sofware to help out:\n  Quartzy is a free web based application (supported by life sciences related companies) it focuses on sharing protocols, tracking orders, manage lab inventory and shared quipment management.\n  eLabFTW is a management system created by Nicolas Carpi. It is opensource (which means each lab can customize it for special needs), free and it can be installed locally. Its online demo version focuses on experiment log, database (where drugs, chemicals, animal strains and etc can be logged) and team (where lab members can be listed).\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"37b675a87ad405a1e1cb0ba82ee69f03","permalink":"https://open-neuroscience.com/en/post/lab-management-software/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/lab-management-software/","section":"post","summary":"Since organisation of ideas, stocks, and projects is a major concern (or at least should be) of labs and researchers, here is a small compilation of cost free sofware to help out:","tags":["Software"],"title":"Lab management software","type":"post"},{"authors":[""],"categories":["Microscopes software"],"content":"Micro-Manager is an ImageJ plugin dedicated to the control of microscopes. Their intent is to have a “one fits all” software for the control of microscopes, stages, filters and cameras. A comprehensive list of supported devives can be found on devices section of the project webpage. As the other projects listed on this website, the software is open source and freely distributed.\n \n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"21ca12687a8a45b85f1218ce31a6c4f2","permalink":"https://open-neuroscience.com/en/post/micro-manager/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/micro-manager/","section":"post","summary":"Micro-Manager is an ImageJ plugin dedicated to the control of microscopes. Their intent is to have a “one fits all” software for the control of microscopes, stages, filters and cameras. A comprehensive list of supported devives can be found on devices section of the project webpage.","tags":["Microscopes software"],"title":"Micro-Manager","type":"post"},{"authors":[""],"categories":["Database"],"content":" NeuroMorpho.Org is a centrally curated inventory of digitally reconstructed neurons associated with peer-reviewed publications. It contains contributions from over 100 laboratories worldwide and is continuously updated as new morphological reconstructions are collected, published, and shared. (taken from neuromorpho.org)\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"c4e2d1b4a8d43cfb89b32b3f37695fd9","permalink":"https://open-neuroscience.com/en/post/neuromorpho/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/neuromorpho/","section":"post","summary":"NeuroMorpho.Org is a centrally curated inventory of digitally reconstructed neurons associated with peer-reviewed publications. It contains contributions from over 100 laboratories worldwide and is continuously updated as new morphological reconstructions are collected, published, and shared.","tags":["Database"],"title":"Neuromorpho","type":"post"},{"authors":[""],"categories":["Simulation","hardware"],"content":" NeuroTinker project is all about hardware emulated neurons. The creators made them in a way that each hardware neuron has excitatory and inhibitory inputs and one output that can be split up to affect dowsntream neurons. They are also cheap enough so that one can build several of them and wire them together to see which properties will emerge in the system. Design files are available on the project\u0026rsquo;s GitHub organization\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"34265d459ace94e13cbb254bebb65674","permalink":"https://open-neuroscience.com/en/post/neurotinker/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/neurotinker/","section":"post","summary":"NeuroTinker project is all about hardware emulated neurons. The creators made them in a way that each hardware neuron has excitatory and inhibitory inputs and one output that can be split up to affect dowsntream neurons.","tags":["Simulation","hardware"],"title":"NeuroTinker","type":"post"},{"authors":[""],"categories":["Data analysis"],"content":" NiBabel is a python package, under the NiPy project, that aims at unifying the process of opening different medical and neuroimaging file formats, including: ANALYZE, GIFTI, NIfTI1, MINC, MGH and ECAT as well as PAR/REC. The package is also able to read and write Freesurfer format.\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"2fdfa3083774ae7faf94b4d4e17b9c5f","permalink":"https://open-neuroscience.com/en/post/nibabel/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/nibabel/","section":"post","summary":"NiBabel is a python package, under the NiPy project, that aims at unifying the process of opening different medical and neuroimaging file formats, including: ANALYZE, GIFTI, NIfTI1, MINC, MGH and ECAT as well as PAR/REC.","tags":["Data analysis"],"title":"NiBabel","type":"post"},{"authors":[""],"categories":["Data analysis"],"content":" NiPy is an effort to make brain imaging research easier and more clear. This is implemented by providing a series of software that deal with file IO, analysis, and interfaces \u0026amp; pipelines.\nThe software present up to now (05/05/2020)\n nipype\n diPy\n mindboggle\n NiBabel\n scitran SDM\n nipy\n nitime\n popeye\n niLearn\n PyMVPA\n MNE\n niwidgets\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"5c1d34a54d17fc5f7672aa4b27484796","permalink":"https://open-neuroscience.com/en/post/nipy/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/nipy/","section":"post","summary":"NiPy is an effort to make brain imaging research easier and more clear. This is implemented by providing a series of software that deal with file IO, analysis, and interfaces \u0026amp; pipelines.","tags":["Data analysis"],"title":"Nipy","type":"post"},{"authors":[""],"categories":null,"content":"This is a small set of instructions on how to build a nose poke device for rats, using an arduino, some 3D printed parts and some off-the-shelf electronic components.\n\nAll the files necessary to reproduce this can be found here\nThe description is still not very detailed, but if something is not clear, do not hesitate to make contact! openeuroscience@gmail.com\nIf you ever use this informatíon, please cite it like this:\nChagas, Andre Maia (2014): Nose poke device using 3d printed parts and Arduino. figshare.\nhttp://dx.doi.org/10.6084/m9.figshare.1057762  ","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"e5c4b36e8e02942d803b937ff3aad1db","permalink":"https://open-neuroscience.com/en/post/nose-poke-device-for-rats-using-arduino-and-3d-printed-parts/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/nose-poke-device-for-rats-using-arduino-and-3d-printed-parts/","section":"post","summary":"This is a small set of instructions on how to build a nose poke device for rats, using an arduino, some 3D printed parts and some off-the-shelf electronic components.","tags":null,"title":"Nose poke device for rats using arduino and 3d printed parts","type":"post"},{"authors":[""],"categories":["Microscopes software"],"content":"The Open Microscopy Environment is a collaborative project between several labs. They are developing file formats and software standards for light microscopy.\nWithin the project they have BIO-formats, a Java library for reading and writing data. It can be used in ImageJ (it comes pre-packaged in FIJI and matlab.\n OMERO is a client-server software for storage and data-analysis of microscopy images.\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"3a40ec2145401e79601c2e11f9915f99","permalink":"https://open-neuroscience.com/en/post/ome-open-microscopy-environment/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/ome-open-microscopy-environment/","section":"post","summary":"The Open Microscopy Environment is a collaborative project between several labs. They are developing file formats and software standards for light microscopy.\nWithin the project they have BIO-formats, a Java library for reading and writing data.","tags":["Microscopes software"],"title":"Open Microscopy Environment","type":"post"},{"authors":[""],"categories":["Software"],"content":"Linux is an open source operating system and it is the major OS used in servers and supercomputers. Ubuntu, one of the best known distributions has been gaining space in the personal computing scene, now days already being factory shipped by major manufacturers.\nBut how practical is to migrate to a Linux distribution? Well, very. If one passes beyond the hassle of backing up data and installing a new OS, there are many advantages that come with it. For starters these OSs are safer than any Microsoft or Apple OS. There is a large community of users sharing solutions to problems, bugs and so on (there hasn’t been to today a widespread of any malware through Linux systems). Being open source, the distributions are perfect for customization, something really useful for science labs.\nA Small list of distributions that make a good starting point:\n  Debian  NeuroDebian (Debian oriented to neuroscience)  Ubuntu  Mint  OpenSuse  Fedora   ROS –\n The robot operating system is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.\n ","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"5aa98733563e71d73e6cebe21fb329e6","permalink":"https://open-neuroscience.com/en/post/linux-distributions/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/en/post/linux-distributions/","section":"post","summary":"Linux is an open source operating system and it is the major OS used in servers and supercomputers. Ubuntu, one of the best known distributions has been gaining space in the personal computing scene, now days already being factory shipped by major manufacturers.","tags":["Software"],"title":"Operating systems","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://open-neuroscience.com/en/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/en/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[""],"categories":["Prosthetics","Hardware"],"content":"Ever thought about making soft robots? The folks at Super-Releaser have, and they are doing very cool projects! Some for medical applications and some for research purposes. Check one of their cool robots below:\n  ","date":1458554412,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458554412,"objectID":"7a02a569e6ea2134095a4ecd1f79085f","permalink":"https://open-neuroscience.com/en/post/super_releaser/","publishdate":"2016-03-21T10:00:12Z","relpermalink":"/en/post/super_releaser/","section":"post","summary":"Ever thought about making soft robots? The folks at Super-Releaser have, and they are doing very cool projects! Some for medical applications and some for research purposes. Check one of their cool robots below:","tags":["Prosthetics","Hardware"],"title":"Super-Releaser","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":"The 5 dollar PCR machine is a project from David Ng.\nhe created a very interesting design for the PCR machine. Instead of using eppendorfs, he is using teflon tubes and three different heating elements, which allows for cheaper (he has a working PCR machine for 5 dollars!) and faster DNA amplifications.\n Here you can find the project page, with nice description and instructions\nBelow is a video from David explaining the project:\n ","date":1433843594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433843594,"objectID":"5a57fa6308a3ed2e6a1b98a60f1db169","permalink":"https://open-neuroscience.com/en/post/5_dollar_pcr/","publishdate":"2015-06-09T09:53:14Z","relpermalink":"/en/post/5_dollar_pcr/","section":"post","summary":"The 5 dollar PCR machine is a project from David Ng.\nhe created a very interesting design for the PCR machine. Instead of using eppendorfs, he is using teflon tubes and three different heating elements, which allows for cheaper (he has a working PCR machine for 5 dollars!","tags":["Benchtop","Hardware"],"title":"5 Dollar PCR machine","type":"post"},{"authors":[""],"categories":["Prosthetics","Hardware"],"content":" The Open bionics project was inspired by the Yale open hand project, aiming to develop light, affordable, and modular robot hands and myoelectric prosthesis. Also they want to make them easy to replicate using off the shelf materials. On the video below taken from their website you can see the hands in action, either as a prosthesis, or attached to a small drone being operated remotely.\n","date":1422745001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422745001,"objectID":"3baa5d1ba9b9ee3f354010e016417e8d","permalink":"https://open-neuroscience.com/en/post/open-bionics/","publishdate":"2015-01-31T22:56:41Z","relpermalink":"/en/post/open-bionics/","section":"post","summary":"The Open bionics project was inspired by the Yale open hand project, aiming to develop light, affordable, and modular robot hands and myoelectric prosthesis. Also they want to make them easy to replicate using off the shelf materials.","tags":["Prosthetics","Hardware"],"title":"Open bionics","type":"post"},{"authors":[""],"categories":["Hardware"],"content":"With the rise of low cost 3D printers, and other cheap manufacturing tools, the field of robotics and prosthetics has been gaining quite a few open source projects. Two very nice compilations can be found at openrobot hardware and at Soft robotics toolkit. Below are some related to neuroscience:\n The open hand project\n The Yale open hand project\n Openbionics\n Fingertip laser sensor\n takktile\n","date":1422742096,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422742096,"objectID":"72aa6845431d02bdb3872afb8fced24c","permalink":"https://open-neuroscience.com/en/post/prosthetics-and-robotics/","publishdate":"2015-01-31T22:08:16Z","relpermalink":"/en/post/prosthetics-and-robotics/","section":"post","summary":"With the rise of low cost 3D printers, and other cheap manufacturing tools, the field of robotics and prosthetics has been gaining quite a few open source projects. Two very nice compilations can be found at openrobot hardware and at Soft robotics toolkit.","tags":["Hardware"],"title":"Open prosthetics and robotics","type":"post"},{"authors":[""],"categories":["Animal ephys","Hardware"],"content":" Backyard brains started out producing low cost, portable, electrophysiology systems to bring neuroscience to classrooms and help promote it.\n“Backyard brains wants to be for neuroscience, what the telescope is for astronomers” – meaning that the idea is that with a couple of hundred dollars anyone can get one of these recording systems and start doing experiments, like amateur astronomers can buy telescopes and start observing the cosmos.\n ","date":1359417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1359417600,"objectID":"5f8ea3cdb1a43500ecf220889108a038","permalink":"https://open-neuroscience.com/en/post/backyard_brains/","publishdate":"2013-01-29T00:00:00Z","relpermalink":"/en/post/backyard_brains/","section":"post","summary":"Backyard brains started out producing low cost, portable, electrophysiology systems to bring neuroscience to classrooms and help promote it.\n“Backyard brains wants to be for neuroscience, what the telescope is for astronomers” – meaning that the idea is that with a couple of hundred dollars anyone can get one of these recording systems and start doing experiments, like amateur astronomers can buy telescopes and start observing the cosmos.","tags":["Animal ephys","Hardware"],"title":"Backyard Brains","type":"post"},{"authors":[""],"categories":["Microscope","Hardware"],"content":"This neat little project uses some plexi-glass, lens extracted from a laser pointer to harvest the power of smartphone cameras for some very big amplifications! Yoshinok manged to see cell plasmolysis and some other cool features with it.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8dfac25e9e8b285b907d240ed63b4d64","permalink":"https://open-neuroscience.com/en/post/10_smartphone_microscope/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/10_smartphone_microscope/","section":"post","summary":"This neat little project uses some plexi-glass, lens extracted from a laser pointer to harvest the power of smartphone cameras for some very big amplifications! Yoshinok manged to see cell plasmolysis and some other cool features with it.","tags":["Microscope","Hardware"],"title":"10$ smartphone microscope","type":"post"},{"authors":[""],"categories":["Database"],"content":" Addgene is a non-profit company that makes the share of plasmids easier by making a plasmid database and linking them to the papers where they were described. In this way they take on the job of maintaining plasmids and shipping them to requesting scientists.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0be1ebe55a5738ec3bd8401903436297","permalink":"https://open-neuroscience.com/en/post/addgene/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/addgene/","section":"post","summary":"Addgene is a non-profit company that makes the share of plasmids easier by making a plasmid database and linking them to the papers where they were described. In this way they take on the job of maintaining plasmids and shipping them to requesting scientists.","tags":["Database"],"title":"Addgene","type":"post"},{"authors":[""],"categories":["Database"],"content":" The Brain Map is one of the initiatives of the Allen Institute.\nIt is a data portal that encompasses different projects:\n the Allen Institute has created a set of large-scale programs to understand the fundamentals of the cortex. We will be focusing our understanding through simultaneous study of the brain\u0026rsquo;s components, computation and cognition.\nthe Allen Institute has produced a collection of open science resources that give users a powerful way to explore gene expression data, neural connections, single cell characterization and neuroanatomy. All of our resources are openly accessible via the Allen Brain Atlas data portal.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a8b838485369e2cabb335ea18f89cfc0","permalink":"https://open-neuroscience.com/en/post/allen-brain-map/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/allen-brain-map/","section":"post","summary":"The Brain Map is one of the initiatives of the Allen Institute.\nIt is a data portal that encompasses different projects:\n the Allen Institute has created a set of large-scale programs to understand the fundamentals of the cortex.","tags":["Database"],"title":"Allen Brain Map","type":"post"},{"authors":[""],"categories":["Human ephys","Hardware"],"content":" Attys is an wearable data acquisition device with a special focus on biomedical signals such as heart activity (ECG), muscle activity (EMG) and brain activity (EEG). It’s open firmware, open API and has open source applications on github in C++ and JAVA to encourage people to create their own custom versions for mobile devices, tablets and PC.\nThe story of the Attys started when Dr. Bernd Porr filmed numerous youTube clips to educate the public about the possibilities and limits of biosignal measurement (http://biosignals.berndporr.me.uk) which are featured here: BPM link\nThe site has been very popular ever since and visitors have been asking if a ready made bio-amp could be made available. This year Dr. Porr then decided to make one. This was the birth of the Attys.\nAttys is also a general educational tool to measure any physical quantity such as temperature, pressure or light intensity. It works with Google’s open source Science Journal and turns every Android phone or tablet into an electronic lab book / oscilloscope. Of course one can measure biosignals with it, too.\nVasso Georgiadou has been the main presenter for our biosignal channel. Here, she shows off the Attys:\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"eb975de2a983ab6e9ed4eb7ae8ec0245","permalink":"https://open-neuroscience.com/en/post/attys/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/attys/","section":"post","summary":"Attys is an wearable data acquisition device with a special focus on biomedical signals such as heart activity (ECG), muscle activity (EMG) and brain activity (EEG). It’s open firmware, open API and has open source applications on github in C++ and JAVA to encourage people to create their own custom versions for mobile devices, tablets and PC.","tags":["Human ephys","Hardware"],"title":"Attys","type":"post"},{"authors":[""],"categories":["Visual","Hardware"],"content":"This project uses a 32X32 LED array (1024 LEDs in total) and a beagle bone black board. The page describing the project has very nice explanations on how the whole system works (and LED displays in general).\nFrom this project, the creator Glen Akins, went on to construct a 3X2 matrix of 32X32 LEDS, or a total of 6144 RGB LEDs that have a 200Hz refresh rate! Check out the video below of the panel in action:\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a97f19a622c785de93ada94b27853849","permalink":"https://open-neuroscience.com/en/post/bb_led_matrix/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/bb_led_matrix/","section":"post","summary":"This project uses a 32X32 LED array (1024 LEDs in total) and a beagle bone black board. The page describing the project has very nice explanations on how the whole system works (and LED displays in general).","tags":["Visual","Hardware"],"title":"BB LED Matrix","type":"post"},{"authors":[""],"categories":["Simulation"],"content":"Big Neuron wants to create a standard for the field of single neuron reconstruction. Because the data available comes from different structures, different organisms, using different collection and analyses algorithms and is in the range of petabytes (according to the project site), there is a strong need for standards that will allow this huge amount of data to be compared.\nThe project aims to develop a common platform and algorithms for data analysis to benchmark as many open source neuronal reconstruction models as possible.\nFor more information visit their GitHub repository.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9f97b6accb4e98fba099c25c554d8e1b","permalink":"https://open-neuroscience.com/en/post/big-neuron/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/big-neuron/","section":"post","summary":"Big Neuron wants to create a standard for the field of single neuron reconstruction. Because the data available comes from different structures, different organisms, using different collection and analyses algorithms and is in the range of petabytes (according to the project site), there is a strong need for standards that will allow this huge amount of data to be compared.","tags":["Simulation"],"title":"Big Neuron","type":"post"},{"authors":[""],"categories":["Visual","Hardware"],"content":" Blinkenschild is a portable sign consisting of 960 RGB LEDs. The images/movies to be displayed are stored in a SD card in a Teensy3 board and controlled via bluetooth. Resolution is not as high as LCD monitors but the refresh rate is much higher:\nThis is done in realtime and pixelvalues are recalculated before display. This is still too fast so i had to add 30 ms delay between the frames or we would not perceive it as a fluid animation but rather just blinking bright light.   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"73e1c6a930a1859bcdf0296764202796","permalink":"https://open-neuroscience.com/en/post/blinkeschild/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/blinkeschild/","section":"post","summary":"Blinkenschild is a portable sign consisting of 960 RGB LEDs. The images/movies to be displayed are stored in a SD card in a Teensy3 board and controlled via bluetooth. Resolution is not as high as LCD monitors but the refresh rate is much higher:","tags":["Visual","Hardware"],"title":"Blinkenschild","type":"post"},{"authors":[""],"categories":["Computer clusters"],"content":"Boinc is a platform for volunteer computing. Briefly, volunteer computer is a system where computer processor\u0026rsquo;s idle time (those periods where your computer is on, but not being used for anything) is turned into calculation time via a custom written software.\nThis idea got a lot of attention with the seti@home project, where the computers of volunteers were transformed into a sort of supercomputer to analyse radio telescope date.\nThe Boinc project provides a platform where different projects can be created and launched on the platform\u0026rsquo;s website. Once online, volunteers can decide to which project they want to spare their computer cycles and help crushing numbers. Currently (11/12/14) the platform has about 229,396 active volunteers on 751,864 computers. with a 24-hour average of 8.024 PetaFLOPS. (not bad!)\nProjects come from universities as well as private sector and range from medicine and mathematics to games.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"49cb4d826ee7dd248a8a4d5caeeea6b9","permalink":"https://open-neuroscience.com/en/post/boinc/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/boinc/","section":"post","summary":"Boinc is a platform for volunteer computing. Briefly, volunteer computer is a system where computer processor\u0026rsquo;s idle time (those periods where your computer is on, but not being used for anything) is turned into calculation time via a custom written software.","tags":["Computer clusters"],"title":"Boinc","type":"post"},{"authors":[""],"categories":["Human ephys","Hardware"],"content":"BPM Biosignal is a two stage amplifier created mainly for educational purposes.\nCheck their YouTube Channel.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7acac75a3647257aea1e66df8b3ab822","permalink":"https://open-neuroscience.com/en/post/bpm_biosignal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/bpm_biosignal/","section":"post","summary":"BPM Biosignal is a two stage amplifier created mainly for educational purposes.\nCheck their YouTube Channel.","tags":["Human ephys","Hardware"],"title":"BPM Biosignal","type":"post"},{"authors":[""],"categories":["Human ephys","Hardware"],"content":" BrainMap expands the accessible DIY projects for brain activity measurements.\nThis is the conclusion project of Patrick Dear and Mark Bunney Jr. at Cornell university where they used infrared leds to measure differences in blood flow at the scalp and map the motor cortex.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cfa9d4a973b970ec95e4efa876a28eae","permalink":"https://open-neuroscience.com/en/post/brain_map/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/brain_map/","section":"post","summary":"BrainMap expands the accessible DIY projects for brain activity measurements.\nThis is the conclusion project of Patrick Dear and Mark Bunney Jr. at Cornell university where they used infrared leds to measure differences in blood flow at the scalp and map the motor cortex.","tags":["Human ephys","Hardware"],"title":"Brain Map","type":"post"},{"authors":[""],"categories":["Data analysis"],"content":"BrainBrowser is a collection of open source, web-based 3D data visualization tools, mainly for neuroimaging studies. It is built using open technologies such as WebGL and HTML5. It allows exploration of cortical surface models (MNI and Wavefront OBJ, as well as FreeSurfer ASCII surface format) and volumetric MINC data. This project is currently maintained by Tarek Sherif at McGill University, and the source code is available on GitHub.\nYou can find more info on the website\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2e8b80b10b57c70af5e96ee007812c7","permalink":"https://open-neuroscience.com/en/post/brainbrowser/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/brainbrowser/","section":"post","summary":"BrainBrowser is a collection of open source, web-based 3D data visualization tools, mainly for neuroimaging studies. It is built using open technologies such as WebGL and HTML5. It allows exploration of cortical surface models (MNI and Wavefront OBJ, as well as FreeSurfer ASCII surface format) and volumetric MINC data.","tags":["Data analysis"],"title":"BrainBrowser","type":"post"},{"authors":[""],"categories":["Software"],"content":"Motion tracking can be really useful in neurosciences, for automatic measurements of behaviour, among other things. Here you’ll find a small list of tracking softwares or libraries used to build such softwares:\n Complete softwares:\n   Ctrax\n  [](https://i0.wp.com/ctrax.sourceforge.net/images/ctrax-logo2b_128.png)taken from: http://ctrax.sourceforge.net/index.html    Ctrax is an open-source, freely available, machine vision program for estimating the positions and orientations of many walking flies, maintaining their individual identities over long periods of time. It was designed to allow high-throughput, quantitative analysis of behavior in freely moving flies.\n     The bio tracking project, designed for multiple object tracking, developed at Georgia tech: http://www.bio-tracking.org/  \n   Community Core Vision: Built with computer vision and machine sensing in mind, they mention multi touch applications as one of their focus on the website. http://ccv.nuigroup.com/  \n    Motion Tracking using python: Independent developed software by Derek Simkowiak, in a project he ran a couple of years back with his daughter, to track Gerbills  \n    Tracking-Learning-Detection: Developed by Zdenek Kalal this software intends to track pretty much anything (object determination can be done via mouse) in real time and to learn features from the object as tracking goes on.  \n    Open Vision Control: Developed on top of OpenCV (see below) in Python, it is a general purpose tracking software with several applications  \n   SwisTrack: Developed at EPFL, it is also a tracking system for multiple objects   From http://en.wikibooks.org/wiki/Swistrack\n http://infoscience.epfl.ch/record/85929 http://infoscience.epfl.ch/record/125704     Tracking software for Drosophila, by Colomb et al.   Computer vision/tracking libraries:\n Open CV is a library for machine learning and computer vision. It is written for different computer languages and different operational systems.\n The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc.\n   Simple CV is a framework that tries to simplify the development of software that require computer vision/machine learning, since a lot of researchers have the necessity of building on such concepts, but sometimes don’t have the time/training necessary to do so.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"72cf0380d14f8791fa66cd44c7aedd35","permalink":"https://open-neuroscience.com/en/post/computer-vision-and-motion-tracking-software/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/computer-vision-and-motion-tracking-software/","section":"post","summary":"Motion tracking can be really useful in neurosciences, for automatic measurements of behaviour, among other things. Here you’ll find a small list of tracking softwares or libraries used to build such softwares:","tags":["Software"],"title":"Computer Vision and motion tracking software","type":"post"},{"authors":[""],"categories":["Other"],"content":"As many other things that are being decentralized with the advent of the internet, so is research. One of the very things being decentralized is the funding source for research projects. This movement is called crowdfunding, and it is already present and strong for other areas, such as funding of technological, and social projects. They are organized via specialised websites that puts people needing funding with people who are willing to support it:\nThe idea is somewhat simple. Researchers make a video of what their project/research idea is and ask for a certain value to fund the project. If people find the idea interesting they make a donation via the website hosting that project.\nThere are normally two types of funding options, fixed, where the researchers only get the money pledged if the donations reach that value (or pass it, and if the minimum is not reached the money is returned to the pledgers), or variable where the researchers get to keep the money raised even if it didn’t reach the amount pledged for. In both cases the website keeps a percentage of the money raised in case the funding is successful.\nArticles about it can be founded here and here\nSome crowdfunding sources are listed below:\nhttp://www.sciencestarter.de/ – Research crowdfunding portal based in germany\n https://www.microryza.com/ – Research crowdFunding portal based in the US. (update – this is now called experiment.com)\n www.kickstarter.com – A Crowdfunding portal that also works for science projects. Currently (as in 02.02.14) only for projects based on the US, Canada, UK, Australia and New Zealand.\n www.indiegogo.com Also a crowdfunding portal that has science related projects. Differently from kickstarter, they support projects from all over the world, except countries in the US OFAC sanctions list\nhttps://www.crowdsupply.com/ is another crowdfunding portal, based in the US, that focus on product development.\nhttp://www.ulule.com/ – A crowdfunding portal based in Europe. They have a nice post on crowdfunding history\n www.petridish.org Research crowdfunding portal, but it seems that they haven’t been taking new projects for a while (since February 2013)\nwww.sciflies.org – Research crowdfunding portal based in Florida, their differential is that all projects posted there have to be approved by an anonymous peer review process, currently done by the American Association for Advancement of science. And 100% of the money goes to the project, there are no administrative fees. It was not clear from the website if only US based projects are funded\nhttp://www.rockethub.com/ – General crowdfunding portal, that has also a science division where everyone can start a project.\n scifundchallenge.org – Built and maintained by the open science federation, this project has three main “departments”, all trying to bridge the gap in between science and the general public: Teach and encourage scientists to outreach, connect the public directly with scientists and science crowdfund.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"84591787ceefa568895abc2281a2957f","permalink":"https://open-neuroscience.com/en/post/crowd-funding/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/crowd-funding/","section":"post","summary":"As many other things that are being decentralized with the advent of the internet, so is research. One of the very things being decentralized is the funding source for research projects.","tags":["Other"],"title":"Crowd funding","type":"post"},{"authors":[""],"categories":["Database"],"content":"In here are some examples of tools that can be used to share/store data collected. Published a paper and think that people would benefit from looking at the raw data? Want to make that data that has been stored for years useful? Here you’ll find some options on how to do it.\n FigShare: Free repository that allows storage of any sort of files (data, code, schematics) and gives each of them a digital object identifier (also keeping track to any changes made), which makes them citable. Also the website has tools to share the data.  Dryad: Repository for data, works in a similar way to Figshare, but Dryad also has a data submission system integrated with a (growing) number of journals, so that paper submissions are synchronized with the data sharing.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0a15bcc1360cc13fe63b614b4864a99b","permalink":"https://open-neuroscience.com/en/post/data-repositories/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/data-repositories/","section":"post","summary":"In here are some examples of tools that can be used to share/store data collected. Published a paper and think that people would benefit from looking at the raw data? Want to make that data that has been stored for years useful?","tags":["Database"],"title":"Data repositories","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":" Katharina and Alex are developing a classic PCR machine: 16 samples and a heated lid.\n You can find more details of their project here\nHere is a demo video:\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2662b5965625900573e0f66330520ad9","permalink":"https://open-neuroscience.com/en/post/diy_pcr/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/diy_pcr/","section":"post","summary":"Katharina and Alex are developing a classic PCR machine: 16 samples and a heated lid.\n You can find more details of their project here\nHere is a demo video:","tags":["Benchtop","Hardware"],"title":"DIY PCR","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":" DremelFuge is a very simple and clever centrifuge, buit perhaps not the safest one (be careful if you end up using it!).\nIt takes advantage of 3d printing technology to print an adaptor that goes on to a Dremel (a precision tool that has really high rotation rates). It was created by Cathal\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b7e430438ab8cc0d0da89715fad56043","permalink":"https://open-neuroscience.com/en/post/dremelfuge/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/dremelfuge/","section":"post","summary":"DremelFuge is a very simple and clever centrifuge, buit perhaps not the safest one (be careful if you end up using it!).\nIt takes advantage of 3d printing technology to print an adaptor that goes on to a Dremel (a precision tool that has really high rotation rates).","tags":["Benchtop","Hardware"],"title":"DremelFuge","type":"post"},{"authors":[""],"categories":["Data analysis"],"content":" Fiji is a distribution of ImageJ. The idea of the developers is to make the life of scientists easier by bundling ImageJ with nicely organised plugins and auto update function.\n Fiji compares to ImageJ as Ubuntu compares to Linux.\n  \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e03d5614d7048eab3185a4ef785145b1","permalink":"https://open-neuroscience.com/en/post/fiji/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/fiji/","section":"post","summary":"Fiji is a distribution of ImageJ. The idea of the developers is to make the life of scientists easier by bundling ImageJ with nicely organised plugins and auto update function.","tags":["Data analysis"],"title":"Fiji","type":"post"},{"authors":[""],"categories":["Other"],"content":"It is great that there are other interesting projects out there that are also concerned with making science available to more people! Here is a short list of projects I came across. They are not necessarily focusing on open source, but worth getting to know anyhow:\n TReND in Africa: Where TReND stands for Teaching and Research in Neuroscience for Development, is a initiative to stop the brain drain in sub-Saharan Africa. They are a non-profit organisation led by a small group of researchers that are training and teaching local African scientists. On top of that they also coordinate the collection of money and equipment donation to establish permanent research facilities on African universities.\n Open Stent project: Although more into medicine rather than neuroscience is the open stent project is developed by NDC. Their stent was first designed to aid customer interaction. It seems that when giving examples on design improvements, they would always bump into proprietary issues, therefore they developed their own design and made the blueprints available for everyone.\n Open source stethoscope: This is a 3D printed stethoscope, developed by Tarek Loubani, a doctor that works in Gaza and with a 3D printer and 5 dollars worth of materials (tubes, ear piece and plastic to be printed) he and his group were able to outperform the Littmann Cardiology 3, a market leader, that sells for over 20X the price of the printed one.\n Hackteria – Is a wiki page that collects several DIY projects related to Biology and Open Source Art Projects that use Biology, LifeSciences, Biotechnology. Among the projects listed are centrifuges, water baths, field microscopes.\n Open Source Lab: A project by Prof. Joshua Pearce of Michigan University. It advocates in favour of researchers building their own lab equipment using 3D printers and other “off the shelf” available items. Although the main focus of the lab are environmental problems, a lot of the solutions there stated can easily be harvested/modified for neuroscience purposes.\n e-Health sensor platform: A device created at the open source division of Libelium, called cooking hacks. It allows integration of several health related sensors (blood pressure, oxygen level, glucose level, muscle activity, airflow, galvanic response) into arduino and raspberry pi. Which can be used to make real time monitoring of patients and/or test subjects.\n Bitalino: On the same lines as e-health (above), the Bitalino is a complete platform for measurements of biosignals, but this project is more focused on learning and prototyping. It also has free software for data visualization.\n Little Devices: develops tools to improve health care and diagnostics. They are open source, and DIY.\n Public lab: Involved with environmental issues, Public lab is a platform that empowers communities to measure environmental variables around them. This way hard data concerning water, air and soil pollution can be used to put pressure on governments.\n  Open source Muon Detector: an undergraduate-level physics project that incorporates various aspects of machine- and electronics-shop technical development. The desktop muon detector is a self-contained apparatus that employs plastic scintillator as a detection medium and a silicon photomultiplier for light collection. These detectors can be used in conjunction with the provided software to make interesting physics measurements. The total cost of each counter is approximately $100.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fe223372b49426c2c8509ce332d6ab59","permalink":"https://open-neuroscience.com/en/post/other-interesting-projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/other-interesting-projects/","section":"post","summary":"It is great that there are other interesting projects out there that are also concerned with making science available to more people! Here is a short list of projects I came across.","tags":["Other"],"title":"Interesting projects","type":"post"},{"authors":[""],"categories":["Database"],"content":" NeuroElectro wants to extract information about neuron types, morphology, electrophysiology properties from papers, using text mining algorithms and gathers them in a database.\n Our goal is to facilitate the discovery of neuron-to-neuron relationships and better understand the role of functional diversity across neuron types.\n  \n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4458c6705deb2621b8c4c7def327a245","permalink":"https://open-neuroscience.com/en/post/neuroelectro/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/neuroelectro/","section":"post","summary":"NeuroElectro wants to extract information about neuron types, morphology, electrophysiology properties from papers, using text mining algorithms and gathers them in a database.\n Our goal is to facilitate the discovery of neuron-to-neuron relationships and better understand the role of functional diversity across neuron types.","tags":["Database"],"title":"NeuroElectro","type":"post"},{"authors":[""],"categories":["Human ephys","Hardware"],"content":"BioAmp is a biopotential acquisition device (EEG, ECG, EMG, EOG, etc.) developed in the Prototyping Laboratory at the School of Engineering of the National University of Entre Rios (Argentina).\nMain features:\n8 independent acquisition channels 24 bits of resolution per channel 2000 Hz is the maximum sampling frequency USB connection (power and data transmission) inputs for trigger signal designed under electrical safety standards for medical use (electrical insulation, touch-proof connectors, etc.)  A very interesting feature of the BioAmp is the possibility of combining two amplifiers to double the number of recording channels. It is also possible to program each channel individually, offering the possibility of registering different types of signal simultaneously. For example, EEG, EOG, and EMG could be recorded during a sleep study, or EMG and ECG during a physical activity study, etc.\nThis project is currently in evolution and development, continually changes and updates are made to improve the product. Both the hardware source files (PCB and cabinet for 3D printing) and firmware are available in the project repository.\nFor more information on this project and other projects carried out in the Prototyping Laboratory, visit the laboratory website.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4e0b1591aecdc936cc14625943e10b37","permalink":"https://open-neuroscience.com/en/post/bio_amp/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/bio_amp/","section":"post","summary":"BioAmp is a biopotential acquisition device (EEG, ECG, EMG, EOG, etc.) developed in the Prototyping Laboratory at the School of Engineering of the National University of Entre Rios (Argentina).\nMain features:","tags":["Human ephys","Hardware"],"title":"Open BCI","type":"post"},{"authors":[""],"categories":["Human ephys","Hardware"],"content":" OpenBCI is a complete open source EEG system that can be built either on top of an Arduino (8-bit system), or on top of chipKIT (32-bit system), which gives the system more local memory and allows for faster speeds.\nAll software code and hardware (including a model for a 3D printable headset) plans can be found freely available at their download section or at GitHub.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"80eedb4d6d2eabaf5f0920d710d37fe9","permalink":"https://open-neuroscience.com/en/post/open-bci/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open-bci/","section":"post","summary":"OpenBCI is a complete open source EEG system that can be built either on top of an Arduino (8-bit system), or on top of chipKIT (32-bit system), which gives the system more local memory and allows for faster speeds.","tags":["Human ephys","Hardware"],"title":"Open BCI","type":"post"},{"authors":[""],"categories":["Human ephys","Hardware"],"content":" The openEEG project aims at describing and putting manuals for building a two channel EEG system for about U$200. More on instructions on how to build one, can be found here.\nThe latest update on the page seems to be a bit old, but Olimex sells the necessary PCB boards and accessories to build the device. They also sell the openEEG completely assembled.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ded4e5c4ceae7a12d9f4af4362599e02","permalink":"https://open-neuroscience.com/en/post/open_eeg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open_eeg/","section":"post","summary":"The openEEG project aims at describing and putting manuals for building a two channel EEG system for about U$200. More on instructions on how to build one, can be found here.","tags":["Human ephys","Hardware"],"title":"Open EEG","type":"post"},{"authors":[""],"categories":["Animal ephys","Hardware"],"content":"Open Ephys is a great initiative to create a suite that encompasses hardware for LFP and spiking recording, optogenetics combined with custom written software for microstimulation, environmental stimuli, extracellular recording and optogen. perturbations. Their ultimate goal is to create a system optimized for tetrodes and optogenetics where one is able to record and analyse data in real-time. On the project’s website one can download plans on how to build the devices and estimate on part cost (which is much, much lower than commercially available systems out there).\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"705493e24f9e49830e00e874381a745c","permalink":"https://open-neuroscience.com/en/post/open-ephys/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open-ephys/","section":"post","summary":"Open Ephys is a great initiative to create a suite that encompasses hardware for LFP and spiking recording, optogenetics combined with custom written software for microstimulation, environmental stimuli, extracellular recording and optogen.","tags":["Animal ephys","Hardware"],"title":"Open Ephys","type":"post"},{"authors":[""],"categories":["Human ephys","Hardware"],"content":"OpenHardwareExG: is a project that provides both open source hardware and software for the measurement and analysis of different types of biosignals\nFrom the project page:\nAbout the OpenHardwareExG project Project goals The main goal of the project is to build a device that allows the creation of electrophysiologic signal processing applications. In addition: Hardware and software that we develop will have a free/open source license. We also prefer to use hardware and software that are free/open source. We would like to keep the hardware \u0026quot;DIY compatible\u0026quot; (hand solderable, with parts that are readily available in small quantities, etc.) For us, this is a hobby and learning project. It's important to keep it fun, and take the time to learn along the way.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"219fdd440e93a9ab13bd746175a47da4","permalink":"https://open-neuroscience.com/en/post/open_exg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open_exg/","section":"post","summary":"OpenHardwareExG: is a project that provides both open source hardware and software for the measurement and analysis of different types of biosignals\nFrom the project page:\nAbout the OpenHardwareExG project Project goals The main goal of the project is to build a device that allows the creation of electrophysiologic signal processing applications.","tags":["Human ephys","Hardware"],"title":"Open ExG","type":"post"},{"authors":[""],"categories":["Other"],"content":" Open notebooks are opening up science in the very first steps, making records of ideas, plans that didn’t work and protocols that failed available publicly. This allows others to avoid trailing the same dead end roads, saving time, money and human power. Some examples are listed below, but unfortunately there weren’t enough examples in the neuroscience field (until 22/01/14), so examples from all fields are listed:\n Carl Boettiger’s notebook\n Jeremiah Faith’s notebook\n Michael Barton’s github repository\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a648b36e1d6332a2a61341faff3b2436","permalink":"https://open-neuroscience.com/en/post/open-lab-notebooks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open-lab-notebooks/","section":"post","summary":"Open notebooks are opening up science in the very first steps, making records of ideas, plans that didn’t work and protocols that failed available publicly. This allows others to avoid trailing the same dead end roads, saving time, money and human power.","tags":["Other"],"title":"Open lab notebooks","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":" Open PCR is an open source PCR machine with heated lid and space for 12 samples\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"21999427d19ec024b8e62a0643f900ff","permalink":"https://open-neuroscience.com/en/post/open_pcr/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open_pcr/","section":"post","summary":"Open PCR is an open source PCR machine with heated lid and space for 12 samples","tags":["Benchtop","Hardware"],"title":"Open PCR","type":"post"},{"authors":[""],"categories":["Database"],"content":"From the Open science framework webpage:\n The Open Science Framework (OSF) is part network of research materials, part version control system, and part collaboration software. The purpose of the software is to support the scientist’s workflow and help increase the alignment between scientific values and scientific practices.  The project offers cloud space for uploading of project outline, materials, workflow, individual contributions and their extent to a specific project. All of that with the option of having all data publicly or privately available. The idea is to allow a more transparent and innovative system where people can see what is being done in “real-time”, contribute and even take up on ideas from other people so that the wheel doesn’t have to be reinvented, the system also allows for proper citation, so that the “wheel inventors” won’t go uncredited.\nAs an example of what can be done through the Open Science Framework, one can cite the Reproducibility Project which is a project that aims at checking the reproducibility of ~150 sample studies from cognitive and psychological sciences. Contributors are welcomed!\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e42a5e567ebcb046ff3aaeb43133ec68","permalink":"https://open-neuroscience.com/en/post/open-science-framework/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open-science-framework/","section":"post","summary":"From the Open science framework webpage:\n The Open Science Framework (OSF) is part network of research materials, part version control system, and part collaboration software. The purpose of the software is to support the scientist’s workflow and help increase the alignment between scientific values and scientific practices.","tags":["Database"],"title":"Open science framework","type":"post"},{"authors":[""],"categories":["Database"],"content":"The open source brain project is a database of computational models of neural systems. From the website:\n Open Source Brain is a resource for sharing and collaboratively developing computational models of neural systems.\n  OSB will provide advanced facilities to analyse, visualise and transform models, and to connect researchers interested in models of specific neurons, brain regions and disease states.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bed9265c521edac9eff9a1daba74a3a5","permalink":"https://open-neuroscience.com/en/post/open-source-brain/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/open-source-brain/","section":"post","summary":"The open source brain project is a database of computational models of neural systems. From the website:\n Open Source Brain is a resource for sharing and collaboratively developing computational models of neural systems.","tags":["Database"],"title":"Open source brain","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":"A very neat picospritzer initially created by Joe (PI at Raimondo Lab) using basically a solenoid valve, microcontroller and a power source.\nWas later further developed by Chris at the Baden Lab, and collaboratively published as a peer reviewed article.\nDetails on how to build it, can be found on the project\u0026rsquo;s Git repository.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8aeb179ca768dee291b750bdc11f8875","permalink":"https://open-neuroscience.com/en/post/openspritzer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/openspritzer/","section":"post","summary":"A very neat picospritzer initially created by Joe (PI at Raimondo Lab) using basically a solenoid valve, microcontroller and a power source.\nWas later further developed by Chris at the Baden Lab, and collaboratively published as a peer reviewed article.","tags":["Benchtop","Hardware"],"title":"OpenSpritzer","type":"post"},{"authors":[""],"categories":["Microscope","Hardware"],"content":" Open stage is a low-cost motorised microscope stage capable of movement in the micrometer range.\nIt features manual control via a control-pad, different movement velocities and pc communication through the serial port.\nThe authors also state that due to its simplicity, the system could be used to drive micromanipulators and other devices\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"63d216802524013fa9775f0e9655f973","permalink":"https://open-neuroscience.com/en/post/openstage/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/openstage/","section":"post","summary":"Open stage is a low-cost motorised microscope stage capable of movement in the micrometer range.\nIt features manual control via a control-pad, different movement velocities and pc communication through the serial port.","tags":["Microscope","Hardware"],"title":"OpenStage","type":"post"},{"authors":[""],"categories":["Computer clusters","Hardware"],"content":" Parallela, an open source, open access card sized supercomputer, has the mission of bringing parallel computing to the masses by combining multiple RISC processors and very low power consumption. Produced by the Adapteva company.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0120b347d5e04bca8bfd253151c02b79","permalink":"https://open-neuroscience.com/en/post/parallela/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/parallela/","section":"post","summary":"Parallela, an open source, open access card sized supercomputer, has the mission of bringing parallel computing to the masses by combining multiple RISC processors and very low power consumption. Produced by the Adapteva company.","tags":["Computer clusters","Hardware"],"title":"Parallela","type":"post"},{"authors":[""],"categories":["Data analysis","Software"],"content":" PySpace is a signal processing and classificiation environment for Python.\nModular software for processing of large data streams that has been specifically designed to enable distributed execution and empirical evaluation of signal processing chains. Various signal processing algorithms are available within the software, from finite impulse response filters over data-dependent spatial filters (e.g. CSP, xDAWN) to established classifiers (e.g. SVM, LDA). pySPACE incorporates the concept of node and node chains of the Modular Toolkit for Data Processing (MDP) framework.\nA paper about PySpace can be found here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"50292d0b906940ca4db8ce0c2fdfb200","permalink":"https://open-neuroscience.com/en/post/pyspace/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/pyspace/","section":"post","summary":"PySpace is a signal processing and classificiation environment for Python.\nModular software for processing of large data streams that has been specifically designed to enable distributed execution and empirical evaluation of signal processing chains.","tags":["Data analysis","Software"],"title":"PySpace","type":"post"},{"authors":[""],"categories":["Software"],"content":"Frontiers has created not one but two nice collections about open source software for neurosciences written in Python.\n Here is collection 1\n Here is collection 2\nIn these collections the readers will find a lot of nice resources, ranging from stimulus generation, to data formatting and analysis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b67a16d4fb3703de97242801df524643","permalink":"https://open-neuroscience.com/en/post/python-for-neuroscience-frontiers-collection/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/python-for-neuroscience-frontiers-collection/","section":"post","summary":"Frontiers has created not one but two nice collections about open source software for neurosciences written in Python.\n Here is collection 1\n Here is collection 2\nIn these collections the readers will find a lot of nice resources, ranging from stimulus generation, to data formatting and analysis.","tags":["Software"],"title":"Python for Neurosciences (Frontiers collection)","type":"post"},{"authors":[""],"categories":["Hardware"],"content":"Every lab needs a signal generator once in a while. They are useful to see if your acquisition program is working properly, to test why a certain piece of equipment is not working properly or to generate cues and targets at behavioural paradigms. Listed below are different generators, built using arduinos and other microcontrollers. They have different degrees of complexity and capabilities, so it would be wise to briefly look through them and see what fits you best!\n  The arduino waveform generator is a pretty straight forward project that is able to generate four different waveforms from 1Hz to 50kHz. Gain, frequency, modulation and waveform type are controlled by nobs.\n   Atmel Xmega USB/Serial Arbitrary Waveform Generator runs using a boston android XMEGA evaluation board and is able to deliver square, sine, triangular and arbitrary waveforms in between 5Hz and 20kHz. This one is not a stand alone system, which means that to set a new waveform type, one would have to have the board connect to a computer at all times.\n  Simple waveform generator seems to be the most straight forward of all projects, requiring only a potentiometer, a couple of resistors and push buttons. The trade off is that with the present sketch, waveforms of only up to 170Hz can be generated. It generates sawtooth, square, triangular and sine waveforms.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d057b7b55922d4500298bb184cb5a8af","permalink":"https://open-neuroscience.com/en/post/signal-generators/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/signal-generators/","section":"post","summary":"Every lab needs a signal generator once in a while. They are useful to see if your acquisition program is working properly, to test why a certain piece of equipment is not working properly or to generate cues and targets at behavioural paradigms.","tags":["Hardware"],"title":"Signal Generators","type":"post"},{"authors":[""],"categories":["Software"],"content":" Ever thought about playing with a virtual worm? or interacting with a simulated bee brain? Sounds interesting no? These are just two projects that offer anyone the opportunity to play around with brain/neuronal simulations and models. Some of them are hardware based, and some completely software:  \u0026lt;p\u0026gt; \u0026lt;a href=\u0026quot;http://openeuroscience.com/open-source-simulations-and-models/open-worm/\u0026quot;\u0026gt;OpenWorm\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;a href=\u0026quot;http://openeuroscience.com/open-source-simulations-and-models/green-brain/\u0026quot;\u0026gt;GreenBrain\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;a href=\u0026quot;http://openeuroscience.com/open-source-simulations-and-models/neuronsneuronsneurons/\u0026quot;\u0026gt;Neurons,Neurons,Neurons\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;a href=\u0026quot;http://openeuroscience.com/open-source-simulations-and-models/big-neuron/\u0026quot;\u0026gt;Big Neuron\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;    {% for page in site.pages %} {% for category in page.categories %} {% if category == \"Simulation\" %} {% include card_page.html %} {% endif %} {% endfor %} {% endfor %} \u0026lt;/div\u0026gt;    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"65e95dccc47fc27f2ca24884b7a90ef7","permalink":"https://open-neuroscience.com/en/post/simulation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/simulation/","section":"post","summary":"Ever thought about playing with a virtual worm? or interacting with a simulated bee brain? Sounds interesting no? These are just two projects that offer anyone the opportunity to play around with brain/neuronal simulations and models.","tags":["Software"],"title":"Simulations","type":"post"},{"authors":[""],"categories":["Behaviour","Hardware"],"content":"This project was developed by Katherine Scott to be presented at the PyCon 2014. She developed a skinner box for her pet rats using a raspberry pi and some 3D printed parts. The setup contain a food dispenser, a buzzer, levers, a camera to observe the animals and it is hooked in a way that everything can be controlled over the internet!\nYou can find the files for 3D parts here and a better description of the project here\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3c5f3d8921427a548065969ab767ba56","permalink":"https://open-neuroscience.com/en/post/skinnerbox_rpi_python/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/skinnerbox_rpi_python/","section":"post","summary":"This project was developed by Katherine Scott to be presented at the PyCon 2014. She developed a skinner box for her pet rats using a raspberry pi and some 3D printed parts.","tags":["Behaviour","Hardware"],"title":"Skinner Box with RPi+Python","type":"post"},{"authors":[""],"categories":["Microscope","Hardware"],"content":"Although stereo microscopes are an essential piece of hardware in biology labs, sometimes we wish they had more features, like the possibility to record the magnified images with a camera, or have a better lighting system to enhance contrast on those small samples.\nOne person has taken those issues to heart and tackled them all in a very brilliant way. Below you\u0026rsquo;ll find links to Steve\u0026rsquo;s blog, where he describes, in a very detailed way, three projects to enhance the all familiar stereo microscope:\n Camera eye piece adaptor.\n AZIZ a ring lighting system.\n Articulated stereo microscope mount.\n\nSome of them are not that easy to reproduce, but maybe be a good starting point for other DIY versions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5226159121a415936202eb8287ca1ec5","permalink":"https://open-neuroscience.com/en/post/stereo_microscope/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/stereo_microscope/","section":"post","summary":"Although stereo microscopes are an essential piece of hardware in biology labs, sometimes we wish they had more features, like the possibility to record the magnified images with a camera, or have a better lighting system to enhance contrast on those small samples.","tags":["Microscope","Hardware"],"title":"Stereo microscope","type":"post"},{"authors":[""],"categories":["Benchtop","Hardware"],"content":"From the Pearce lab, this syringe pump was published in Plos One and is built using 3d printed parts, stepper motors and a raspberry pi, costing 5% or less than commercial available systems. Can be calibrated and customized for different applications.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"66ce688660d9fda1850b63eee4ff2623","permalink":"https://open-neuroscience.com/en/post/syringe_pump/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/syringe_pump/","section":"post","summary":"From the Pearce lab, this syringe pump was published in Plos One and is built using 3d printed parts, stepper motors and a raspberry pi, costing 5% or less than commercial available systems.","tags":["Benchtop","Hardware"],"title":"Syringe Pump","type":"post"},{"authors":[""],"categories":["Prosthetics","Hardware"],"content":" Takktile, is a tactile sensor to be used on robotic applications. The developers want to make it move away from the closed walls of research institutions by making it open source and cheap. It is built based on MEMs barometers and can sense 1 gram loads as well as coping with hammer blows (see video from their website below).\n\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7aeb3cdeef4a16d9a6b47c99f1f06d7b","permalink":"https://open-neuroscience.com/en/post/takktile/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/takktile/","section":"post","summary":"Takktile, is a tactile sensor to be used on robotic applications. The developers want to make it move away from the closed walls of research institutions by making it open source and cheap.","tags":["Prosthetics","Hardware"],"title":"Takktile","type":"post"},{"authors":[""],"categories":["Electric","Hardware"],"content":"Although of simple complexity and using low currents, this tDCS machine is still to be considered a piece of equipment that could be dangerous both in the assembly and in the operation phases, so please inform yourself as best as you can before either of these steps! Also remember that the openeuroscience website cannot be held responsible for any injuries that might occur from improper use of this tool.\n DIY tDCS instructables\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"69eeaa1b26835ffe035cda5d8dcd5ed2","permalink":"https://open-neuroscience.com/en/post/tdcs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/tdcs/","section":"post","summary":"Although of simple complexity and using low currents, this tDCS machine is still to be considered a piece of equipment that could be dangerous both in the assembly and in the operation phases, so please inform yourself as best as you can before either of these steps!","tags":["Electric","Hardware"],"title":"tDCS","type":"post"},{"authors":[""],"categories":["Data analysis"],"content":"Google has packaged their deeplearning machine learning tools and made it open source. The project is called tensorflow, and is available here. Some nice tutorials on the website, so that with a bit of patience, people can start to deep their toes into machine learning!\nBe sure to check the video below for more details!\n\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5d3435d9ec2280e654ec8c59a0aaa54a","permalink":"https://open-neuroscience.com/en/post/tensor-flow/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/tensor-flow/","section":"post","summary":"Google has packaged their deeplearning machine learning tools and made it open source. The project is called tensorflow, and is available here. Some nice tutorials on the website, so that with a bit of patience, people can start to deep their toes into machine learning!","tags":["Data analysis"],"title":"Tensor Flow","type":"post"},{"authors":[""],"categories":["Database"],"content":" The Visible Human Project is a database of anatomical images (MR, CT and radiography) from male and female bodies. Information about the database is translated into a couple of different languages. Although an license needs to be signed and sent over to the NIH, the procedure seems to be straightforward and cost free.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ffcb48126db759d95bce43c8546ffcbc","permalink":"https://open-neuroscience.com/en/post/the-visible-human-project/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/the-visible-human-project/","section":"post","summary":"The Visible Human Project is a database of anatomical images (MR, CT and radiography) from male and female bodies. Information about the database is translated into a couple of different languages.","tags":["Database"],"title":"The Visible Human project","type":"post"},{"authors":[""],"categories":["Prosthetics","Hardware"],"content":" The Yale open hand project, has a similar purpose of the open hand project, that is, to make prosthetic hands more widely available through the lowering of costs. They have a different design from the open hand project. Additionally the project wants to take advantage of the lowered costs to speed up the development cycle and provide, together with input from the user community, several different useful hand designs.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2a37bb9309fc415181f9099267622f38","permalink":"https://open-neuroscience.com/en/post/the_yale_open_hand_project/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/the_yale_open_hand_project/","section":"post","summary":"The Yale open hand project, has a similar purpose of the open hand project, that is, to make prosthetic hands more widely available through the lowering of costs. They have a different design from the open hand project.","tags":["Prosthetics","Hardware"],"title":"The Yale open hand project","type":"post"},{"authors":[""],"categories":["Software"],"content":" Vision Egg is a Python library for generating visual stimuli.\nIn more detail, it is a high level interface in between Python and OpenGL, and can use inexpensive consumer grade graphics cards to generate precise visual stimuli. A paper with more details can be found here http://journal.frontiersin.org/article/10.3389/neuro.11.004.2008/full\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ce01ec458ee1fca81c869800230b4b66","permalink":"https://open-neuroscience.com/en/post/vision-egg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/vision-egg/","section":"post","summary":"Vision Egg is a Python library for generating visual stimuli.\nIn more detail, it is a high level interface in between Python and OpenGL, and can use inexpensive consumer grade graphics cards to generate precise visual stimuli.","tags":["Software"],"title":"Vision Egg","type":"post"},{"authors":[""],"categories":["Learning"],"content":"Here are some open learning sources, they go from sites that interactively teach one how to code, to efforts in publishing free college textbooks.\n Khan Academy: Is composed of a series of lectures and exercises on a wide range of topics from basic multiplication to linear algebra and information theory. A great place to learn those things you missed in high school.\n Openstax College: is an initiative that is producing free, downloadable college level textbooks initially in sociology, physics, biology and anatomy and Physiology.\n CodeAcademy: Teaches several programming languages, including python, javascript, etc. in an interactive manner. From the first lesson one is already writing meaningful code to solve exercises.\n Software Carpentry: Is a project that helps scientists to write better code and increase their productivity by teaching them basic computing skills, such as version control, database systems, code with proper documentation and so on. They offer bootcamps, so check their website to see if there are any near you!\n Code.org: Aims to teach programming to everyone, by putting learning sources together, such as codeacademy, khanacademy and so on. Considering that mostly everything now days is run by a computer, this is a great idea.\n edx.org: An initiative from Harvard and MIT to make their lectures (and from other universities) available free online, the nice thing is that they range from humanities to computer science, meaning that this is useful event if it is only for you to go a little bit depeer into that “old forgotten hobby/interest in something that is not neuroscience” you once had.\n Coursera: Aggregates online courses from several universities. It offers certificates for people who complete the courses.\n Sparkfun is a retail store that sells eletronic components for hobbyists and DIY enthusiasts. But they also keep a very useful tutorial section where one can find lessons on basic eletronics, installing arduino libraries, infrared communication, and designing PCB boards.\n OpenOptogenetics: is a wiki page designed to promote knowledge and know-how exchange for optogenetic applications.\n Open Wetware wiki is a page dedicated to gathering information and know-how in biology and biological engineering. They provide a place to organize your own information, store labnotebooks and collaborate with other individuals. There is an article released in Nature (2008) about this project.\n OpenPicoAmp: is an open source planar lipid bilayer amplifier designed to teach undergrad students about electro-chemical properties of membranes. A paper describing the project, together with bill of materials and more can be found here (for some reason this link did not open on Firefox. Try Chromium or Chrome instead). Also, a description on thingiverse can found here.\n PyroElectro: a page for electronics and robotics enthusiasts, they have tutorials on several topics, such as modern electronics. microcontrollers and FPGA.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"36f079a71d7e31e00a252f0febf8c9a0","permalink":"https://open-neuroscience.com/en/post/webportals/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/webportals/","section":"post","summary":"Here are some open learning sources, they go from sites that interactively teach one how to code, to efforts in publishing free college textbooks.\n Khan Academy: Is composed of a series of lectures and exercises on a wide range of topics from basic multiplication to linear algebra and information theory.","tags":["Learning"],"title":"Web portals","type":"post"},{"authors":null,"categories":["Learning"],"content":"When working with Open Hardware, Google search will become your friend, whether you want it or not. Other search engines, such as DuckDuckGo won’t cut it (it is much harder to find what you are looking for, especially in cases where you don’t know all specific terms). Google is a fantastic tool to find answers. But if you are new in electronic development, and in programming, or even if you are going to work in a new subfield, you may not even know what you don’t know. What to search for if you don’t know what the problem or component is called? Here I’d like to suggest YouTube. You want to get involved with Arduinos and a interesting sensor. Go and search for ‘Arduino interesting sensor’ on YouTube. There are many videos, long and short, explaining in more or less depth, more or less funny, what you can expect, and more importantly what the used components are called. I normally start by watching a few short videos to make sure that system is what I’m looking for. Afterwards, I look into several longer, deeper videos. You will get a great overview of components and alternatives regarding code and hardware.\nHere I suggest some YouTube channels that constantly output good content, going across all kind of sensors, wireless communication as well as science and hacking in a more general sense. They can also be seen as evening entertainment, for me much better than dozing off to some soap opera.\n ElectroBOOM https://www.youtube.com/channel/UCJ0-OtVpF0wOKEqT2Z1HEtA\nMehdi Sadaghdar, the protagonist of this channel explains in a very unique way how not to get electrocuted in any possible way. It trains the viewer what to keep in mind when working with electronics. There are many ways to fry your circuit, he will show them all in a entertaining way. It seems repetitive after a whole but that will just help your brain to keep those bullet points!\n GreatScott https://www.youtube.com/channel/UC6mIxFTvXkWQVEHPsEdflzQ\nBasic arduino and electronic projects, mosty day to day useful and very reproducible. His series ‘Electronics Basics’ explains fantastically electronic components like transistors and diodes to name a few. Easy to digest and a lot can be learned.\n Cody’s Lab https://www.youtube.com/user/theCodyReeder/videos\nCody is the Nr 1 in entertaining education on YouTube. He does all kind of experiments from geology, chemistry biology to gardening and everything in between. His passion is infectious and his style not teachy at all, you just tag along a fun quarter hour of science and ideas.\n Afrotechmods https://www.youtube.com/user/Afrotechmods\nA nice source for Arduino knowledge and inspiration! Great videos about basic electronics and some basic elements like power supplies, LEDs and transistors as well. There are well explained circuits about filters and op amps for example.\n Marco Reps https://www.youtube.com/user/reppesis/videos\nA very diverse set of videos about electronics and hacking with great explanations. A good source for inspiration and entertainment, oscilloscopes, lasers and soldering are some of his main topics.\n Applied Science https://www.youtube.com/user/bkraz333/videos\nIMHO the most advanced scientist on YouTube. X-ray, water cutter, electron microscopy and others, in depth explanation how he build or hacked several machines that seem way to complex / delicate to open up. His reverse engineering skills are helpful, it applies to how we could approach devices when we want to fix or understand them.\n The Thought Emporium https://www.youtube.com/user/TheChemlife/videos\nA group of scientists hacking advanced scientific machinery with household items, listening to satellites, dry freezing, fluorescence dyes and how to become a cyborg.\n The Post Apocalyptic Inventor https://www.youtube.com/channel/UCDbWmfrwmzn1ZsGgrYRUxoA/videos\nHe hacks household items to harvest their motors and other hard to come by components. Lots of useful explanations on how to use metal working machines and how to build your own. A lot of entertainment around basic electronics.\n Andreas Spiess https://www.youtube.com/channel/UCu7_D0o48KbfhpEohoP7YSQ/videos\nTHE source of information if you want to learn wireless communication with Arduinos. Andreas gives very well structured and explained lectures about the ESP32, an Arduino with WiFi and other wireless capabilities. He enlightens every aspect about hardware and software on this topic. There are also many videos about all kind of interesting sensors.\n EEVblog https://www.youtube.com/user/EEVblog/videos\nI will be honest, the videos are really long and very deep and technical. But if you need some information on a specific topic and his channel has a relevant video, that video will contain all the information you will need. If you are already trying to get into PCB design, watch his videos, all of them, over and over again, you will pick up all the rules and tricks to keep im mind when designing yourself.\n bitluni’s lab https://www.youtube.com/user/bitlunislab/videos\nGood videos about Arduino in the world of internet of things, making electronics in your house remote controlled and automatic will nicely translate into the lab as well.\n AvE https://www.youtube.com/user/arduinoversusevil/videos\nEntertainment in the first place, but be aware of his potty mouth, not everyone likes it. If you do, keep on watching. He mostly dissembles power tools and evaluates their build with focus on the machine engineering side – is the housing sufficiently stable, and electronically, are the components capable of what the label advertises? After a good amount of videos you get a good grasp on how engineering works in general, how they think. He helps to understand that you don’t need to be afraid to open up devices if they break or if you want to interfere with them. there are patterns and regularities that make all those machines somewhat self explanatory.\n ForceTronics https://www.youtube.com/channel/UCNd_fNspAczm8UoE2ay7K1Q/videos\nFrom easy to advanced and mostly around Arduino and PCB design, also really good videos about soldering including helpful tips on SMD soldering. All ind of tutorials about sensors and times, protocols and wifi stuff.\n Tom Scott https://www.youtube.com/user/enyay/videos\nNo Arduino, no electronics just science and curiosity. Short professionally produced videos about various topics space, computers, technology, science and more.\n If you know all of that already … KerryWong https://www.youtube.com/user/KerryWongBlog/videos\nLots of interesting and exotic laboratory electronics testing equipment and some more basic videos.\n TheSignalPath https://www.youtube.com/user/TheSignalPathBlog/videos\nReally professional high frequency stuff, loang and in depth. if you are into that or you just want to see realy sexy PCBs give it a go!\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d296508f6ca0c5c1cc42eb9aa763bad4","permalink":"https://open-neuroscience.com/en/post/youtube_as_a_resource_for_open_science_hardware/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/post/youtube_as_a_resource_for_open_science_hardware/","section":"post","summary":"When working with Open Hardware, Google search will become your friend, whether you want it or not. Other search engines, such as DuckDuckGo won’t cut it (it is much harder to find what you are looking for, especially in cases where you don’t know all specific terms).","tags":["Learning"],"title":"YouTube as a resource for Open Science Hardware","type":"post"}]