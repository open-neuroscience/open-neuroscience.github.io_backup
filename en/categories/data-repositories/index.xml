<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Repositories | Open Neuroscience</title>
    <link>https://open-neuroscience.com/en/categories/data-repositories/</link>
      <atom:link href="https://open-neuroscience.com/en/categories/data-repositories/index.xml" rel="self" type="application/rss+xml" />
    <description>Data Repositories</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>CC BY SA 4.0</copyright><lastBuildDate>Thu, 23 Jul 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://open-neuroscience.com/images/icon_hud109d9c66059217af2bab44795aa78ad_73385_512x512_fill_lanczos_center_2.png</url>
      <title>Data Repositories</title>
      <link>https://open-neuroscience.com/en/categories/data-repositories/</link>
    </image>
    
    <item>
      <title>Neuroimaging Informatics Tools and Resources Collaboratory (NITRC)</title>
      <link>https://open-neuroscience.com/en/post/neuroimaging_informatics_tools_and_resources_collaboratory_nitrc/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/neuroimaging_informatics_tools_and_resources_collaboratory_nitrc/</guid>
      <description>&lt;p&gt;NeuroImaging Tools &amp;amp; Resources Collaboratory is an award-winning free web-based resource that offers comprehensive information on an ever expanding scope of neuroinformatics software and data. Since debuting in 2007, NITRC has helped the neuroscience community make further discoveries using software and data produced from research that used to end up lost or disregarded.&lt;/p&gt;
&lt;p&gt;NITRC also provides free access to data and enables pay-per-use cloud-based access to unlimited computing power, enabling worldwide scientific collaboration with minimal startup and cost. NITRC’s scientific focus includes: MR, PET/SPECT, CT, EEG/MEG, optical imaging, clinical neuroimaging, computational neuroscience, and imaging genomics software tools, data, and computational resources.&lt;/p&gt;
&lt;p&gt;With NITRC and its components—the Resources Registry (NITRC-R), Image Repository (NITRC-IR), and Computational Environment (NITRC-CE)—a researcher can obtain pilot or proof-of-concept data to validate a hypothesis for just a few dollars.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;NITRC Development Team&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nitrc.org&#34;&gt;http://www.nitrc.org&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
David Kennedy&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>ReproNim: A Center for Reproducible Neuroimaging Computation</title>
      <link>https://open-neuroscience.com/en/post/repronim_a_center_for_reproducible_neuroimaging_computation/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/repronim_a_center_for_reproducible_neuroimaging_computation/</guid>
      <description>&lt;p&gt;ReproNim&amp;rsquo;s goal is to improve the reproducibility of neuroimaging science and extend the value of our national investment in neuroimaging research, while making the process easier and more efficient for investigators.&lt;/p&gt;
&lt;p&gt;ReproNim delivers a reproducible analysis framework comprised of components that include: 1) data and software discovery; 2) implementation of standardized description of data, results and workflows; 3) development of execution options that facilitates operation in all computational environments; 4)
provision of training and education to the community.&lt;/p&gt;
&lt;p&gt;All components of the framework are intended to foster continued use and development of the reproducible and generalizable framework in neuroimaging research.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;The ReproNim Development Team&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ReproNim&#34;&gt;https://github.com/ReproNim&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
David Kennedy&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Simple Behavioral Analysis (SimBA)</title>
      <link>https://open-neuroscience.com/en/post/simple_behavioral_analysis_simba/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/simple_behavioral_analysis_simba/</guid>
      <description>&lt;p&gt;Several excellent computational frameworks exist that enable high-throughput and consistent tracking of freely moving unmarked animals. SimBA introduce and distribute a plug-and play pipeline that enables users to use these pose-estimation approaches in combination with behavioral annotation for the generation of supervised machine-learning behavioral predictive classifiers.&lt;/p&gt;
&lt;p&gt;SimBA was developed for the analysis of complex social behaviors, but includes the flexibility for users to generate predictive classifiers across other behavioral modalities with minimal effort and no specialized computational background.&lt;/p&gt;
&lt;p&gt;SimBA has a variety of extended functions for large scale batch video pre-processing, generating descriptive statistics from movement features, and interactive modules for user-defined regions of interest and visualizing classification probabilities and movement patterns.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Simon Nilsson: Jia Jie Chhong; Sophia Hwang; Nastacia Goodwin; Sam A Golden&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/sgoldenlab/simba&#34;&gt;https://github.com/sgoldenlab/simba&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-video&#34;&gt;Project Video&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Frq6mMcaHBc&amp;amp;list=PLi5Vwf0hhy1R6NDQJ3U28MOUJPfl2YWYl&amp;amp;index=2&amp;amp;t=0s&#34;&gt;https://www.youtube.com/watch?v=Frq6mMcaHBc&amp;amp;list=PLi5Vwf0hhy1R6NDQJ3U28MOUJPfl2YWYl&amp;amp;index=2&amp;amp;t=0s&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Simon Nilsson&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>OpenNeuro</title>
      <link>https://open-neuroscience.com/en/post/openneuro/</link>
      <pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/openneuro/</guid>
      <description>&lt;p&gt;A free and open platform for sharing MRI, MEG, EEG, iEEG, and ECoG data.&lt;/p&gt;
&lt;p&gt;With OpenNeuro, you can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Browse and explore public datasets and analyses from a wide range of global contributors. Our collection of public datasets continues to grow as more and more become BIDS compatible.&lt;/li&gt;
&lt;li&gt;Download and use public data to create new datasets and run your own analyses.&lt;/li&gt;
&lt;li&gt;Privately share your data so your colleagues can view and edit your work.&lt;/li&gt;
&lt;li&gt;Publish your dataset where anyone can view, download, and run analyses on it.&lt;/li&gt;
&lt;li&gt;Create snapshots of your datasets to ensure past analyses remain reproducible as your datasets grow and change. Publish any of your snapshots while you continue work on your original data behind the scenes.&lt;/li&gt;
&lt;li&gt;Explore your published OpenNeuro dataset using BrainLife&amp;rsquo;s computing network. Utilize their community driven apps to run a variety of analysis and processing software in the browser.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Russell A. Poldrack; Krzysztof Jacek Gorgolewski&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://openneuro.org/&#34;&gt;https://openneuro.org/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-video&#34;&gt;Project Video&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=FK_c1x1Pilk&#34;&gt;https://www.youtube.com/watch?v=FK_c1x1Pilk&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Elizabeth DuPre&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Addgene&#39;s AAV Data Hub</title>
      <link>https://open-neuroscience.com/en/post/addgenes_aav_data_hub/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/addgenes_aav_data_hub/</guid>
      <description>&lt;p&gt;AAV are versatile tools used by neuroscientists for expression and manipulation of neurons. Many scientists have benefited from the high-quality, ready-to-use AAV prep service from Addgene, a nonprofit plasmid repository. However, it can be challenging to determine which AAV tool and techniques are best to use for an experiment. Scientists also may have questions about how much virus to inject or which serotype or promoter should be used to target the desired neuron or brain region. To help scientists answer these questions, Addgene launched an open platform called the AAV Data Hub (&lt;a href=&#34;https://datahub.addgene.org/aav/&#34;&gt;https://datahub.addgene.org/aav/&lt;/a&gt;) which allows researchers to easily share practical experimental details with the scientific community (AAV used, in vivo model used, injection site, injection volumes, etc.). The goal of this platform is to help scientists find the best AAV tool for their experiments by reviewing combined data from a broad range of research labs. The AAV Data Hub launched in late 2019 and over 100 experiments have since been contributed to this project. The dataset includes details and images from experiments conducted in six different species and several different expression sites.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Addgene&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://datahub.addgene.org/aav/&#34;&gt;https://datahub.addgene.org/aav/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-video&#34;&gt;Project Video&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ZPKdr1RdtGI&amp;amp;feature=youtu.be&#34;&gt;https://www.youtube.com/watch?v=ZPKdr1RdtGI&amp;amp;feature=youtu.be&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Angela Abitua&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>BossDB</title>
      <link>https://open-neuroscience.com/en/post/bossdb/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/bossdb/</guid>
      <description>&lt;p&gt;BossDB is a volumetric database that lives in the AWS cloud. Hundreds of terabytes of electron microscopy, light microscopy, and x-ray tomography data are available for free download and study.&lt;/p&gt;
&lt;p&gt;Have a project you want to share with the world for free? Get in touch!
&lt;a href=&#34;https://twitter.com/thebossdb&#34;&gt;https://twitter.com/thebossdb&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;JHU|APL&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://bossdb.org/&#34;&gt;https://bossdb.org/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Jordan Matelsky&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
  </channel>
</rss>
