<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Calcium Imaging | Open Neuroscience</title>
    <link>https://open-neuroscience.com/en/tags/calcium-imaging/</link>
      <atom:link href="https://open-neuroscience.com/en/tags/calcium-imaging/index.xml" rel="self" type="application/rss+xml" />
    <description>Calcium Imaging</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>CC BY SA 4.0</copyright><lastBuildDate>Sun, 04 Oct 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://open-neuroscience.com/media/openneuroscience_logo_dark.svg</url>
      <title>Calcium Imaging</title>
      <link>https://open-neuroscience.com/en/tags/calcium-imaging/</link>
    </image>
    
    <item>
      <title>Mouse VR</title>
      <link>https://open-neuroscience.com/en/post/mouse_vr/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/mouse_vr/</guid>
      <description>&lt;p&gt;Harvey Lab miniaturized mouse VR rig for head-fixed virtual navigation and decision-making tasks.&lt;/p&gt;
&lt;p&gt;The VR setup is comprised of several independent assemblies:&lt;/p&gt;
&lt;p&gt;The screen assembly: a laser projector projects onto a parabolic screen surrounding the mouse. This is the basis for the visual virtual reality.&lt;/p&gt;
&lt;p&gt;Ball cup assembly: an air-supported 8&amp;quot; styrofoam ball that the mouse can run on, with associated ball cup, sensors, and electronics&lt;/p&gt;
&lt;p&gt;Reward delivery system and lick sensor: lick spout, liquid reward reservoir, solenoid, and associated electronics&lt;/p&gt;
&lt;p&gt;Enclosure: A box surrounding the behavioral setup.&lt;/p&gt;
&lt;p&gt;Each of these components is independent of the others: i.e. just the screen could be used in combination with a different treadmill and reward delivery system. The electronics for the ball sensors, reward delivery, and lick detection are all mounted on the same PCB. If only one or two of these functions are needed, you do not need to populate the entire PCB.&lt;/p&gt;
&lt;p&gt;The screen assembly is designed to be small enough to be mounted within a standard 19&amp;quot; server rack, which could easily fit 3 rigs stacked vertically (or two + monitor and keyboard station).&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Noah Pettit; Matthias Minderer; Selmaan Chettih; Charlotte Arlt; Jim Bohnslav; Pavel Gorelick; Ofer Mazor; Christopher Harvey&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/HarveyLab/mouseVR&#34;&gt;https://github.com/HarveyLab/mouseVR&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Noah Pettit&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>DataJoint</title>
      <link>https://open-neuroscience.com/en/post/datajoint/</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/datajoint/</guid>
      <description>&lt;p&gt;DataJoint is an open-source library for managing and sharing scientific data pipelines in Python and Matlab.&lt;/p&gt;
&lt;p&gt;DataJoint allows creating and sharing computational data pipelines, which are defined as databases and analysis code for executing steps of activities for data collection and analysis. For example, many neuroscience studies are organized around DataJoint pipelines that start with basic information about the experiment, then ingest acquired data, and then perform processing, analysis, and visualization of results. The entire pipeline is diagrammed as a graph where each node is a table in the database with a corresponding class in the programming language; together they define the data structure and computations.&lt;/p&gt;
&lt;p&gt;DataJoint key features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;access to shared data pipelines in a relational database (MySQL-compatible) from Python, Matlab, or both.&lt;/li&gt;
&lt;li&gt;data integrity and consistency based founded on the relational data model and transactions&lt;/li&gt;
&lt;li&gt;an intuitive data definition language for pipeline design&lt;/li&gt;
&lt;li&gt;a diagramming notation to visualize data structure and dependencies&lt;/li&gt;
&lt;li&gt;a serialization framework: storing large numerical arrays and other scientific data in a language-independent way&lt;/li&gt;
&lt;li&gt;a flexible query language to retrieve precise cross-sections of data in a desired format&lt;/li&gt;
&lt;li&gt;automated  execution of computational jobs, with built-in job management for distributed computing&lt;/li&gt;
&lt;li&gt;managed storage of large data objects outside the database&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Dimitri Yatsenko; Edgar Walker; Fabian Sinz; Christopher Turner; Raphael Guzman&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://datajoint.io&#34;&gt;https://datajoint.io&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Dimitri Yatsenko&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Neurodata Without Borders</title>
      <link>https://open-neuroscience.com/en/post/neurodata_without_borders/</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/neurodata_without_borders/</guid>
      <description>&lt;p&gt;Neurodata Without Borders is a data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build analysis tools for neurophysiology data. NWB is designed to store a variety of neurophysiology data, including data from intracellular and extracellular electrophysiology experiments, data from optical physiology experiments, and tracking and stimulus data.&lt;/p&gt;
&lt;p&gt;The NWB team consists of neuroscientists and software developers who recognize that adoption of a unified data format is an important step toward breaking down the barriers to data sharing in neuroscience.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Andrew Tritt; Ryan Ly; Ben Dichter; Oliver Ruebel&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nwb.org/&#34;&gt;https://www.nwb.org/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-video&#34;&gt;Project Video&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/vfQsMyl0HQI&#34;&gt;https://youtu.be/vfQsMyl0HQI&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Ben Dichter&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Deep Cinac</title>
      <link>https://open-neuroscience.com/en/post/deep_cinac/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/deep_cinac/</guid>
      <description>&lt;p&gt;Two-photon calcium imaging is now widely used to infer neuronal dynamics from changes in fluorescence of an indicator. However, state of the art computational tools are not optimized for the reliable detection of fluorescence transients from highly synchronous neurons located in densely packed regions such as the CA1 pyramidal layer of the hippocampus during early postnatal  stages  of  development.  Indeed,the  latest  analytical  tools  often  lack  proper benchmark  measurements.  To  meet  this  challenge,  we  first  developed  a  graphical  user interface allowing for a precise manual detection of all calcium transients from imaged neurons based on the visualization of the calcium imaging movie. Then, we analyzed the movies using a convolutional neural network with an attention process and a bidirectional long-short term memory network. This method is able to reach human performance and offers a better F1 score (harmonic mean of sensitivity and precision) than CaImAn to infer neural activity in the developingCA1 without any user intervention. It also enables automatically identifying activity originating from GABAergic neurons. Overall, DeepCINAC offers a simple, fast and flexible open-source toolbox for processing a wide variety of calcium imaging datasets while providing the tools to evaluate its performance.&lt;/p&gt;
&lt;p&gt;See full text at &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/803726v2.full.pdf&#34;&gt;https://www.biorxiv.org/content/10.1101/803726v2.full.pdf&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Julien Denis&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://gitlab.com/cossartlab/deepcinac&#34;&gt;https://gitlab.com/cossartlab/deepcinac&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Matias Andina&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
  </channel>
</rss>
